{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms.functional as TF\nimport os\nimport math\nimport random\nimport pyarrow.parquet as pq\nimport copy\nimport optuna\nfrom optuna.trial import TrialState\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:53:50.694139Z","iopub.execute_input":"2023-04-28T00:53:50.694917Z","iopub.status.idle":"2023-04-28T00:53:54.108795Z","shell.execute_reply.started":"2023-04-28T00:53:50.694878Z","shell.execute_reply":"2023-04-28T00:53:54.107735Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:53:54.110932Z","iopub.execute_input":"2023-04-28T00:53:54.111756Z","iopub.status.idle":"2023-04-28T00:53:54.175412Z","shell.execute_reply.started":"2023-04-28T00:53:54.111712Z","shell.execute_reply":"2023-04-28T00:53:54.174334Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda\nUsing device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/asl-signs/train.csv\")\nimport json\ndef read_json(path):\n    with open(path, \"r\") as file:\n        json_data = json.load(file)\n    return json_data\ns2p_map = read_json(os.path.join(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\"))\np2s_map = {v: k for k, v in s2p_map.items()}\n\nencoder = lambda x: s2p_map.get(x)\ndecoder = lambda x: p2s_map.get(x)\n\ntrain[\"label\"] =train[\"sign\"].map(encoder)\ntrain = train.drop([\"participant_id\",\"sequence_id\",\"sign\"],axis=1)\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:53:54.177917Z","iopub.execute_input":"2023-04-28T00:53:54.178352Z","iopub.status.idle":"2023-04-28T00:53:54.429765Z","shell.execute_reply.started":"2023-04-28T00:53:54.178314Z","shell.execute_reply":"2023-04-28T00:53:54.428732Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                path  label\n0      train_landmark_files/26734/1000035562.parquet     25\n1      train_landmark_files/28656/1000106739.parquet    232\n2       train_landmark_files/16069/100015657.parquet     48\n3      train_landmark_files/25571/1000210073.parquet     23\n4      train_landmark_files/62590/1000240708.parquet    164\n...                                              ...    ...\n94472   train_landmark_files/53618/999786174.parquet    238\n94473   train_landmark_files/26734/999799849.parquet    108\n94474   train_landmark_files/25571/999833418.parquet     86\n94475   train_landmark_files/29302/999895257.parquet    188\n94476   train_landmark_files/36257/999962374.parquet    105\n\n[94477 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmark_files/26734/1000035562.parquet</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmark_files/28656/1000106739.parquet</td>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmark_files/16069/100015657.parquet</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmark_files/25571/1000210073.parquet</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmark_files/62590/1000240708.parquet</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94472</th>\n      <td>train_landmark_files/53618/999786174.parquet</td>\n      <td>238</td>\n    </tr>\n    <tr>\n      <th>94473</th>\n      <td>train_landmark_files/26734/999799849.parquet</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>94474</th>\n      <td>train_landmark_files/25571/999833418.parquet</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>94475</th>\n      <td>train_landmark_files/29302/999895257.parquet</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>94476</th>\n      <td>train_landmark_files/36257/999962374.parquet</td>\n      <td>105</td>\n    </tr>\n  </tbody>\n</table>\n<p>94477 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def flattenData(path):\n    df = pd.read_parquet(path)\n    df = pad_or_truncate(df)\n    flatten = df.to_numpy().flatten()\n    return flatten\n\ndef pad_or_truncate(data):\n    if len(data)>50:\n        return truncate_start(data)\n    elif len(data)<50:\n        return pad_end(data)\n    else:\n        return data\ndef pad_end(data):\n    rows_to_add = 50 - len(data)\n    padded_data = {}\n    for column in data.columns:\n        padded_data[column] = [0] * rows_to_add\n    return data.append(pd.DataFrame(padded_data))\n\ndef truncate_start(data):\n    return data.iloc[:50, :]","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:53:58.810272Z","iopub.execute_input":"2023-04-28T00:53:58.810643Z","iopub.status.idle":"2023-04-28T00:53:58.819602Z","shell.execute_reply.started":"2023-04-28T00:53:58.810611Z","shell.execute_reply":"2023-04-28T00:53:58.818319Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ny = train['label'].values\nX = np.stack([flattenData(\"/kaggle/input/pca-data/pca_files/\"+i) for i in tqdm(train['path'])])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:54:00.976159Z","iopub.execute_input":"2023-04-28T00:54:00.976535Z","iopub.status.idle":"2023-04-28T01:10:39.979191Z","shell.execute_reply.started":"2023-04-28T00:54:00.976500Z","shell.execute_reply":"2023-04-28T01:10:39.978111Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 94477/94477 [16:38<00:00, 94.60it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:36:49.456273Z","iopub.execute_input":"2023-04-28T01:36:49.457004Z","iopub.status.idle":"2023-04-28T01:36:49.619757Z","shell.execute_reply.started":"2023-04-28T01:36:49.456963Z","shell.execute_reply":"2023-04-28T01:36:49.618591Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"X_train = torch.FloatTensor(X_train).to(DEVICE)\nX_test = torch.FloatTensor(X_test).to(DEVICE)\ny_train = torch.tensor(y_train).to(DEVICE)\ny_test = torch.tensor(y_test).to(DEVICE)\nprint(\"X shape: \",X.shape)\nprint(\"Y shape: \",y.shape)\nprint(\"X_train shape: \",X_train.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"X_test shape: \",X_test.shape)\nprint(\"y_test shape: \",y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:36:51.911578Z","iopub.execute_input":"2023-04-28T01:36:51.912318Z","iopub.status.idle":"2023-04-28T01:36:52.176561Z","shell.execute_reply.started":"2023-04-28T01:36:51.912279Z","shell.execute_reply":"2023-04-28T01:36:52.175320Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"X shape:  (94477, 650)\nY shape:  (94477,)\nX_train shape:  torch.Size([85029, 650])\ny_train shape:  torch.Size([85029])\nX_test shape:  torch.Size([9448, 650])\ny_test shape:  torch.Size([9448])\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:36:54.932020Z","iopub.execute_input":"2023-04-28T01:36:54.932671Z","iopub.status.idle":"2023-04-28T01:36:54.945922Z","shell.execute_reply.started":"2023-04-28T01:36:54.932615Z","shell.execute_reply":"2023-04-28T01:36:54.944830Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([[  8.8263,  -3.0656,  11.8574,  ...,   0.0000,   0.0000,   0.0000],\n        [ 19.7643,   9.8388,  -4.0689,  ...,   0.0000,   0.0000,   0.0000],\n        [-11.2891,   1.5575,  -6.3298,  ...,   0.0000,   0.0000,   0.0000],\n        ...,\n        [ 16.3869,   7.6579,   1.6181,  ...,   0.0000,   0.0000,   0.0000],\n        [ 12.3552,  -4.7865,   4.8455,  ...,  -0.2096,  -0.4664,  -0.3443],\n        [ 19.1033,   5.9618,  -0.5345,  ...,   0.0000,   0.0000,   0.0000]],\n       device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"batch_size=256\ntrain_loader = DataLoader(dataset = TensorDataset(X_train,y_train),batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(dataset = TensorDataset(X_test,y_test) ,batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:36:58.412424Z","iopub.execute_input":"2023-04-28T01:36:58.413123Z","iopub.status.idle":"2023-04-28T01:36:58.418555Z","shell.execute_reply.started":"2023-04-28T01:36:58.413084Z","shell.execute_reply":"2023-04-28T01:36:58.417456Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self,n_layers, nodes_list):\n        super(FeedForward, self).__init__()\n        self.n_layers = n_layers\n        self.nodes_list = nodes_list\n        \n        \n        \n        \n        self.layers = nn.ModuleList()\n        \n        \n        for i in range(n_layers-2):\n            self.layers.append(nn.Linear(self.nodes_list[i], self.nodes_list[i+1]))\n            self.layers.append(nn.ReLU())\n        \n        self.layers.append(nn.Linear(self.nodes_list[-2],self.nodes_list[-1]))\n        \n        \n        \n    def forward(self, x):\n        \n        for layer in self.layers:\n            x = layer(x)\n        \n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:12:43.812455Z","iopub.execute_input":"2023-04-28T01:12:43.813424Z","iopub.status.idle":"2023-04-28T01:12:43.821474Z","shell.execute_reply.started":"2023-04-28T01:12:43.813384Z","shell.execute_reply":"2023-04-28T01:12:43.820171Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\nnum_classes = 250\n\n\none_layer_model64 = FeedForward(n_layers=3, nodes_list = [X_train.shape[1],64,num_classes]).to(device)\none_layer_model128 = FeedForward(n_layers=3, nodes_list = [X_train.shape[1],128,num_classes]).to(device)\ntwo_layer_model64 = FeedForward(n_layers=4, nodes_list = [X_train.shape[1],64,64,num_classes]).to(device)\ntwo_layer_model128 = FeedForward(n_layers=4, nodes_list = [X_train.shape[1],128,128,num_classes]).to(device)\n\ncuston = FeedForward(n_layers=8, nodes_list = [X_train.shape[1],128,128,256,256,128,128,num_classes]).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:12:51.455750Z","iopub.execute_input":"2023-04-28T01:12:51.456701Z","iopub.status.idle":"2023-04-28T01:12:51.482933Z","shell.execute_reply.started":"2023-04-28T01:12:51.456624Z","shell.execute_reply":"2023-04-28T01:12:51.482006Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#method to train the model object passed\ndef train(model):\n    \n    epochs = 100\n    lr = 0.001\n    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n    criterion = nn.CrossEntropyLoss()\n    \n    train_losses = []\n    val_losses = []\n    train_acc = []\n    val_acc = []\n    best_val_loss = float('inf')\n    for epoch in range(epochs):\n        train_loss = 0\n        train_acc = 0\n        for data, labels in train_loader:\n            \n            \n\n            outputs = model(data)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            _, preds = torch.max(outputs, 1)\n            train_loss += loss.item()\n\n            train_acc += torch.sum(preds == labels.data) \n\n        train_loss = train_loss / (len(train_loader)*batch_size)\n        train_losses.append(train_loss)\n\n        # Validation phase\n\n        val_loss = 0.0\n        val_acc = 0.0\n        with torch.no_grad():\n            for val_data, val_labels in val_loader:\n                val_outputs = model(val_data)\n                loss = criterion(val_outputs, val_labels)\n                val_loss += loss.item()\n                _, gt = torch.max(val_outputs, 1)\n                val_acc += torch.sum(val_labels.data == gt)\n            val_loss = val_loss / (len(val_loader)*batch_size)\n            val_losses.append(val_loss)\n            val_acc = val_acc/ (len(val_loader)*batch_size)\n\n        # Update best model based on validation loss\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model = copy.deepcopy(model.state_dict())\n\n        # Print training progress\n        if (epoch+1)%10==0:\n            print('Epoch [%d/%d], Train Loss: %.4f, Val Loss: %.4f, Val acc: %.4f'\n                  % (epoch+1, epochs, train_loss, val_loss, val_acc))\n        \n    return best_model, train_losses, val_losses\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:22:11.096678Z","iopub.execute_input":"2023-04-28T00:22:11.097895Z","iopub.status.idle":"2023-04-28T00:22:11.111969Z","shell.execute_reply.started":"2023-04-28T00:22:11.097845Z","shell.execute_reply":"2023-04-28T00:22:11.110279Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"best_model1, train_losses1, val_losses1 = train(one_layer_model64)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:22:29.595260Z","iopub.execute_input":"2023-04-28T00:22:29.595987Z","iopub.status.idle":"2023-04-28T00:25:24.441699Z","shell.execute_reply.started":"2023-04-28T00:22:29.595936Z","shell.execute_reply":"2023-04-28T00:25:24.440260Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"  0%|          | 252/94477 [17:10<107:03:58,  4.09s/it]\n  0%|          | 257/94477 [17:15<105:27:22,  4.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/100], Train Loss: 0.0201, Val Loss: 0.0223, Val acc: 0.0073\nEpoch [20/100], Train Loss: 0.0196, Val Loss: 0.0229, Val acc: 0.0078\nEpoch [30/100], Train Loss: 0.0194, Val Loss: 0.0232, Val acc: 0.0072\nEpoch [40/100], Train Loss: 0.0192, Val Loss: 0.0235, Val acc: 0.0088\nEpoch [50/100], Train Loss: 0.0191, Val Loss: 0.0237, Val acc: 0.0082\nEpoch [60/100], Train Loss: 0.0190, Val Loss: 0.0239, Val acc: 0.0088\nEpoch [70/100], Train Loss: 0.0189, Val Loss: 0.0240, Val acc: 0.0073\nEpoch [80/100], Train Loss: 0.0189, Val Loss: 0.0242, Val acc: 0.0075\nEpoch [90/100], Train Loss: 0.0188, Val Loss: 0.0244, Val acc: 0.0077\nEpoch [100/100], Train Loss: 0.0188, Val Loss: 0.0245, Val acc: 0.0087\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model2, train_losses2, val_losses2 = train(two_layer_model64)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:35:22.293745Z","iopub.execute_input":"2023-04-28T00:35:22.294564Z","iopub.status.idle":"2023-04-28T00:38:25.951318Z","shell.execute_reply.started":"2023-04-28T00:35:22.294506Z","shell.execute_reply":"2023-04-28T00:38:25.950190Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch [10/100], Train Loss: 0.0200, Val Loss: 0.0219, Val acc: 0.0095\nEpoch [20/100], Train Loss: 0.0194, Val Loss: 0.0227, Val acc: 0.0095\nEpoch [30/100], Train Loss: 0.0190, Val Loss: 0.0233, Val acc: 0.0083\nEpoch [40/100], Train Loss: 0.0188, Val Loss: 0.0238, Val acc: 0.0093\nEpoch [50/100], Train Loss: 0.0186, Val Loss: 0.0242, Val acc: 0.0096\nEpoch [60/100], Train Loss: 0.0185, Val Loss: 0.0246, Val acc: 0.0100\nEpoch [70/100], Train Loss: 0.0184, Val Loss: 0.0251, Val acc: 0.0086\nEpoch [80/100], Train Loss: 0.0183, Val Loss: 0.0252, Val acc: 0.0092\nEpoch [90/100], Train Loss: 0.0182, Val Loss: 0.0257, Val acc: 0.0090\nEpoch [100/100], Train Loss: 0.0181, Val Loss: 0.0260, Val acc: 0.0094\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model3, train_losses3, val_losses3 = train(one_layer_model128)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:31:49.634175Z","iopub.execute_input":"2023-04-28T00:31:49.634623Z","iopub.status.idle":"2023-04-28T00:35:22.291472Z","shell.execute_reply.started":"2023-04-28T00:31:49.634583Z","shell.execute_reply":"2023-04-28T00:35:22.290038Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch [10/100], Train Loss: 0.0191, Val Loss: 0.0232, Val acc: 0.0071\nEpoch [20/100], Train Loss: 0.0181, Val Loss: 0.0247, Val acc: 0.0071\nEpoch [30/100], Train Loss: 0.0176, Val Loss: 0.0257, Val acc: 0.0067\nEpoch [40/100], Train Loss: 0.0172, Val Loss: 0.0263, Val acc: 0.0070\nEpoch [50/100], Train Loss: 0.0170, Val Loss: 0.0270, Val acc: 0.0064\nEpoch [60/100], Train Loss: 0.0168, Val Loss: 0.0276, Val acc: 0.0062\nEpoch [70/100], Train Loss: 0.0167, Val Loss: 0.0281, Val acc: 0.0064\nEpoch [80/100], Train Loss: 0.0165, Val Loss: 0.0286, Val acc: 0.0069\nEpoch [90/100], Train Loss: 0.0164, Val Loss: 0.0290, Val acc: 0.0069\nEpoch [100/100], Train Loss: 0.0163, Val Loss: 0.0294, Val acc: 0.0063\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model4, train_losses4, val_losses4 = train(two_layer_model128)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:25:56.265482Z","iopub.execute_input":"2023-04-28T00:25:56.265863Z","iopub.status.idle":"2023-04-28T00:29:47.475772Z","shell.execute_reply.started":"2023-04-28T00:25:56.265830Z","shell.execute_reply":"2023-04-28T00:29:47.474313Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch [10/100], Train Loss: 0.0189, Val Loss: 0.0228, Val acc: 0.0079\nEpoch [20/100], Train Loss: 0.0173, Val Loss: 0.0250, Val acc: 0.0077\nEpoch [30/100], Train Loss: 0.0164, Val Loss: 0.0268, Val acc: 0.0077\nEpoch [40/100], Train Loss: 0.0159, Val Loss: 0.0284, Val acc: 0.0078\nEpoch [50/100], Train Loss: 0.0155, Val Loss: 0.0299, Val acc: 0.0078\nEpoch [60/100], Train Loss: 0.0152, Val Loss: 0.0313, Val acc: 0.0077\nEpoch [70/100], Train Loss: 0.0149, Val Loss: 0.0328, Val acc: 0.0072\nEpoch [80/100], Train Loss: 0.0147, Val Loss: 0.0339, Val acc: 0.0062\nEpoch [90/100], Train Loss: 0.0145, Val Loss: 0.0354, Val acc: 0.0074\nEpoch [100/100], Train Loss: 0.0144, Val Loss: 0.0369, Val acc: 0.0069\n","output_type":"stream"}]},{"cell_type":"code","source":"custombest, train_lossescustom, val_lossescustom = train(custon)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:38:48.026751Z","iopub.execute_input":"2023-04-28T00:38:48.027184Z","iopub.status.idle":"2023-04-28T00:43:11.054667Z","shell.execute_reply.started":"2023-04-28T00:38:48.027146Z","shell.execute_reply":"2023-04-28T00:43:11.052467Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch [10/100], Train Loss: 0.0200, Val Loss: 0.0217, Val acc: 0.0111\nEpoch [20/100], Train Loss: 0.0182, Val Loss: 0.0247, Val acc: 0.0091\nEpoch [30/100], Train Loss: 0.0163, Val Loss: 0.0291, Val acc: 0.0086\nEpoch [40/100], Train Loss: 0.0145, Val Loss: 0.0338, Val acc: 0.0080\nEpoch [50/100], Train Loss: 0.0132, Val Loss: 0.0390, Val acc: 0.0070\nEpoch [60/100], Train Loss: 0.0122, Val Loss: 0.0447, Val acc: 0.0069\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1334109274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustombest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lossescustom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_lossescustom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuston\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/2835924087.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"learning_rate = 5e-4\nweight_decay = 1e-1\ncycle = 8\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(custon.parameters(), lr=learning_rate, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cycle, eta_min=learning_rate / 10)\n\ntrain_losses = []\nval_losses = []\n\ndef train_val_loop(epoch, train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, n_offset=1):\n    total_batches = len(train_dataloader)\n    train_size, train_batches = 0, 0\n    train_loss, train_correct = 0, 0\n    val_size, val_batches = 0, 0\n    val_loss, val_correct = 0, 0\n    \n    with tqdm(desc=f'Epoch {epoch+n_offset}', total=total_batches) as bar:\n        \n        # Training\n        for batch, (src, y) in enumerate(train_dataloader):\n            src, y = src.to(device), y.to(device)\n            \n                \n            \n            # Compute prediction and loss\n            pred = model(src)\n            loss = loss_fn(pred, y)\n            \n            # Compute metrics\n            train_loss += loss.item()\n            train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n            train_size += len(y)\n            train_batches += 1\n\n            # Backpropagation\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n            optimizer.step()\n                \n            scheduler.step(epoch + batch / total_batches)\n            \n            # Update progress bar\n            bar.update()\n            bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches,\n                           lr=scheduler.get_last_lr())\n            \n        bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches)\n        \n        #scheduler.step()\n           \n        # Validation\n        with torch.no_grad():\n\n            for batch, (src, y) in enumerate(val_dataloader):\n                src, y = src.to(device), y.to(device)\n                \n                \n                # Compute prediction and loss\n                pred = model(src)\n                val_loss += loss_fn(pred, y).item()\n                \n                # Compute metrics\n                val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n                val_size += len(y)\n                val_batches += 1\n\n                # Update progress bar\n                bar.set_postfix(\n                    accuracy = train_correct / train_size, loss = train_loss / train_batches,\n                    val_accuracy = val_correct / val_size, val_loss = val_loss / val_batches\n                )\n                \n    if scheduler.T_0 - scheduler.T_cur < 0.1:\n        print()\n        \n    train_losses.append(train_loss / train_batches)\n    val_losses.append(val_loss / val_batches)\n\n    return train_correct / train_size, train_loss / train_batches, val_correct / val_size, val_loss / val_batches\n\n\n\n\n\n#model.load_state_dict(saved_state)\n# Iterate through epochs for training\n\n\nbest_loss = float('inf')\nsaved_state = custon.state_dict()\n\nepochs = 300\nfor epoch in range(epochs):\n    acc, loss, v_acc, v_loss = train_val_loop(epoch, train_loader, val_loader, custon, loss_fn, optimizer, scheduler)\n    if v_loss<best_loss:\n        best_loss = v_loss\n        saved_state = custon.state_dict()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:43:59.307156Z","iopub.execute_input":"2023-04-28T00:43:59.307614Z","iopub.status.idle":"2023-04-28T00:53:11.207847Z","shell.execute_reply.started":"2023-04-28T00:43:59.307565Z","shell.execute_reply":"2023-04-28T00:53:11.205973Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 333/333 [00:05<00:00, 65.83it/s, accuracy=0.395, loss=2.59, val_accuracy=0.00804, val_loss=12.2]\nEpoch 2: 100%|██████████| 333/333 [00:05<00:00, 65.11it/s, accuracy=0.416, loss=2.52, val_accuracy=0.0073, val_loss=12.3] \nEpoch 3: 100%|██████████| 333/333 [00:05<00:00, 66.04it/s, accuracy=0.434, loss=2.45, val_accuracy=0.00783, val_loss=12.4]\nEpoch 4: 100%|██████████| 333/333 [00:05<00:00, 61.66it/s, accuracy=0.457, loss=2.38, val_accuracy=0.0073, val_loss=12.7] \nEpoch 5: 100%|██████████| 333/333 [00:05<00:00, 66.15it/s, accuracy=0.484, loss=2.29, val_accuracy=0.00783, val_loss=13]  \nEpoch 6: 100%|██████████| 333/333 [00:05<00:00, 60.73it/s, accuracy=0.505, loss=2.22, val_accuracy=0.00794, val_loss=13.1]\nEpoch 7: 100%|██████████| 333/333 [00:05<00:00, 64.91it/s, accuracy=0.523, loss=2.16, val_accuracy=0.00815, val_loss=13.3]\nEpoch 8: 100%|██████████| 333/333 [00:05<00:00, 62.02it/s, accuracy=0.535, loss=2.13, val_accuracy=0.00847, val_loss=13.4]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 333/333 [00:05<00:00, 64.33it/s, accuracy=0.449, loss=2.39, val_accuracy=0.00847, val_loss=12.6]\nEpoch 10: 100%|██████████| 333/333 [00:05<00:00, 63.69it/s, accuracy=0.443, loss=2.42, val_accuracy=0.00868, val_loss=12.5]\nEpoch 11: 100%|██████████| 333/333 [00:05<00:00, 63.70it/s, accuracy=0.458, loss=2.38, val_accuracy=0.00857, val_loss=12.5]\nEpoch 12: 100%|██████████| 333/333 [00:05<00:00, 59.12it/s, accuracy=0.479, loss=2.31, val_accuracy=0.00815, val_loss=12.7]\nEpoch 13: 100%|██████████| 333/333 [00:05<00:00, 61.09it/s, accuracy=0.504, loss=2.24, val_accuracy=0.00773, val_loss=13]  \nEpoch 14: 100%|██████████| 333/333 [00:05<00:00, 65.11it/s, accuracy=0.525, loss=2.17, val_accuracy=0.00826, val_loss=13.2]\nEpoch 15: 100%|██████████| 333/333 [00:05<00:00, 62.51it/s, accuracy=0.542, loss=2.11, val_accuracy=0.00878, val_loss=13.3]\nEpoch 16: 100%|██████████| 333/333 [00:05<00:00, 62.18it/s, accuracy=0.553, loss=2.08, val_accuracy=0.00868, val_loss=13.5]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 333/333 [00:05<00:00, 60.17it/s, accuracy=0.458, loss=2.36, val_accuracy=0.0091, val_loss=12.5] \nEpoch 18: 100%|██████████| 333/333 [00:05<00:00, 58.67it/s, accuracy=0.452, loss=2.39, val_accuracy=0.00836, val_loss=12.4]\nEpoch 19: 100%|██████████| 333/333 [00:05<00:00, 63.56it/s, accuracy=0.466, loss=2.35, val_accuracy=0.0091, val_loss=12.6] \nEpoch 20: 100%|██████████| 333/333 [00:05<00:00, 63.88it/s, accuracy=0.491, loss=2.28, val_accuracy=0.00878, val_loss=12.8]\nEpoch 21: 100%|██████████| 333/333 [00:05<00:00, 62.23it/s, accuracy=0.514, loss=2.21, val_accuracy=0.00868, val_loss=12.9]\nEpoch 22: 100%|██████████| 333/333 [00:05<00:00, 60.70it/s, accuracy=0.537, loss=2.14, val_accuracy=0.00773, val_loss=13.2]\nEpoch 23: 100%|██████████| 333/333 [00:05<00:00, 64.27it/s, accuracy=0.555, loss=2.08, val_accuracy=0.00794, val_loss=13.3]\nEpoch 24: 100%|██████████| 333/333 [00:05<00:00, 61.10it/s, accuracy=0.565, loss=2.05, val_accuracy=0.00804, val_loss=13.4]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25: 100%|██████████| 333/333 [00:05<00:00, 63.64it/s, accuracy=0.464, loss=2.34, val_accuracy=0.00857, val_loss=12.5]\nEpoch 26: 100%|██████████| 333/333 [00:05<00:00, 63.58it/s, accuracy=0.456, loss=2.38, val_accuracy=0.00921, val_loss=12.4]\nEpoch 27: 100%|██████████| 333/333 [00:05<00:00, 63.32it/s, accuracy=0.469, loss=2.34, val_accuracy=0.00815, val_loss=12.5]\nEpoch 28: 100%|██████████| 333/333 [00:05<00:00, 66.11it/s, accuracy=0.496, loss=2.27, val_accuracy=0.00836, val_loss=12.7]\nEpoch 29: 100%|██████████| 333/333 [00:05<00:00, 63.02it/s, accuracy=0.521, loss=2.19, val_accuracy=0.00794, val_loss=12.9]\nEpoch 30: 100%|██████████| 333/333 [00:05<00:00, 60.05it/s, accuracy=0.543, loss=2.12, val_accuracy=0.00878, val_loss=13.1]\nEpoch 31: 100%|██████████| 333/333 [00:05<00:00, 61.68it/s, accuracy=0.563, loss=2.07, val_accuracy=0.00826, val_loss=13.3]\nEpoch 32: 100%|██████████| 333/333 [00:05<00:00, 65.42it/s, accuracy=0.572, loss=2.03, val_accuracy=0.00847, val_loss=13.4]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33: 100%|██████████| 333/333 [00:05<00:00, 62.60it/s, accuracy=0.466, loss=2.34, val_accuracy=0.00847, val_loss=12.5]\nEpoch 34: 100%|██████████| 333/333 [00:05<00:00, 64.50it/s, accuracy=0.457, loss=2.37, val_accuracy=0.00783, val_loss=12.4]\nEpoch 35: 100%|██████████| 333/333 [00:05<00:00, 60.06it/s, accuracy=0.472, loss=2.33, val_accuracy=0.00794, val_loss=12.4]\nEpoch 36: 100%|██████████| 333/333 [00:05<00:00, 58.93it/s, accuracy=0.498, loss=2.26, val_accuracy=0.00794, val_loss=12.6]\nEpoch 37: 100%|██████████| 333/333 [00:05<00:00, 63.52it/s, accuracy=0.524, loss=2.18, val_accuracy=0.00857, val_loss=12.8]\nEpoch 38: 100%|██████████| 333/333 [00:05<00:00, 64.48it/s, accuracy=0.55, loss=2.11, val_accuracy=0.00868, val_loss=13]  \nEpoch 39: 100%|██████████| 333/333 [00:05<00:00, 63.91it/s, accuracy=0.568, loss=2.05, val_accuracy=0.00794, val_loss=13.3]\nEpoch 40: 100%|██████████| 333/333 [00:05<00:00, 61.81it/s, accuracy=0.578, loss=2.02, val_accuracy=0.00836, val_loss=13.3]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|██████████| 333/333 [00:05<00:00, 62.28it/s, accuracy=0.468, loss=2.33, val_accuracy=0.00931, val_loss=12.4]\nEpoch 42: 100%|██████████| 333/333 [00:05<00:00, 61.23it/s, accuracy=0.456, loss=2.38, val_accuracy=0.00751, val_loss=12.3]\nEpoch 43: 100%|██████████| 333/333 [00:05<00:00, 62.06it/s, accuracy=0.474, loss=2.33, val_accuracy=0.00804, val_loss=12.5]\nEpoch 44: 100%|██████████| 333/333 [00:05<00:00, 63.59it/s, accuracy=0.5, loss=2.26, val_accuracy=0.00741, val_loss=12.5]\nEpoch 45: 100%|██████████| 333/333 [00:05<00:00, 66.37it/s, accuracy=0.527, loss=2.18, val_accuracy=0.00815, val_loss=12.8]\nEpoch 46: 100%|██████████| 333/333 [00:05<00:00, 64.70it/s, accuracy=0.552, loss=2.1, val_accuracy=0.00773, val_loss=13]  \nEpoch 47: 100%|██████████| 333/333 [00:05<00:00, 66.58it/s, accuracy=0.571, loss=2.04, val_accuracy=0.0072, val_loss=13.2] \nEpoch 48: 100%|██████████| 333/333 [00:05<00:00, 62.22it/s, accuracy=0.582, loss=2.01, val_accuracy=0.00751, val_loss=13.3]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49: 100%|██████████| 333/333 [00:05<00:00, 61.66it/s, accuracy=0.466, loss=2.33, val_accuracy=0.00889, val_loss=12.5]\nEpoch 50: 100%|██████████| 333/333 [00:05<00:00, 65.31it/s, accuracy=0.454, loss=2.38, val_accuracy=0.00836, val_loss=12.2]\nEpoch 51: 100%|██████████| 333/333 [00:05<00:00, 63.40it/s, accuracy=0.473, loss=2.33, val_accuracy=0.00751, val_loss=12.3]\nEpoch 52: 100%|██████████| 333/333 [00:05<00:00, 63.05it/s, accuracy=0.499, loss=2.26, val_accuracy=0.00794, val_loss=12.4]\nEpoch 53: 100%|██████████| 333/333 [00:05<00:00, 59.64it/s, accuracy=0.528, loss=2.18, val_accuracy=0.00804, val_loss=12.7]\nEpoch 54: 100%|██████████| 333/333 [00:05<00:00, 58.41it/s, accuracy=0.554, loss=2.1, val_accuracy=0.00773, val_loss=12.9]\nEpoch 55: 100%|██████████| 333/333 [00:05<00:00, 63.74it/s, accuracy=0.574, loss=2.04, val_accuracy=0.00804, val_loss=13.1]\nEpoch 56: 100%|██████████| 333/333 [00:05<00:00, 64.16it/s, accuracy=0.585, loss=2, val_accuracy=0.0072, val_loss=13.2] \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57: 100%|██████████| 333/333 [00:05<00:00, 61.47it/s, accuracy=0.468, loss=2.34, val_accuracy=0.00751, val_loss=12.3]\nEpoch 58: 100%|██████████| 333/333 [00:05<00:00, 60.19it/s, accuracy=0.454, loss=2.38, val_accuracy=0.00741, val_loss=12.1]\nEpoch 59: 100%|██████████| 333/333 [00:05<00:00, 61.06it/s, accuracy=0.472, loss=2.34, val_accuracy=0.00783, val_loss=12.2]\nEpoch 60: 100%|██████████| 333/333 [00:05<00:00, 63.46it/s, accuracy=0.5, loss=2.26, val_accuracy=0.00709, val_loss=12.4]\nEpoch 61: 100%|██████████| 333/333 [00:05<00:00, 63.75it/s, accuracy=0.529, loss=2.17, val_accuracy=0.00709, val_loss=12.7]\nEpoch 62: 100%|██████████| 333/333 [00:05<00:00, 61.93it/s, accuracy=0.556, loss=2.1, val_accuracy=0.00709, val_loss=12.9]\nEpoch 63: 100%|██████████| 333/333 [00:05<00:00, 64.94it/s, accuracy=0.576, loss=2.03, val_accuracy=0.00751, val_loss=13]  \nEpoch 64: 100%|██████████| 333/333 [00:05<00:00, 59.25it/s, accuracy=0.587, loss=2, val_accuracy=0.0073, val_loss=13.1] \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 65: 100%|██████████| 333/333 [00:05<00:00, 61.21it/s, accuracy=0.465, loss=2.34, val_accuracy=0.00667, val_loss=12.2]\nEpoch 66: 100%|██████████| 333/333 [00:05<00:00, 63.77it/s, accuracy=0.452, loss=2.39, val_accuracy=0.00804, val_loss=11.9]\nEpoch 67: 100%|██████████| 333/333 [00:05<00:00, 61.78it/s, accuracy=0.47, loss=2.34, val_accuracy=0.0073, val_loss=12.1] \nEpoch 68: 100%|██████████| 333/333 [00:05<00:00, 66.60it/s, accuracy=0.5, loss=2.26, val_accuracy=0.00815, val_loss=12.2]\nEpoch 69: 100%|██████████| 333/333 [00:04<00:00, 67.19it/s, accuracy=0.53, loss=2.18, val_accuracy=0.00773, val_loss=12.5]\nEpoch 70: 100%|██████████| 333/333 [00:05<00:00, 65.10it/s, accuracy=0.557, loss=2.09, val_accuracy=0.00804, val_loss=12.7]\nEpoch 71: 100%|██████████| 333/333 [00:05<00:00, 60.25it/s, accuracy=0.578, loss=2.03, val_accuracy=0.0073, val_loss=12.9] \nEpoch 72: 100%|██████████| 333/333 [00:05<00:00, 65.98it/s, accuracy=0.589, loss=1.99, val_accuracy=0.0072, val_loss=13]   \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 73: 100%|██████████| 333/333 [00:05<00:00, 66.44it/s, accuracy=0.463, loss=2.34, val_accuracy=0.00826, val_loss=12]  \nEpoch 74: 100%|██████████| 333/333 [00:05<00:00, 66.00it/s, accuracy=0.451, loss=2.39, val_accuracy=0.00889, val_loss=12]  \nEpoch 75: 100%|██████████| 333/333 [00:05<00:00, 65.55it/s, accuracy=0.469, loss=2.35, val_accuracy=0.00741, val_loss=12]  \nEpoch 76: 100%|██████████| 333/333 [00:05<00:00, 63.06it/s, accuracy=0.498, loss=2.27, val_accuracy=0.00741, val_loss=12.2]\nEpoch 77: 100%|██████████| 333/333 [00:05<00:00, 61.67it/s, accuracy=0.529, loss=2.18, val_accuracy=0.00804, val_loss=12.4]\nEpoch 78: 100%|██████████| 333/333 [00:05<00:00, 64.11it/s, accuracy=0.558, loss=2.09, val_accuracy=0.00794, val_loss=12.7]\nEpoch 79: 100%|██████████| 333/333 [00:05<00:00, 65.03it/s, accuracy=0.577, loss=2.03, val_accuracy=0.0072, val_loss=12.9] \nEpoch 80: 100%|██████████| 333/333 [00:05<00:00, 64.62it/s, accuracy=0.59, loss=1.99, val_accuracy=0.00773, val_loss=13]  \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81: 100%|██████████| 333/333 [00:05<00:00, 64.88it/s, accuracy=0.462, loss=2.35, val_accuracy=0.00741, val_loss=12]  \nEpoch 82: 100%|██████████| 333/333 [00:05<00:00, 65.84it/s, accuracy=0.449, loss=2.4, val_accuracy=0.00762, val_loss=12]  \nEpoch 83: 100%|██████████| 333/333 [00:05<00:00, 63.48it/s, accuracy=0.467, loss=2.35, val_accuracy=0.00667, val_loss=11.9]\nEpoch 84: 100%|██████████| 333/333 [00:05<00:00, 62.75it/s, accuracy=0.497, loss=2.27, val_accuracy=0.00741, val_loss=12.2]\nEpoch 85: 100%|██████████| 333/333 [00:05<00:00, 62.46it/s, accuracy=0.53, loss=2.18, val_accuracy=0.00667, val_loss=12.4]\nEpoch 86: 100%|██████████| 333/333 [00:05<00:00, 65.04it/s, accuracy=0.558, loss=2.09, val_accuracy=0.00773, val_loss=12.6]\nEpoch 87: 100%|██████████| 333/333 [00:05<00:00, 64.17it/s, accuracy=0.579, loss=2.03, val_accuracy=0.00773, val_loss=12.8]\nEpoch 88: 100%|██████████| 333/333 [00:05<00:00, 64.26it/s, accuracy=0.59, loss=1.99, val_accuracy=0.0072, val_loss=12.9] \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 89: 100%|██████████| 333/333 [00:05<00:00, 60.87it/s, accuracy=0.46, loss=2.36, val_accuracy=0.00826, val_loss=11.9]\nEpoch 90: 100%|██████████| 333/333 [00:05<00:00, 64.93it/s, accuracy=0.445, loss=2.41, val_accuracy=0.00826, val_loss=11.8]\nEpoch 91: 100%|██████████| 333/333 [00:05<00:00, 64.96it/s, accuracy=0.466, loss=2.36, val_accuracy=0.0072, val_loss=11.8] \nEpoch 92: 100%|██████████| 333/333 [00:05<00:00, 65.97it/s, accuracy=0.496, loss=2.28, val_accuracy=0.00709, val_loss=12]  \nEpoch 93: 100%|██████████| 333/333 [00:05<00:00, 65.41it/s, accuracy=0.528, loss=2.18, val_accuracy=0.00857, val_loss=12.3]\nEpoch 94: 100%|██████████| 333/333 [00:05<00:00, 59.32it/s, accuracy=0.557, loss=2.09, val_accuracy=0.00783, val_loss=12.5]\nEpoch 95: 100%|██████████| 333/333 [00:05<00:00, 63.50it/s, accuracy=0.579, loss=2.03, val_accuracy=0.00794, val_loss=12.7]\nEpoch 96: 100%|██████████| 333/333 [00:05<00:00, 63.44it/s, accuracy=0.591, loss=1.99, val_accuracy=0.00783, val_loss=12.8]\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 97: 100%|██████████| 333/333 [00:05<00:00, 66.11it/s, accuracy=0.459, loss=2.36, val_accuracy=0.00762, val_loss=11.8]\nEpoch 98: 100%|██████████| 333/333 [00:05<00:00, 61.53it/s, accuracy=0.445, loss=2.42, val_accuracy=0.00815, val_loss=11.8]\nEpoch 99: 100%|██████████| 333/333 [00:05<00:00, 63.55it/s, accuracy=0.463, loss=2.36, val_accuracy=0.00826, val_loss=11.8]\nEpoch 100: 100%|██████████| 333/333 [00:05<00:00, 64.61it/s, accuracy=0.494, loss=2.28, val_accuracy=0.00804, val_loss=12.1]\nEpoch 101: 100%|██████████| 333/333 [00:05<00:00, 66.32it/s, accuracy=0.528, loss=2.18, val_accuracy=0.00677, val_loss=12.3]\nEpoch 102: 100%|██████████| 333/333 [00:05<00:00, 60.57it/s, accuracy=0.558, loss=2.09, val_accuracy=0.00762, val_loss=12.4]\nEpoch 103: 100%|██████████| 333/333 [00:05<00:00, 61.51it/s, accuracy=0.58, loss=2.03, val_accuracy=0.00709, val_loss=12.6]\nEpoch 104: 100%|██████████| 333/333 [00:05<00:00, 65.51it/s, accuracy=0.592, loss=1.98, val_accuracy=0.0072, val_loss=12.8] \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Epoch 105:  67%|██████▋   | 224/333 [00:03<00:01, 68.50it/s, accuracy=0.479, loss=2.3, lr=[0.0004922644854837775]] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/4284166686.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuston\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mv_loss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/4284166686.py\u001b[0m in \u001b[0;36mtrain_val_loop\u001b[0;34m(epoch, train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, n_offset)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3106547309.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn.functional as F\ndef define_model(trial):\n    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n    layers = []\n\n    in_features = 650\n    for i in range(n_layers):\n        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n        layers.append(nn.Linear(in_features, out_features))\n        layers.append(nn.ReLU())\n        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n        layers.append(nn.Dropout(p))\n\n        in_features = out_features\n    layers.append(nn.Linear(in_features, 250))\n    layers.append(nn.LogSoftmax(dim=1))\n\n    return nn.Sequential(*layers)\n\ndef objective(trial):\n    # Generate the model.\n    model = define_model(trial).to(DEVICE)\n\n    # Generate the optimizers.\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n\n    # Get the FashionMNIST dataset.\n    \n\n    # Training of the model.\n    for epoch in range(100):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            \n\n            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n\n        # Validation of the model.\n        model.eval()\n        correct = 0\n        with torch.no_grad():\n            for batch_idx, (data, target) in enumerate(val_loader):\n                \n                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n                output = model(data)\n                # Get the index of the max log-probability.\n                pred = output.argmax(dim=1, keepdim=True)\n                correct += pred.eq(target.view_as(pred)).sum().item()\n\n        accuracy = correct / (len(val_loader.dataset))\n\n        trial.report(accuracy, epoch)\n\n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n    return accuracy\n\n\nif __name__ == \"__main__\":\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=100, timeout=600)\n\n    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n\n    print(\"Study statistics: \")\n    print(\"  Number of finished trials: \", len(study.trials))\n    print(\"  Number of pruned trials: \", len(pruned_trials))\n    print(\"  Number of complete trials: \", len(complete_trials))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: \", trial.value)\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:37:10.598073Z","iopub.execute_input":"2023-04-28T01:37:10.598457Z","iopub.status.idle":"2023-04-28T01:48:26.057402Z","shell.execute_reply.started":"2023-04-28T01:37:10.598422Z","shell.execute_reply":"2023-04-28T01:48:26.056313Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-04-28 01:37:10,613]\u001b[0m A new study created in memory with name: no-name-92298d23-32bb-41f4-9e33-5c19eee3a697\u001b[0m\n\u001b[32m[I 2023-04-28 01:38:47,264]\u001b[0m Trial 0 finished with value: 0.0060330228619813716 and parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.2035279888018733, 'optimizer': 'Adam', 'lr': 0.0068110790235364205}. Best is trial 0 with value: 0.0060330228619813716.\u001b[0m\n\u001b[32m[I 2023-04-28 01:40:19,031]\u001b[0m Trial 1 finished with value: 0.0034928027095681626 and parameters: {'n_layers': 2, 'n_units_l0': 109, 'dropout_l0': 0.32153480665931067, 'n_units_l1': 7, 'dropout_l1': 0.39578128187000106, 'optimizer': 'SGD', 'lr': 0.009221309986333685}. Best is trial 0 with value: 0.0060330228619813716.\u001b[0m\n\u001b[32m[I 2023-04-28 01:41:58,367]\u001b[0m Trial 2 finished with value: 0.004022015241320914 and parameters: {'n_layers': 2, 'n_units_l0': 128, 'dropout_l0': 0.3414935840406287, 'n_units_l1': 77, 'dropout_l1': 0.3255424802484055, 'optimizer': 'RMSprop', 'lr': 0.06580264442519955}. Best is trial 0 with value: 0.0060330228619813716.\u001b[0m\n\u001b[32m[I 2023-04-28 01:43:36,222]\u001b[0m Trial 3 finished with value: 0.003810330228619814 and parameters: {'n_layers': 3, 'n_units_l0': 22, 'dropout_l0': 0.46466218943977805, 'n_units_l1': 67, 'dropout_l1': 0.288579321723267, 'n_units_l2': 102, 'dropout_l2': 0.39723517935087327, 'optimizer': 'SGD', 'lr': 1.7680533619859227e-05}. Best is trial 0 with value: 0.0060330228619813716.\u001b[0m\n\u001b[32m[I 2023-04-28 01:45:14,255]\u001b[0m Trial 4 finished with value: 0.0047629127857747675 and parameters: {'n_layers': 3, 'n_units_l0': 25, 'dropout_l0': 0.35969534233593614, 'n_units_l1': 22, 'dropout_l1': 0.3092223037816212, 'n_units_l2': 5, 'dropout_l2': 0.278635655610574, 'optimizer': 'SGD', 'lr': 1.2353011200221342e-05}. Best is trial 0 with value: 0.0060330228619813716.\u001b[0m\n\u001b[32m[I 2023-04-28 01:46:45,239]\u001b[0m Trial 5 finished with value: 0.004233700254022015 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.3090107201555557, 'optimizer': 'RMSprop', 'lr': 0.026686575857450316}. Best is trial 0 with value: 0.0060330228619813716.\u001b[0m\n\u001b[32m[I 2023-04-28 01:46:46,101]\u001b[0m Trial 6 pruned. \u001b[0m\n\u001b[32m[I 2023-04-28 01:46:47,137]\u001b[0m Trial 7 pruned. \u001b[0m\n\u001b[32m[I 2023-04-28 01:46:48,077]\u001b[0m Trial 8 pruned. \u001b[0m\n\u001b[32m[I 2023-04-28 01:46:49,178]\u001b[0m Trial 9 pruned. \u001b[0m\n\u001b[32m[I 2023-04-28 01:48:26,049]\u001b[0m Trial 10 finished with value: 0.0073031329381879765 and parameters: {'n_layers': 1, 'n_units_l0': 64, 'dropout_l0': 0.20573955607494795, 'optimizer': 'Adam', 'lr': 0.0025661782346817707}. Best is trial 10 with value: 0.0073031329381879765.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Study statistics: \n  Number of finished trials:  11\n  Number of pruned trials:  4\n  Number of complete trials:  7\nBest trial:\n  Value:  0.0073031329381879765\n  Params: \n    n_layers: 1\n    n_units_l0: 64\n    dropout_l0: 0.20573955607494795\n    optimizer: Adam\n    lr: 0.0025661782346817707\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}