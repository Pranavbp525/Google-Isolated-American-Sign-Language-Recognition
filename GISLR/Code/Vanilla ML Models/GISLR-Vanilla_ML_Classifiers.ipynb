{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0138bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d0fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenData(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df = pad_or_truncate(df)\n",
    "    flatten = df.to_numpy().flatten()\n",
    "    return flatten\n",
    "\n",
    "def pad_or_truncate(data):\n",
    "    if len(data)>50:\n",
    "        return truncate_start(data)\n",
    "    elif len(data)<50:\n",
    "        return pad_end(data)\n",
    "    else:\n",
    "        return data\n",
    "def pad_end(data):\n",
    "    rows_to_add = 50 - len(data)\n",
    "    padded_data = {}\n",
    "    for column in data.columns:\n",
    "        padded_data[column] = [0] * rows_to_add\n",
    "    return data.append(pd.DataFrame(padded_data))\n",
    "\n",
    "def truncate_start(data):\n",
    "    return data.iloc[:50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282d2817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94477"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_files = []\n",
    "for dirname, _, filenames in os.walk('pca_files'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.parquet'):\n",
    "            pca_files.append(os.path.join(dirname, filename))\n",
    "len(pca_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852fe18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pca_files/dataset4/asl-signs/train_landmark_files/4718/1160474191.parquet'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7973b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"final_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc3dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [04:46<00:00, 329.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = train['label'].values\n",
    "X = np.stack([flattenData(\"pca_files/\"+i) for i in tqdm(train['path'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf93d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba651e4d",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d0d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.01153683319220999\n",
      "Confusion Matrix:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.00      0.00      0.00        43\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.01      0.02      0.02        44\n",
      "           5       0.00      0.00      0.00        32\n",
      "           6       0.00      0.00      0.00        31\n",
      "           7       0.00      0.00      0.00        29\n",
      "           8       0.00      0.00      0.00        37\n",
      "           9       0.00      0.00      0.00        38\n",
      "          10       0.02      0.06      0.03        36\n",
      "          11       0.00      0.00      0.00        30\n",
      "          12       0.03      0.02      0.02        47\n",
      "          13       0.00      0.00      0.00        39\n",
      "          14       0.02      0.04      0.03        45\n",
      "          15       0.00      0.00      0.00        32\n",
      "          16       0.00      0.00      0.00        39\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.00      0.00      0.00        33\n",
      "          19       0.00      0.00      0.00        36\n",
      "          20       0.00      0.00      0.00        28\n",
      "          21       0.02      0.09      0.03        34\n",
      "          22       0.00      0.00      0.00        43\n",
      "          23       0.01      0.08      0.03        37\n",
      "          24       0.00      0.00      0.00        36\n",
      "          25       0.00      0.00      0.00        41\n",
      "          26       0.00      0.00      0.00        39\n",
      "          27       0.00      0.00      0.00        39\n",
      "          28       0.00      0.00      0.00        39\n",
      "          29       0.00      0.00      0.00        40\n",
      "          30       0.00      0.00      0.00        29\n",
      "          31       0.02      0.17      0.04        30\n",
      "          32       0.04      0.05      0.05        37\n",
      "          33       0.00      0.00      0.00        45\n",
      "          34       0.00      0.00      0.00        35\n",
      "          35       0.00      0.00      0.00        38\n",
      "          36       0.00      0.00      0.00        24\n",
      "          37       0.00      0.00      0.00        46\n",
      "          38       0.00      0.00      0.00        42\n",
      "          39       0.00      0.00      0.00        26\n",
      "          40       0.00      0.00      0.00        39\n",
      "          41       0.00      0.00      0.00        42\n",
      "          42       0.00      0.00      0.00        38\n",
      "          43       0.00      0.00      0.00        30\n",
      "          44       0.00      0.00      0.00        40\n",
      "          45       0.00      0.00      0.00        40\n",
      "          46       0.00      0.00      0.00        49\n",
      "          47       0.03      0.07      0.04        40\n",
      "          48       0.00      0.00      0.00        46\n",
      "          49       0.03      0.10      0.04        39\n",
      "          50       0.00      0.00      0.00        42\n",
      "          51       0.00      0.00      0.00        41\n",
      "          52       0.02      0.02      0.02        46\n",
      "          53       0.00      0.00      0.00        34\n",
      "          54       0.00      0.00      0.00        43\n",
      "          55       0.00      0.00      0.00        31\n",
      "          56       0.00      0.00      0.00        32\n",
      "          57       0.00      0.00      0.00        25\n",
      "          58       0.00      0.00      0.00        32\n",
      "          59       0.03      0.04      0.04        47\n",
      "          60       0.01      0.04      0.02        47\n",
      "          61       0.00      0.00      0.00        32\n",
      "          62       0.00      0.00      0.00        33\n",
      "          63       0.04      0.03      0.03        38\n",
      "          64       0.00      0.00      0.00        42\n",
      "          65       0.01      0.03      0.02        30\n",
      "          66       0.00      0.00      0.00        43\n",
      "          67       0.02      0.03      0.02        35\n",
      "          68       0.00      0.00      0.00        35\n",
      "          69       0.00      0.00      0.00        31\n",
      "          70       0.00      0.00      0.00        40\n",
      "          71       0.00      0.00      0.00        43\n",
      "          72       0.00      0.00      0.00        51\n",
      "          73       0.03      0.02      0.02        48\n",
      "          74       0.00      0.00      0.00        34\n",
      "          75       0.00      0.00      0.00        28\n",
      "          76       0.00      0.00      0.00        38\n",
      "          77       0.00      0.00      0.00        43\n",
      "          78       0.00      0.00      0.00        27\n",
      "          79       0.00      0.00      0.00        49\n",
      "          80       0.00      0.00      0.00        45\n",
      "          81       0.02      0.03      0.02        37\n",
      "          82       0.00      0.00      0.00        38\n",
      "          83       0.01      0.02      0.01        41\n",
      "          84       0.00      0.00      0.00        30\n",
      "          85       0.00      0.00      0.00        37\n",
      "          86       0.02      0.02      0.02        42\n",
      "          87       0.00      0.00      0.00        42\n",
      "          88       0.00      0.00      0.00        40\n",
      "          89       0.00      0.00      0.00        37\n",
      "          90       0.00      0.00      0.00        31\n",
      "          91       0.00      0.00      0.00        46\n",
      "          92       0.00      0.00      0.00        37\n",
      "          93       0.05      0.06      0.05        36\n",
      "          94       0.00      0.00      0.00        47\n",
      "          95       0.00      0.00      0.00        34\n",
      "          96       0.00      0.00      0.00        40\n",
      "          97       0.01      0.07      0.02        42\n",
      "          98       0.01      0.03      0.01        35\n",
      "          99       0.00      0.00      0.00        39\n",
      "         100       0.00      0.00      0.00        41\n",
      "         101       0.00      0.00      0.00        50\n",
      "         102       0.00      0.00      0.00        43\n",
      "         103       0.03      0.05      0.03        40\n",
      "         104       0.00      0.00      0.00        33\n",
      "         105       0.00      0.00      0.00        36\n",
      "         106       0.00      0.00      0.00        38\n",
      "         107       0.00      0.00      0.00        43\n",
      "         108       0.00      0.00      0.00        38\n",
      "         109       0.00      0.00      0.00        44\n",
      "         110       0.00      0.00      0.00        30\n",
      "         111       0.00      0.00      0.00        32\n",
      "         112       0.00      0.00      0.00        29\n",
      "         113       0.00      0.00      0.00        45\n",
      "         114       0.00      0.00      0.00        37\n",
      "         115       0.00      0.00      0.00        29\n",
      "         116       0.00      0.00      0.00        35\n",
      "         117       0.12      0.02      0.04        44\n",
      "         118       0.03      0.13      0.05        31\n",
      "         119       0.00      0.00      0.00        37\n",
      "         120       0.00      0.00      0.00        36\n",
      "         121       0.00      0.00      0.00        37\n",
      "         122       0.03      0.05      0.04        40\n",
      "         123       0.00      0.00      0.00        32\n",
      "         124       0.00      0.00      0.00        33\n",
      "         125       0.00      0.00      0.00        38\n",
      "         126       0.00      0.00      0.00        34\n",
      "         127       0.00      0.00      0.00        41\n",
      "         128       0.00      0.00      0.00        36\n",
      "         129       0.02      0.02      0.02        41\n",
      "         130       0.00      0.00      0.00        42\n",
      "         131       0.00      0.00      0.00        39\n",
      "         132       0.00      0.00      0.00        35\n",
      "         133       0.03      0.02      0.02        56\n",
      "         134       0.01      0.02      0.02        41\n",
      "         135       0.02      0.02      0.02        48\n",
      "         136       0.00      0.00      0.00        40\n",
      "         137       0.00      0.00      0.00        35\n",
      "         138       0.00      0.00      0.00        39\n",
      "         139       0.00      0.00      0.00        31\n",
      "         140       0.03      0.05      0.03        44\n",
      "         141       0.33      0.03      0.05        34\n",
      "         142       0.00      0.00      0.00        33\n",
      "         143       0.02      0.03      0.02        39\n",
      "         144       0.04      0.11      0.06        54\n",
      "         145       0.25      0.03      0.05        37\n",
      "         146       0.00      0.00      0.00        41\n",
      "         147       0.02      0.03      0.02        37\n",
      "         148       0.01      0.02      0.01        44\n",
      "         149       0.00      0.00      0.00        33\n",
      "         150       0.02      0.03      0.02        39\n",
      "         151       0.00      0.00      0.00        42\n",
      "         152       0.00      0.00      0.00        28\n",
      "         153       0.00      0.00      0.00        35\n",
      "         154       0.00      0.00      0.00        50\n",
      "         155       0.05      0.03      0.04        38\n",
      "         156       0.03      0.20      0.05        41\n",
      "         157       0.00      0.00      0.00        32\n",
      "         158       0.00      0.00      0.00        39\n",
      "         159       0.01      0.03      0.02        34\n",
      "         160       0.00      0.00      0.00        32\n",
      "         161       0.00      0.00      0.00        33\n",
      "         162       0.00      0.00      0.00        46\n",
      "         163       0.03      0.02      0.02        44\n",
      "         164       0.00      0.00      0.00        34\n",
      "         165       0.00      0.00      0.00        39\n",
      "         166       0.00      0.00      0.00        44\n",
      "         167       0.01      0.03      0.02        40\n",
      "         168       0.01      0.03      0.01        40\n",
      "         169       0.00      0.00      0.00        37\n",
      "         170       0.00      0.00      0.00        34\n",
      "         171       0.00      0.00      0.00        30\n",
      "         172       0.00      0.00      0.00        37\n",
      "         173       0.03      0.05      0.03        44\n",
      "         174       0.06      0.02      0.03        41\n",
      "         175       0.00      0.00      0.00        26\n",
      "         176       0.00      0.00      0.00        30\n",
      "         177       0.00      0.00      0.00        49\n",
      "         178       0.00      0.00      0.00        34\n",
      "         179       0.00      0.00      0.00        41\n",
      "         180       0.00      0.00      0.00        41\n",
      "         181       0.06      0.05      0.05        42\n",
      "         182       0.00      0.00      0.00        27\n",
      "         183       0.00      0.00      0.00        38\n",
      "         184       0.00      0.00      0.00        39\n",
      "         185       0.00      0.00      0.00        29\n",
      "         186       0.01      0.02      0.01        46\n",
      "         187       0.00      0.00      0.00        34\n",
      "         188       0.00      0.00      0.00        48\n",
      "         189       0.03      0.03      0.03        36\n",
      "         190       0.00      0.00      0.00        29\n",
      "         191       0.00      0.00      0.00        31\n",
      "         192       0.00      0.00      0.00        31\n",
      "         193       0.00      0.00      0.00        40\n",
      "         194       0.03      0.05      0.03        39\n",
      "         195       0.00      0.00      0.00        33\n",
      "         196       0.00      0.00      0.00        29\n",
      "         197       0.00      0.00      0.00        38\n",
      "         198       0.00      0.00      0.00        36\n",
      "         199       0.00      0.00      0.00        36\n",
      "         200       0.02      0.03      0.02        32\n",
      "         201       0.00      0.00      0.00        33\n",
      "         202       0.00      0.00      0.00        38\n",
      "         203       0.03      0.08      0.04        36\n",
      "         204       0.00      0.00      0.00        36\n",
      "         205       0.00      0.00      0.00        35\n",
      "         206       0.00      0.00      0.00        32\n",
      "         207       0.00      0.00      0.00        34\n",
      "         208       0.00      0.00      0.00        36\n",
      "         209       0.00      0.00      0.00        38\n",
      "         210       0.01      0.03      0.02        34\n",
      "         211       0.00      0.00      0.00        31\n",
      "         212       0.00      0.00      0.00        33\n",
      "         213       0.00      0.00      0.00        46\n",
      "         214       0.00      0.00      0.00        31\n",
      "         215       0.00      0.00      0.00        31\n",
      "         216       0.00      0.00      0.00        37\n",
      "         217       0.00      0.00      0.00        40\n",
      "         218       0.00      0.00      0.00        41\n",
      "         219       0.07      0.02      0.03        48\n",
      "         220       0.00      0.00      0.00        37\n",
      "         221       0.00      0.00      0.00        42\n",
      "         222       0.00      0.00      0.00        30\n",
      "         223       0.00      0.00      0.00        50\n",
      "         224       0.00      0.00      0.00        39\n",
      "         225       0.00      0.00      0.00        40\n",
      "         226       0.00      0.00      0.00        54\n",
      "         227       0.00      0.00      0.00        39\n",
      "         228       0.00      0.00      0.00        43\n",
      "         229       0.00      0.00      0.00        45\n",
      "         230       0.00      0.00      0.00        43\n",
      "         231       0.00      0.00      0.00        22\n",
      "         232       0.00      0.00      0.00        25\n",
      "         233       0.00      0.00      0.00        45\n",
      "         234       0.00      0.00      0.00        30\n",
      "         235       0.02      0.05      0.02        39\n",
      "         236       0.05      0.03      0.04        38\n",
      "         237       0.00      0.00      0.00        36\n",
      "         238       0.04      0.03      0.03        40\n",
      "         239       0.03      0.05      0.04        44\n",
      "         240       0.00      0.00      0.00        40\n",
      "         241       0.00      0.00      0.00        35\n",
      "         242       0.00      0.00      0.00        44\n",
      "         243       0.12      0.02      0.04        42\n",
      "         244       0.00      0.00      0.00        36\n",
      "         245       0.02      0.08      0.03        38\n",
      "         246       0.00      0.00      0.00        35\n",
      "         247       0.00      0.00      0.00        44\n",
      "         248       0.00      0.00      0.00        41\n",
      "         249       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.01      9448\n",
      "   macro avg       0.01      0.01      0.01      9448\n",
      "weighted avg       0.01      0.01      0.01      9448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavtandra/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pranavtandra/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pranavtandra/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "# Compute the classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc133698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc26d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "s2p_map = read_json(os.path.join(\"sign_to_prediction_index_map.json\"))\n",
    "p2s_map = {v: k for k, v in s2p_map.items()}\n",
    "\n",
    "encoder = lambda x: s2p_map.get(x)\n",
    "decoder = lambda x: p2s_map.get(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2843ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d07511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(cm / np.sum(cm, axis=1)[:, None], index = [v for k,v in p2s_map.items()],\n",
    "                     columns = [v for k,v in p2s_map.items()])\n",
    "plt.figure(figsize = (250,250))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('SVM-CM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08ce60",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc9fcd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.009949195596951736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create Random Forest classifier object\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train classifier on training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657f183",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e0f6c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.009208298052497883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a K-NN classifier object\n",
    "clf = KNeighborsClassifier(n_neighbors = 293)\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a9118",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f82651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a Gradient Boosting classifier object\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915dcc9a",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8decbdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.005080440304826418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5834c7f",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcc6bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.006773920406435224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavtandra/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression classifier object\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a11e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavtandra/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create the classifier\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier\n",
    "accuracy = xgb_clf.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86802965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
