{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbcfb51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:07.677663Z",
     "iopub.status.busy": "2023-04-28T00:24:07.676737Z",
     "iopub.status.idle": "2023-04-28T00:24:07.684087Z",
     "shell.execute_reply": "2023-04-28T00:24:07.683004Z",
     "shell.execute_reply.started": "2023-04-28T00:24:07.677612Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88600c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:08.153454Z",
     "iopub.status.busy": "2023-04-28T00:24:08.152958Z",
     "iopub.status.idle": "2023-04-28T00:24:08.160671Z",
     "shell.execute_reply": "2023-04-28T00:24:08.159610Z",
     "shell.execute_reply.started": "2023-04-28T00:24:08.153408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6eff4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:09.121859Z",
     "iopub.status.busy": "2023-04-28T00:24:09.121391Z",
     "iopub.status.idle": "2023-04-28T00:24:09.133603Z",
     "shell.execute_reply": "2023-04-28T00:24:09.132439Z",
     "shell.execute_reply.started": "2023-04-28T00:24:09.121816Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_parquet_file(filename):\n",
    "    return (filename[0].endswith(\".parquet\"))\n",
    "\n",
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \n",
    "        \n",
    "        self.labels = torch.LongTensor(labels).to(device)\n",
    "        self.landmark_filenames = ['/kaggle/input/ml-asl-project/'+x[0] for x in data if is_parquet_file(x)]\n",
    "        self.data = [torch.FloatTensor(pd.read_parquet(path).values).to(device) for path in tqdm(self.landmark_filenames,desc='Loading data', total=len(self.landmark_filenames))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907ba7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:09.693804Z",
     "iopub.status.busy": "2023-04-28T00:24:09.692998Z",
     "iopub.status.idle": "2023-04-28T00:24:10.010972Z",
     "shell.execute_reply": "2023-04-28T00:24:10.009857Z",
     "shell.execute_reply.started": "2023-04-28T00:24:09.693760Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/final-train/final_train.csv\")\n",
    "data = data.drop([\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728d1308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:10.252759Z",
     "iopub.status.busy": "2023-04-28T00:24:10.252227Z",
     "iopub.status.idle": "2023-04-28T00:24:10.266802Z",
     "shell.execute_reply": "2023-04-28T00:24:10.265385Z",
     "shell.execute_reply.started": "2023-04-28T00:24:10.252714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['dataset4/asl-signs/train_landmark_files/26734/1000035562.parquet'],\n",
       "       ['dataset4/asl-signs/train_landmark_files/28656/1000106739.parquet'],\n",
       "       ['dataset4/asl-signs/train_landmark_files/16069/100015657.parquet'],\n",
       "       ...,\n",
       "       ['dataset4/asl-signs/train_landmark_files/25571/999833418.parquet'],\n",
       "       ['dataset4/asl-signs/train_landmark_files/29302/999895257.parquet'],\n",
       "       ['dataset4/asl-signs/train_landmark_files/36257/999962374.parquet']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[\"path\"].values\n",
    "X = X.reshape(-1,1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48e493f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:13.013107Z",
     "iopub.status.busy": "2023-04-28T00:24:13.012735Z",
     "iopub.status.idle": "2023-04-28T00:24:13.020636Z",
     "shell.execute_reply": "2023-04-28T00:24:13.019413Z",
     "shell.execute_reply.started": "2023-04-28T00:24:13.013075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25, 232,  48, ...,  86, 188, 105])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[\"label\"].values\n",
    "#Y = Y.reshape(-1,1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04bd1ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:14.940710Z",
     "iopub.status.busy": "2023-04-28T00:24:14.940270Z",
     "iopub.status.idle": "2023-04-28T00:24:14.959288Z",
     "shell.execute_reply": "2023-04-28T00:24:14.958389Z",
     "shell.execute_reply.started": "2023-04-28T00:24:14.940673Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74578c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:18.257142Z",
     "iopub.status.busy": "2023-04-28T00:24:18.256177Z",
     "iopub.status.idle": "2023-04-28T00:24:18.264501Z",
     "shell.execute_reply": "2023-04-28T00:24:18.263228Z",
     "shell.execute_reply.started": "2023-04-28T00:24:18.257104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (94477, 1)\n",
      "Y shape:  (94477,)\n",
      "X_train shape:  (85029, 1)\n",
      "y_train shape:  (85029,)\n",
      "X_test shape:  (9448, 1)\n",
      "y_test shape:  (9448,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \",X.shape)\n",
    "print(\"Y shape: \",Y.shape)\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_test shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2415062c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:24:20.628895Z",
     "iopub.status.busy": "2023-04-28T00:24:20.628432Z",
     "iopub.status.idle": "2023-04-28T01:11:37.590974Z",
     "shell.execute_reply": "2023-04-28T01:11:37.589360Z",
     "shell.execute_reply.started": "2023-04-28T00:24:20.628860Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 85029/85029 [42:00<00:00, 33.74it/s]\n",
      "Loading data: 100%|██████████| 9448/9448 [05:16<00:00, 29.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = LandmarkDataset(X_train, y_train)\n",
    "val_dataset = LandmarkDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67011e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:13:33.104166Z",
     "iopub.status.busy": "2023-04-28T01:13:33.103401Z",
     "iopub.status.idle": "2023-04-28T01:13:33.206948Z",
     "shell.execute_reply": "2023-04-28T01:13:33.206023Z",
     "shell.execute_reply.started": "2023-04-28T01:13:33.104128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4033,  0.3968,  0.4048,  ...,  0.4906,  0.5191,  0.5397],\n",
       "         [ 0.3956,  0.3968,  0.3964,  ...,  0.4934,  0.5190,  0.5360],\n",
       "         [ 0.3928,  0.3844,  0.3925,  ...,  0.4926,  0.5144,  0.5263],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       "        device='cuda:0'),\n",
       " tensor(168, device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e816a942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:13:38.437805Z",
     "iopub.status.busy": "2023-04-28T01:13:38.437120Z",
     "iopub.status.idle": "2023-04-28T01:13:38.443593Z",
     "shell.execute_reply": "2023-04-28T01:13:38.442162Z",
     "shell.execute_reply.started": "2023-04-28T01:13:38.437767Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)#, num_workers=8, drop_last=False, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=128, shuffle=False)#, num_workers=8, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57a84e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:13:49.411854Z",
     "iopub.status.busy": "2023-04-28T01:13:49.411170Z",
     "iopub.status.idle": "2023-04-28T01:13:49.424070Z",
     "shell.execute_reply": "2023-04-28T01:13:49.423020Z",
     "shell.execute_reply.started": "2023-04-28T01:13:49.411815Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, bidirectional, num_classes, batch_first):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.num_fearturs = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_first = batch_first\n",
    "        self.lstm = nn.LSTM(input_size = num_features, hidden_size = hidden_size, num_layers = num_layers, batch_first = batch_first, bidirectional = bidirectional)\n",
    "        if self.bidirectional:\n",
    "            self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features*2, bias = True),\n",
    "            nn.LayerNorm(num_features*2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(num_features*2, num_features, bias = True),\n",
    "            nn.LayerNorm(num_features),\n",
    "            nn.ReLU(inplace = True)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        if self.bidirectional:\n",
    "            h0 = torch.zeros(self.num_layers*2, x.shape[0], self.hidden_size).to(x.device)\n",
    "            c0 = torch.zeros(self.num_layers*2, x.shape[0], self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(x.device)\n",
    "            c0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49229b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T00:32:16.855712Z",
     "iopub.status.busy": "2023-04-27T00:32:16.855303Z",
     "iopub.status.idle": "2023-04-27T01:39:27.600049Z",
     "shell.execute_reply": "2023-04-27T01:39:27.598964Z",
     "shell.execute_reply.started": "2023-04-27T00:32:16.855679Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 00:32:16,870]\u001b[0m A new study created in memory with name: no-name-86b6c8c2-dded-4686-bf36-f469523ee2e6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.0035, loss=5.52, val_accuracy=0.00349, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:25<00:00, 13.10it/s, accuracy=0.00457, loss=5.51, val_accuracy=0.00646, val_loss=5.5] \n",
      "Epoch 3: 100%|██████████| 333/333 [00:25<00:00, 13.12it/s, accuracy=0.00633, loss=5.49, val_accuracy=0.00635, val_loss=5.49]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:25<00:00, 13.12it/s, accuracy=0.0074, loss=5.45, val_accuracy=0.00931, val_loss=5.34]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.0134, loss=5.21, val_accuracy=0.0145, val_loss=5.14]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:25<00:00, 13.13it/s, accuracy=0.0165, loss=5.11, val_accuracy=0.0189, val_loss=5.11] \n",
      "Epoch 7: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.0205, loss=5.04, val_accuracy=0.0211, val_loss=5.03]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:25<00:00, 13.12it/s, accuracy=0.0232, loss=5, val_accuracy=0.0219, val_loss=5.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:25<00:00, 13.12it/s, accuracy=0.019, loss=5.07, val_accuracy=0.0206, val_loss=5.02]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.0222, loss=4.99, val_accuracy=0.0238, val_loss=4.98]\n",
      "\u001b[32m[I 2023-04-27 00:36:30,827]\u001b[0m Trial 0 finished with value: 4.983493392531936 and parameters: {'hidden_size': 160, 'num_layers': 5}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 96, 'num_layers': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:21<00:00, 15.83it/s, accuracy=0.00339, loss=5.52, val_accuracy=0.0036, val_loss=5.52]  \n",
      "Epoch 2: 100%|██████████| 333/333 [00:21<00:00, 15.81it/s, accuracy=0.0041, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:21<00:00, 15.76it/s, accuracy=0.00387, loss=5.52, val_accuracy=0.00307, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:21<00:00, 15.77it/s, accuracy=0.00407, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:21<00:00, 15.73it/s, accuracy=0.00387, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:21<00:00, 15.75it/s, accuracy=0.00416, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:21<00:00, 15.82it/s, accuracy=0.00389, loss=5.52, val_accuracy=0.00318, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:21<00:00, 15.79it/s, accuracy=0.00422, loss=5.52, val_accuracy=0.00381, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:21<00:00, 15.80it/s, accuracy=0.00407, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:21<00:00, 15.79it/s, accuracy=0.00409, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 00:40:01,865]\u001b[0m Trial 1 finished with value: 5.521474825369345 and parameters: {'hidden_size': 96, 'num_layers': 7}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 96, 'num_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:09<00:00, 33.41it/s, accuracy=0.0042, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:09<00:00, 33.74it/s, accuracy=0.00385, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:09<00:00, 33.68it/s, accuracy=0.00429, loss=5.52, val_accuracy=0.00455, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:09<00:00, 33.69it/s, accuracy=0.00407, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:09<00:00, 33.63it/s, accuracy=0.00534, loss=5.5, val_accuracy=0.00603, val_loss=5.5] \n",
      "Epoch 6: 100%|██████████| 333/333 [00:09<00:00, 33.73it/s, accuracy=0.00597, loss=5.49, val_accuracy=0.00614, val_loss=5.5] \n",
      "Epoch 7: 100%|██████████| 333/333 [00:09<00:00, 33.66it/s, accuracy=0.00715, loss=5.47, val_accuracy=0.00614, val_loss=5.47]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:09<00:00, 33.68it/s, accuracy=0.00826, loss=5.43, val_accuracy=0.00868, val_loss=5.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:09<00:00, 33.74it/s, accuracy=0.00786, loss=5.41, val_accuracy=0.00773, val_loss=5.36]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:09<00:00, 33.68it/s, accuracy=0.0085, loss=5.28, val_accuracy=0.0121, val_loss=5.18]\n",
      "\u001b[32m[I 2023-04-27 00:41:40,838]\u001b[0m Trial 2 finished with value: 5.177524811512715 and parameters: {'hidden_size': 96, 'num_layers': 2}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'num_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:26<00:00, 12.69it/s, accuracy=0.00403, loss=5.52, val_accuracy=0.00561, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:26<00:00, 12.72it/s, accuracy=0.00383, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:26<00:00, 12.73it/s, accuracy=0.00418, loss=5.52, val_accuracy=0.0036, val_loss=5.52] \n",
      "Epoch 4: 100%|██████████| 333/333 [00:26<00:00, 12.75it/s, accuracy=0.00421, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:26<00:00, 12.75it/s, accuracy=0.00428, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:26<00:00, 12.75it/s, accuracy=0.00418, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:26<00:00, 12.70it/s, accuracy=0.00414, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:26<00:00, 12.78it/s, accuracy=0.00439, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:26<00:00, 12.71it/s, accuracy=0.00436, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:26<00:00, 12.72it/s, accuracy=0.00412, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 00:46:02,518]\u001b[0m Trial 3 finished with value: 5.522565777237351 and parameters: {'hidden_size': 128, 'num_layers': 8}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'num_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:08<00:00, 38.54it/s, accuracy=0.00381, loss=5.52, val_accuracy=0.0055, val_loss=5.52] \n",
      "Epoch 2: 100%|██████████| 333/333 [00:08<00:00, 38.58it/s, accuracy=0.00416, loss=5.52, val_accuracy=0.00423, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:08<00:00, 38.63it/s, accuracy=0.00363, loss=5.52, val_accuracy=0.00423, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:08<00:00, 38.54it/s, accuracy=0.00375, loss=5.52, val_accuracy=0.00381, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:08<00:00, 38.58it/s, accuracy=0.00393, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:08<00:00, 38.56it/s, accuracy=0.00413, loss=5.52, val_accuracy=0.00445, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:08<00:00, 38.36it/s, accuracy=0.00445, loss=5.52, val_accuracy=0.00445, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:08<00:00, 38.54it/s, accuracy=0.00472, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:08<00:00, 38.57it/s, accuracy=0.00447, loss=5.52, val_accuracy=0.00381, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:08<00:00, 38.55it/s, accuracy=0.00442, loss=5.52, val_accuracy=0.00497, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 00:47:28,967]\u001b[0m Trial 4 finished with value: 5.519601989436794 and parameters: {'hidden_size': 128, 'num_layers': 1}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 256, 'num_layers': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.00408, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:48<00:00,  6.85it/s, accuracy=0.00418, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.00399, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.00418, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.00427, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:48<00:00,  6.85it/s, accuracy=0.00427, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.00389, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.00401, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:48<00:00,  6.85it/s, accuracy=0.0041, loss=5.52, val_accuracy=0.0036, val_loss=5.52] \n",
      "Epoch 10: 100%|██████████| 333/333 [00:48<00:00,  6.86it/s, accuracy=0.0042, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 00:55:34,734]\u001b[0m Trial 5 finished with value: 5.522268849450189 and parameters: {'hidden_size': 256, 'num_layers': 7}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:09<00:00, 33.57it/s, accuracy=0.00403, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 2: 100%|██████████| 333/333 [00:09<00:00, 33.62it/s, accuracy=0.00376, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 3: 100%|██████████| 333/333 [00:09<00:00, 33.65it/s, accuracy=0.00374, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 4: 100%|██████████| 333/333 [00:09<00:00, 33.62it/s, accuracy=0.0041, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:09<00:00, 33.54it/s, accuracy=0.00455, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:09<00:00, 33.51it/s, accuracy=0.00469, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:09<00:00, 33.51it/s, accuracy=0.00487, loss=5.52, val_accuracy=0.00423, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:09<00:00, 33.57it/s, accuracy=0.00467, loss=5.52, val_accuracy=0.00455, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:09<00:00, 33.55it/s, accuracy=0.00508, loss=5.51, val_accuracy=0.00529, val_loss=5.51]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:09<00:00, 33.37it/s, accuracy=0.00585, loss=5.5, val_accuracy=0.00614, val_loss=5.5] \n",
      "\u001b[32m[I 2023-04-27 00:57:14,042]\u001b[0m Trial 6 finished with value: 5.500430493741422 and parameters: {'hidden_size': 160, 'num_layers': 1}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 192, 'num_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:32<00:00, 10.10it/s, accuracy=0.00406, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 2: 100%|██████████| 333/333 [00:32<00:00, 10.11it/s, accuracy=0.00423, loss=5.52, val_accuracy=0.00307, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:32<00:00, 10.10it/s, accuracy=0.00396, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:32<00:00, 10.13it/s, accuracy=0.00475, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:32<00:00, 10.15it/s, accuracy=0.00457, loss=5.52, val_accuracy=0.00445, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:32<00:00, 10.12it/s, accuracy=0.00453, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:33<00:00, 10.09it/s, accuracy=0.00476, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:32<00:00, 10.10it/s, accuracy=0.00479, loss=5.52, val_accuracy=0.00455, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:33<00:00, 10.08it/s, accuracy=0.00462, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:32<00:00, 10.11it/s, accuracy=0.00483, loss=5.52, val_accuracy=0.00445, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 01:02:43,526]\u001b[0m Trial 7 finished with value: 5.520130299233101 and parameters: {'hidden_size': 192, 'num_layers': 6}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'num_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:08<00:00, 38.46it/s, accuracy=0.00367, loss=5.52, val_accuracy=0.00307, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:08<00:00, 38.50it/s, accuracy=0.00373, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:08<00:00, 38.46it/s, accuracy=0.00367, loss=5.52, val_accuracy=0.00328, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:08<00:00, 38.49it/s, accuracy=0.00403, loss=5.52, val_accuracy=0.00296, val_loss=5.52] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:08<00:00, 38.51it/s, accuracy=0.00459, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:08<00:00, 38.39it/s, accuracy=0.00456, loss=5.52, val_accuracy=0.00349, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:08<00:00, 38.49it/s, accuracy=0.00475, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:08<00:00, 38.63it/s, accuracy=0.00462, loss=5.52, val_accuracy=0.00318, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:08<00:00, 38.61it/s, accuracy=0.00537, loss=5.51, val_accuracy=0.00402, val_loss=5.5] \n",
      "Epoch 10: 100%|██████████| 333/333 [00:08<00:00, 38.42it/s, accuracy=0.00619, loss=5.49, val_accuracy=0.00519, val_loss=5.5] \n",
      "\u001b[32m[I 2023-04-27 01:04:10,080]\u001b[0m Trial 8 finished with value: 5.499425475661819 and parameters: {'hidden_size': 128, 'num_layers': 1}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 192, 'num_layers': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:23<00:00, 14.13it/s, accuracy=0.00401, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 2: 100%|██████████| 333/333 [00:23<00:00, 14.09it/s, accuracy=0.00405, loss=5.52, val_accuracy=0.00349, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:23<00:00, 14.08it/s, accuracy=0.00416, loss=5.52, val_accuracy=0.0055, val_loss=5.52] \n",
      "Epoch 4: 100%|██████████| 333/333 [00:23<00:00, 14.04it/s, accuracy=0.00472, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:23<00:00, 14.03it/s, accuracy=0.00423, loss=5.52, val_accuracy=0.00497, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:23<00:00, 14.10it/s, accuracy=0.00479, loss=5.52, val_accuracy=0.0054, val_loss=5.52] \n",
      "Epoch 7: 100%|██████████| 333/333 [00:23<00:00, 14.13it/s, accuracy=0.00481, loss=5.51, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:23<00:00, 14.08it/s, accuracy=0.00501, loss=5.51, val_accuracy=0.00392, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:23<00:00, 14.14it/s, accuracy=0.00442, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:23<00:00, 14.13it/s, accuracy=0.00497, loss=5.51, val_accuracy=0.00466, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 01:08:06,418]\u001b[0m Trial 9 finished with value: 5.520587315430513 and parameters: {'hidden_size': 192, 'num_layers': 4}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'num_layers': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:10<00:00, 32.96it/s, accuracy=0.00373, loss=5.52, val_accuracy=0.0036, val_loss=5.52] \n",
      "Epoch 2: 100%|██████████| 333/333 [00:10<00:00, 31.83it/s, accuracy=0.00369, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:10<00:00, 32.84it/s, accuracy=0.00454, loss=5.51, val_accuracy=0.00593, val_loss=5.5] \n",
      "Epoch 4: 100%|██████████| 333/333 [00:10<00:00, 32.98it/s, accuracy=0.00565, loss=5.49, val_accuracy=0.00572, val_loss=5.5] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:10<00:00, 31.47it/s, accuracy=0.00569, loss=5.49, val_accuracy=0.00519, val_loss=5.49]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:10<00:00, 32.91it/s, accuracy=0.00699, loss=5.44, val_accuracy=0.00624, val_loss=5.38]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:10<00:00, 33.01it/s, accuracy=0.00882, loss=5.35, val_accuracy=0.00804, val_loss=5.31]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:10<00:00, 30.51it/s, accuracy=0.00982, loss=5.3, val_accuracy=0.00773, val_loss=5.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:10<00:00, 32.80it/s, accuracy=0.00909, loss=5.31, val_accuracy=0.00953, val_loss=5.28]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:10<00:00, 32.64it/s, accuracy=0.0122, loss=5.2, val_accuracy=0.0135, val_loss=5.16] \n",
      "\u001b[32m[I 2023-04-27 01:09:49,335]\u001b[0m Trial 10 finished with value: 5.161530945752118 and parameters: {'hidden_size': 64, 'num_layers': 4}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'num_layers': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:10<00:00, 31.42it/s, accuracy=0.00416, loss=5.52, val_accuracy=0.00318, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:10<00:00, 32.59it/s, accuracy=0.0044, loss=5.52, val_accuracy=0.00381, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:10<00:00, 32.91it/s, accuracy=0.00467, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:10<00:00, 31.91it/s, accuracy=0.00502, loss=5.5, val_accuracy=0.00487, val_loss=5.5] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:10<00:00, 32.86it/s, accuracy=0.00617, loss=5.49, val_accuracy=0.00582, val_loss=5.5] \n",
      "Epoch 6: 100%|██████████| 333/333 [00:10<00:00, 32.75it/s, accuracy=0.0063, loss=5.48, val_accuracy=0.00529, val_loss=5.5] \n",
      "Epoch 7: 100%|██████████| 333/333 [00:10<00:00, 32.88it/s, accuracy=0.00673, loss=5.46, val_accuracy=0.00773, val_loss=5.43]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:10<00:00, 31.55it/s, accuracy=0.00803, loss=5.4, val_accuracy=0.0073, val_loss=5.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:10<00:00, 32.69it/s, accuracy=0.00848, loss=5.36, val_accuracy=0.0108, val_loss=5.26] \n",
      "Epoch 10: 100%|██████████| 333/333 [00:10<00:00, 32.85it/s, accuracy=0.0109, loss=5.24, val_accuracy=0.0109, val_loss=5.2] \n",
      "\u001b[32m[I 2023-04-27 01:11:32,082]\u001b[0m Trial 11 finished with value: 5.19819536724606 and parameters: {'hidden_size': 64, 'num_layers': 4}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'num_layers': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:13<00:00, 25.55it/s, accuracy=0.00383, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:12<00:00, 25.84it/s, accuracy=0.00407, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:13<00:00, 25.48it/s, accuracy=0.00414, loss=5.52, val_accuracy=0.0036, val_loss=5.52] \n",
      "Epoch 4: 100%|██████████| 333/333 [00:12<00:00, 25.93it/s, accuracy=0.0047, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:12<00:00, 26.09it/s, accuracy=0.00479, loss=5.52, val_accuracy=0.00455, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:13<00:00, 25.56it/s, accuracy=0.00474, loss=5.52, val_accuracy=0.00508, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:12<00:00, 26.15it/s, accuracy=0.00526, loss=5.5, val_accuracy=0.0055, val_loss=5.5]  \n",
      "Epoch 8: 100%|██████████| 333/333 [00:13<00:00, 25.36it/s, accuracy=0.00603, loss=5.49, val_accuracy=0.00497, val_loss=5.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:12<00:00, 25.80it/s, accuracy=0.00673, loss=5.49, val_accuracy=0.00624, val_loss=5.49]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:12<00:00, 25.83it/s, accuracy=0.0071, loss=5.44, val_accuracy=0.00794, val_loss=5.35]\n",
      "\u001b[32m[I 2023-04-27 01:13:41,426]\u001b[0m Trial 12 finished with value: 5.354805675712791 and parameters: {'hidden_size': 64, 'num_layers': 5}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:17<00:00, 18.63it/s, accuracy=0.00401, loss=5.52, val_accuracy=0.00497, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:17<00:00, 18.66it/s, accuracy=0.00415, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 3: 100%|██████████| 333/333 [00:17<00:00, 18.64it/s, accuracy=0.00563, loss=5.5, val_accuracy=0.00529, val_loss=5.5] \n",
      "Epoch 4: 100%|██████████| 333/333 [00:17<00:00, 18.65it/s, accuracy=0.0063, loss=5.49, val_accuracy=0.00656, val_loss=5.5] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:17<00:00, 18.62it/s, accuracy=0.00662, loss=5.47, val_accuracy=0.00762, val_loss=5.42]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:17<00:00, 18.60it/s, accuracy=0.00955, loss=5.32, val_accuracy=0.0091, val_loss=5.27] \n",
      "Epoch 7: 100%|██████████| 333/333 [00:17<00:00, 18.67it/s, accuracy=0.0105, loss=5.24, val_accuracy=0.0109, val_loss=5.22]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:17<00:00, 18.58it/s, accuracy=0.0127, loss=5.2, val_accuracy=0.0145, val_loss=5.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:17<00:00, 18.57it/s, accuracy=0.0126, loss=5.22, val_accuracy=0.0103, val_loss=5.2]  \n",
      "Epoch 10: 100%|██████████| 333/333 [00:17<00:00, 18.53it/s, accuracy=0.0161, loss=5.12, val_accuracy=0.0199, val_loss=5.06]\n",
      "\u001b[32m[I 2023-04-27 01:16:40,402]\u001b[0m Trial 13 finished with value: 5.05655337668754 and parameters: {'hidden_size': 160, 'num_layers': 3}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:17<00:00, 18.58it/s, accuracy=0.00402, loss=5.52, val_accuracy=0.00286, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:17<00:00, 18.57it/s, accuracy=0.00413, loss=5.52, val_accuracy=0.0037, val_loss=5.52] \n",
      "Epoch 3: 100%|██████████| 333/333 [00:17<00:00, 18.53it/s, accuracy=0.00475, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:17<00:00, 18.54it/s, accuracy=0.00485, loss=5.5, val_accuracy=0.0054, val_loss=5.5]  \n",
      "Epoch 5: 100%|██████████| 333/333 [00:17<00:00, 18.59it/s, accuracy=0.0063, loss=5.49, val_accuracy=0.00582, val_loss=5.5] \n",
      "Epoch 6: 100%|██████████| 333/333 [00:17<00:00, 18.59it/s, accuracy=0.00652, loss=5.48, val_accuracy=0.00667, val_loss=5.49]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:17<00:00, 18.64it/s, accuracy=0.00794, loss=5.45, val_accuracy=0.00889, val_loss=5.41]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:17<00:00, 18.63it/s, accuracy=0.00941, loss=5.36, val_accuracy=0.00942, val_loss=5.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:17<00:00, 18.57it/s, accuracy=0.00877, loss=5.33, val_accuracy=0.00942, val_loss=5.38]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:17<00:00, 18.53it/s, accuracy=0.0113, loss=5.22, val_accuracy=0.0114, val_loss=5.25] \n",
      "\u001b[32m[I 2023-04-27 01:19:39,732]\u001b[0m Trial 14 finished with value: 5.245254787238869 and parameters: {'hidden_size': 160, 'num_layers': 3}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:18<00:00, 18.49it/s, accuracy=0.00399, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:18<00:00, 18.49it/s, accuracy=0.00435, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:18<00:00, 18.49it/s, accuracy=0.00456, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:18<00:00, 18.44it/s, accuracy=0.00443, loss=5.52, val_accuracy=0.00445, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:17<00:00, 18.51it/s, accuracy=0.00468, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:18<00:00, 18.50it/s, accuracy=0.00485, loss=5.52, val_accuracy=0.00476, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:17<00:00, 18.50it/s, accuracy=0.00465, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:18<00:00, 18.47it/s, accuracy=0.00492, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:17<00:00, 18.61it/s, accuracy=0.0046, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:17<00:00, 18.62it/s, accuracy=0.00485, loss=5.52, val_accuracy=0.00392, val_loss=5.52]\n",
      "\u001b[32m[I 2023-04-27 01:22:39,679]\u001b[0m Trial 15 finished with value: 5.521239345138137 and parameters: {'hidden_size': 160, 'num_layers': 3}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.00403, loss=5.52, val_accuracy=0.00381, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:25<00:00, 13.12it/s, accuracy=0.00375, loss=5.52, val_accuracy=0.00455, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.00501, loss=5.51, val_accuracy=0.00624, val_loss=5.51]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:25<00:00, 13.12it/s, accuracy=0.00602, loss=5.49, val_accuracy=0.00667, val_loss=5.5] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:25<00:00, 13.06it/s, accuracy=0.0066, loss=5.49, val_accuracy=0.00582, val_loss=5.49]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:25<00:00, 13.06it/s, accuracy=0.00655, loss=5.48, val_accuracy=0.00762, val_loss=5.48]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:25<00:00, 13.06it/s, accuracy=0.00741, loss=5.43, val_accuracy=0.00656, val_loss=5.38]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:25<00:00, 13.04it/s, accuracy=0.00942, loss=5.35, val_accuracy=0.0106, val_loss=5.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:25<00:00, 13.08it/s, accuracy=0.00843, loss=5.36, val_accuracy=0.00942, val_loss=5.25]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:25<00:00, 13.11it/s, accuracy=0.0122, loss=5.19, val_accuracy=0.00942, val_loss=5.22]\n",
      "\u001b[32m[I 2023-04-27 01:26:54,177]\u001b[0m Trial 16 finished with value: 5.223115070446117 and parameters: {'hidden_size': 160, 'num_layers': 5}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:17<00:00, 18.67it/s, accuracy=0.00381, loss=5.52, val_accuracy=0.00572, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:17<00:00, 18.63it/s, accuracy=0.00373, loss=5.52, val_accuracy=0.00413, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:17<00:00, 18.68it/s, accuracy=0.00419, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:17<00:00, 18.71it/s, accuracy=0.00457, loss=5.52, val_accuracy=0.00445, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:17<00:00, 18.70it/s, accuracy=0.00552, loss=5.51, val_accuracy=0.0055, val_loss=5.5] \n",
      "Epoch 6: 100%|██████████| 333/333 [00:17<00:00, 18.66it/s, accuracy=0.00603, loss=5.49, val_accuracy=0.0055, val_loss=5.49] \n",
      "Epoch 7: 100%|██████████| 333/333 [00:17<00:00, 18.71it/s, accuracy=0.00683, loss=5.47, val_accuracy=0.00635, val_loss=5.46]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:17<00:00, 18.63it/s, accuracy=0.00837, loss=5.4, val_accuracy=0.00826, val_loss=5.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:17<00:00, 18.67it/s, accuracy=0.00884, loss=5.36, val_accuracy=0.0109, val_loss=5.24] \n",
      "Epoch 10: 100%|██████████| 333/333 [00:17<00:00, 18.65it/s, accuracy=0.0134, loss=5.18, val_accuracy=0.0121, val_loss=5.19]\n",
      "\u001b[32m[I 2023-04-27 01:29:52,599]\u001b[0m Trial 17 finished with value: 5.19024185232214 and parameters: {'hidden_size': 160, 'num_layers': 3}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 256, 'num_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:43<00:00,  7.71it/s, accuracy=0.00382, loss=5.52, val_accuracy=0.00466, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:42<00:00,  7.75it/s, accuracy=0.00383, loss=5.52, val_accuracy=0.00318, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:43<00:00,  7.73it/s, accuracy=0.0039, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:43<00:00,  7.74it/s, accuracy=0.00401, loss=5.52, val_accuracy=0.00307, val_loss=5.52]\n",
      "Epoch 5: 100%|██████████| 333/333 [00:43<00:00,  7.74it/s, accuracy=0.00402, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:43<00:00,  7.74it/s, accuracy=0.00428, loss=5.52, val_accuracy=0.00434, val_loss=5.52]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:43<00:00,  7.72it/s, accuracy=0.00409, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:43<00:00,  7.74it/s, accuracy=0.00406, loss=5.52, val_accuracy=0.00296, val_loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:43<00:00,  7.73it/s, accuracy=0.00419, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 10: 100%|██████████| 333/333 [00:43<00:00,  7.73it/s, accuracy=0.00425, loss=5.52, val_accuracy=0.0036, val_loss=5.52] \n",
      "\u001b[32m[I 2023-04-27 01:37:03,432]\u001b[0m Trial 18 finished with value: 5.522360402184564 and parameters: {'hidden_size': 256, 'num_layers': 6}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 160, 'num_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [00:14<00:00, 23.14it/s, accuracy=0.00416, loss=5.52, val_accuracy=0.00339, val_loss=5.52]\n",
      "Epoch 2: 100%|██████████| 333/333 [00:14<00:00, 23.15it/s, accuracy=0.0038, loss=5.52, val_accuracy=0.00413, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 333/333 [00:14<00:00, 23.15it/s, accuracy=0.00446, loss=5.52, val_accuracy=0.00381, val_loss=5.52]\n",
      "Epoch 4: 100%|██████████| 333/333 [00:14<00:00, 23.11it/s, accuracy=0.00553, loss=5.5, val_accuracy=0.00593, val_loss=5.5] \n",
      "Epoch 5: 100%|██████████| 333/333 [00:14<00:00, 23.12it/s, accuracy=0.00616, loss=5.49, val_accuracy=0.00519, val_loss=5.49]\n",
      "Epoch 6: 100%|██████████| 333/333 [00:14<00:00, 23.13it/s, accuracy=0.00626, loss=5.48, val_accuracy=0.00508, val_loss=5.44]\n",
      "Epoch 7: 100%|██████████| 333/333 [00:14<00:00, 23.08it/s, accuracy=0.00747, loss=5.38, val_accuracy=0.00646, val_loss=5.35]\n",
      "Epoch 8: 100%|██████████| 333/333 [00:14<00:00, 23.06it/s, accuracy=0.00896, loss=5.32, val_accuracy=0.00889, val_loss=5.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [00:14<00:00, 23.07it/s, accuracy=0.00928, loss=5.31, val_accuracy=0.0107, val_loss=5.22] \n",
      "Epoch 10: 100%|██████████| 333/333 [00:14<00:00, 23.08it/s, accuracy=0.0119, loss=5.19, val_accuracy=0.0162, val_loss=5.14]\n",
      "\u001b[32m[I 2023-04-27 01:39:27,596]\u001b[0m Trial 19 finished with value: 5.14094877243042 and parameters: {'hidden_size': 160, 'num_layers': 2}. Best is trial 0 with value: 4.983493392531936.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "def train(params,save_model, trial):\n",
    "    learning_rate = 5e-4\n",
    "    weight_decay = 1e-1\n",
    "    cycle = 8\n",
    "    model = LSTMModel(num_features = 176, hidden_size = params[\"hidden_size\"], num_layers = params['num_layers'], \n",
    "                  bidirectional = False, num_classes = 250, batch_first = True).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cycle, eta_min=learning_rate / 10)\n",
    "    best_loss = float('inf')\n",
    "    saved_state = model.state_dict()\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        acc, loss, v_acc, v_loss = 0,0,0,0\n",
    "        \n",
    "        total_batches = len(train_loader)\n",
    "        train_size, train_batches = 0, 0\n",
    "        train_loss, train_correct = 0, 0\n",
    "        val_size, val_batches = 0, 0\n",
    "        val_loss, val_correct = 0, 0\n",
    "        n_offset=1\n",
    "\n",
    "        with tqdm(desc=f'Epoch {epoch+n_offset}', total=total_batches) as bar:\n",
    "\n",
    "            # Training\n",
    "            for batch, (src, y) in enumerate(train_loader):\n",
    "\n",
    "                # Compute prediction and loss\n",
    "                pred = model(src)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                # Compute metrics\n",
    "                train_loss += loss.item()\n",
    "                train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                train_size += len(y)\n",
    "                train_batches += 1\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "                optimizer.step()\n",
    "\n",
    "                scheduler.step(epoch + batch / total_batches)\n",
    "\n",
    "                # Update progress bar\n",
    "                bar.update()\n",
    "                bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches,\n",
    "                               lr=scheduler.get_last_lr())\n",
    "\n",
    "            bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches)\n",
    "            #scheduler.step()\n",
    "\n",
    "            # Validation\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for batch, (src, y) in enumerate(val_loader):\n",
    "\n",
    "                    # Compute prediction and loss\n",
    "                    pred = model(src)\n",
    "                    val_loss += loss_fn(pred, y).item()\n",
    "\n",
    "                    # Compute metrics\n",
    "                    val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                    val_size += len(y)\n",
    "                    val_batches += 1\n",
    "\n",
    "                    # Update progress bar\n",
    "                    bar.set_postfix(\n",
    "                        accuracy = train_correct / train_size, loss = train_loss / train_batches,\n",
    "                        val_accuracy = val_correct / val_size, val_loss = val_loss / val_batches\n",
    "                    )\n",
    "                    \n",
    "            \n",
    "\n",
    "        if scheduler.T_0 - scheduler.T_cur < 0.1:\n",
    "            print()\n",
    "        acc = train_correct / train_size\n",
    "        loss = train_loss / train_batches\n",
    "        v_acc = val_correct / val_size\n",
    "        v_loss = val_loss / val_batches\n",
    "        \n",
    "        \n",
    "        if v_loss<best_loss:\n",
    "            best_loss = v_loss\n",
    "            if save_model:\n",
    "                saved_state = model.state_dict()\n",
    "        \n",
    "        if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "                \n",
    "        \n",
    "            \n",
    "    return best_loss\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"hidden_size\": trial.suggest_categorical(\"hidden_size\",[64, 96, 128, 160, 192, 256]),\n",
    "        \"num_layers\" : trial.suggest_int(\"num_layers\",1,8)\n",
    "    }\n",
    "    print(trial.params)\n",
    "    best_val_loss = train(params, False, trial)\n",
    "    return best_val_loss\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\", pruner=MedianPruner())\n",
    "study.optimize(objective, n_trials=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b68b386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T02:01:03.203656Z",
     "iopub.status.busy": "2023-04-27T02:01:03.203237Z",
     "iopub.status.idle": "2023-04-27T02:01:03.215666Z",
     "shell.execute_reply": "2023-04-27T02:01:03.214161Z",
     "shell.execute_reply.started": "2023-04-27T02:01:03.203619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  20\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  20\n",
      "Best trial:\n",
      "  Value:  4.983493392531936\n",
      "  Params: \n",
      "    hidden_size: 160\n",
      "    num_layers: 5\n"
     ]
    }
   ],
   "source": [
    "from optuna.trial import TrialState\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial_ = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial_.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial_.params.items():\n",
    "    print(\"    {}: {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b80520f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T02:02:23.693437Z",
     "iopub.status.busy": "2023-04-27T02:02:23.692882Z",
     "iopub.status.idle": "2023-04-27T02:02:24.280666Z",
     "shell.execute_reply": "2023-04-27T02:02:24.279714Z",
     "shell.execute_reply.started": "2023-04-27T02:02:23.693403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"8e2ffe4b-8dc8-4c3c-bb33-9bba97045fe7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8e2ffe4b-8dc8-4c3c-bb33-9bba97045fe7\")) {                    Plotly.newPlot(                        \"8e2ffe4b-8dc8-4c3c-bb33-9bba97045fe7\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[4.983493392531936,5.521474825369345,5.177524811512715,5.522565777237351,5.519601989436794,5.522268849450189,5.500430493741422,5.520130299233101,5.499425475661819,5.520587315430513,5.161530945752118,5.19819536724606,5.354805675712791,5.05655337668754,5.245254787238869,5.521239345138137,5.223115070446117,5.19024185232214,5.522360402184564,5.14094877243042],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936,4.983493392531936],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8e2ffe4b-8dc8-4c3c-bb33-9bba97045fe7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the optimization history.\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d76916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T02:02:28.296933Z",
     "iopub.status.busy": "2023-04-27T02:02:28.296257Z",
     "iopub.status.idle": "2023-04-27T02:02:28.355791Z",
     "shell.execute_reply": "2023-04-27T02:02:28.354210Z",
     "shell.execute_reply.started": "2023-04-27T02:02:28.296893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"26b6552a-1100-4c86-ad7b-7e0d4865f71b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"26b6552a-1100-4c86-ad7b-7e0d4865f71b\")) {                    Plotly.newPlot(                        \"26b6552a-1100-4c86-ad7b-7e0d4865f71b\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[4.983493392531936,5.522565777237351],\"values\":[5.161530945752118,5.19819536724606,5.354805675712791,5.521474825369345,5.177524811512715,5.522565777237351,5.519601989436794,5.499425475661819,4.983493392531936,5.500430493741422,5.05655337668754,5.245254787238869,5.521239345138137,5.223115070446117,5.19024185232214,5.14094877243042,5.520130299233101,5.520587315430513,5.522268849450189,5.522360402184564]},{\"label\":\"hidden_size\",\"range\":[0,5],\"ticktext\":[\"64\",\"96\",\"128\",\"160\",\"192\",\"256\"],\"tickvals\":[0,1,2,3,4,5],\"values\":[0,0,0,1,1,2,2,2,3,3,3,3,3,3,3,3,4,4,5,5]},{\"label\":\"num_layers\",\"range\":[1,8],\"values\":[4,4,5,7,2,8,1,1,5,1,3,3,3,5,3,2,6,4,7,6]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[5.161530945752118,5.19819536724606,5.354805675712791,5.521474825369345,5.177524811512715,5.522565777237351,5.519601989436794,5.499425475661819,4.983493392531936,5.500430493741422,5.05655337668754,5.245254787238869,5.521239345138137,5.223115070446117,5.19024185232214,5.14094877243042,5.520130299233101,5.520587315430513,5.522268849450189,5.522360402184564],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":true,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('26b6552a-1100-4c86-ad7b-7e0d4865f71b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize high-dimensional parameter relationships.\n",
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65c3235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T02:02:29.985000Z",
     "iopub.status.busy": "2023-04-27T02:02:29.984311Z",
     "iopub.status.idle": "2023-04-27T02:02:30.061962Z",
     "shell.execute_reply": "2023-04-27T02:02:30.061035Z",
     "shell.execute_reply.started": "2023-04-27T02:02:29.984964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"4dd152cc-9f5d-42dd-8115-ac9a5e619333\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4dd152cc-9f5d-42dd-8115-ac9a5e619333\")) {                    Plotly.newPlot(                        \"4dd152cc-9f5d-42dd-8115-ac9a5e619333\",                        [{\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"connectgaps\":true,\"contours\":{\"coloring\":\"heatmap\"},\"hoverinfo\":\"none\",\"line\":{\"smoothing\":1.3},\"reversescale\":true,\"x\":[54.4,64,96,128,160,192,256,265.6],\"y\":[0.6499999999999999,1,2,3,4,5,6,7,8,8.35],\"z\":[[null,null,null,null,null,null,null,null],[null,null,null,5.499425475661819,5.500430493741422,null,null,null],[null,null,5.177524811512715,null,5.14094877243042,null,null,null],[null,null,null,null,5.19024185232214,null,null,null],[null,5.19819536724606,null,null,null,5.520587315430513,null,null],[null,5.354805675712791,null,null,5.223115070446117,null,null,null],[null,null,null,null,null,5.520130299233101,5.522360402184564,null],[null,null,5.521474825369345,null,null,null,5.522268849450189,null],[null,null,null,5.522565777237351,null,null,null,null],[null,null,null,null,null,null,null,null]],\"type\":\"contour\"},{\"marker\":{\"color\":\"black\",\"line\":{\"color\":\"Grey\",\"width\":2.0}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[160,96,96,128,128,256,160,192,128,192,64,64,64,160,160,160,160,160,256,160],\"y\":[5,7,2,8,1,7,1,6,1,4,4,4,5,3,3,3,5,3,6,2],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"hidden_size\"},\"range\":[54.4,265.6]},\"yaxis\":{\"title\":{\"text\":\"num_layers\"},\"range\":[0.6499999999999999,8.35]}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4dd152cc-9f5d-42dd-8115-ac9a5e619333');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_contour(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb89273d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T02:02:31.285426Z",
     "iopub.status.busy": "2023-04-27T02:02:31.284735Z",
     "iopub.status.idle": "2023-04-27T02:02:31.505163Z",
     "shell.execute_reply": "2023-04-27T02:02:31.504114Z",
     "shell.execute_reply.started": "2023-04-27T02:02:31.285389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"e05aff35-dca1-44c2-b7a5-57a907395968\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e05aff35-dca1-44c2-b7a5-57a907395968\")) {                    Plotly.newPlot(                        \"e05aff35-dca1-44c2-b7a5-57a907395968\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"showlegend\":false,\"x\":[160,96,96,128,128,256,160,192,128,192,64,64,64,160,160,160,160,160,256,160],\"y\":[4.983493392531936,5.521474825369345,5.177524811512715,5.522565777237351,5.519601989436794,5.522268849450189,5.500430493741422,5.520130299233101,5.499425475661819,5.520587315430513,5.161530945752118,5.19819536724606,5.354805675712791,5.05655337668754,5.245254787238869,5.521239345138137,5.223115070446117,5.19024185232214,5.522360402184564,5.14094877243042],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[5,7,2,8,1,7,1,6,1,4,4,4,5,3,3,3,5,3,6,2],\"y\":[4.983493392531936,5.521474825369345,5.177524811512715,5.522565777237351,5.519601989436794,5.522268849450189,5.500430493741422,5.520130299233101,5.499425475661819,5.520587315430513,5.161530945752118,5.19819536724606,5.354805675712791,5.05655337668754,5.245254787238869,5.521239345138137,5.223115070446117,5.19024185232214,5.522360402184564,5.14094877243042],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"hidden_size\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"num_layers\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"Slice Plot\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e05aff35-dca1-44c2-b7a5-57a907395968');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57699e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T02:02:32.447202Z",
     "iopub.status.busy": "2023-04-27T02:02:32.446034Z",
     "iopub.status.idle": "2023-04-27T02:02:32.794096Z",
     "shell.execute_reply": "2023-04-27T02:02:32.792943Z",
     "shell.execute_reply.started": "2023-04-27T02:02:32.447156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"ccafe7b7-f26b-4912-ae7a-e10525b403ec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ccafe7b7-f26b-4912-ae7a-e10525b403ec\")) {                    Plotly.newPlot(                        \"ccafe7b7-f26b-4912-ae7a-e10525b403ec\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"num_layers (IntDistribution): 0.4923347240090088<extra></extra>\",\"hidden_size (CategoricalDistribution): 0.5076652759909912<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.49\",\"0.51\"],\"textposition\":\"outside\",\"x\":[0.4923347240090088,0.5076652759909912],\"y\":[\"num_layers\",\"hidden_size\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ccafe7b7-f26b-4912-ae7a-e10525b403ec');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize parameter importances.\n",
    "plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7eb34",
   "metadata": {},
   "source": [
    "Training the model with the hyperparameters obtained for the best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de975b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T03:02:38.799894Z",
     "iopub.status.busy": "2023-04-27T03:02:38.798795Z",
     "iopub.status.idle": "2023-04-27T03:02:38.841386Z",
     "shell.execute_reply": "2023-04-27T03:02:38.840355Z",
     "shell.execute_reply.started": "2023-04-27T03:02:38.799852Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = 176\n",
    "hidden_size = 160\n",
    "num_layers = 5\n",
    "num_classes = 250\n",
    "model = LSTMModel(num_features = num_features, hidden_size = hidden_size, num_layers = num_layers, \n",
    "                  bidirectional = True, num_classes = num_classes, batch_first = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284b6958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T03:02:40.794634Z",
     "iopub.status.busy": "2023-04-27T03:02:40.794227Z",
     "iopub.status.idle": "2023-04-27T08:33:55.360428Z",
     "shell.execute_reply": "2023-04-27T08:33:55.358288Z",
     "shell.execute_reply.started": "2023-04-27T03:02:40.794596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 665/665 [01:36<00:00,  6.86it/s, accuracy=0.00414, loss=5.52, val_accuracy=0.00286, val_loss=5.52] \n",
      "Epoch 2: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.00433, loss=5.52, val_accuracy=0.00402, val_loss=5.52]\n",
      "Epoch 3: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.00545, loss=5.5, val_accuracy=0.00656, val_loss=5.5] \n",
      "Epoch 4: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.00626, loss=5.49, val_accuracy=0.00561, val_loss=5.49]\n",
      "Epoch 5: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.007, loss=5.47, val_accuracy=0.00773, val_loss=5.42]\n",
      "Epoch 6: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0106, loss=5.3, val_accuracy=0.0117, val_loss=5.22] \n",
      "Epoch 7: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.0139, loss=5.17, val_accuracy=0.0151, val_loss=5.14] \n",
      "Epoch 8: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0166, loss=5.11, val_accuracy=0.015, val_loss=5.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0138, loss=5.16, val_accuracy=0.0184, val_loss=5.09] \n",
      "Epoch 10: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.019, loss=5.07, val_accuracy=0.0251, val_loss=5]   \n",
      "Epoch 11: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0253, loss=4.96, val_accuracy=0.0291, val_loss=4.95]\n",
      "Epoch 12: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.0322, loss=4.81, val_accuracy=0.0409, val_loss=4.7] \n",
      "Epoch 13: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.0459, loss=4.65, val_accuracy=0.054, val_loss=4.59] \n",
      "Epoch 14: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.0575, loss=4.54, val_accuracy=0.0604, val_loss=4.5] \n",
      "Epoch 15: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.0684, loss=4.45, val_accuracy=0.0678, val_loss=4.44]\n",
      "Epoch 16: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0736, loss=4.4, val_accuracy=0.0658, val_loss=4.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0594, loss=4.53, val_accuracy=0.0605, val_loss=4.53]\n",
      "Epoch 18: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0639, loss=4.47, val_accuracy=0.0719, val_loss=4.4] \n",
      "Epoch 19: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0746, loss=4.38, val_accuracy=0.0747, val_loss=4.41]\n",
      "Epoch 20: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.0848, loss=4.28, val_accuracy=0.0911, val_loss=4.26]\n",
      "Epoch 21: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.101, loss=4.18, val_accuracy=0.0992, val_loss=4.21]\n",
      "Epoch 22: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.118, loss=4.06, val_accuracy=0.114, val_loss=4.1] \n",
      "Epoch 23: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.135, loss=3.95, val_accuracy=0.134, val_loss=3.97]\n",
      "Epoch 24: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.148, loss=3.87, val_accuracy=0.147, val_loss=3.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.122, loss=4.01, val_accuracy=0.119, val_loss=4.04]\n",
      "Epoch 26: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.141, loss=3.87, val_accuracy=0.125, val_loss=3.98]\n",
      "Epoch 27: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.168, loss=3.69, val_accuracy=0.163, val_loss=3.68]\n",
      "Epoch 28: 100%|██████████| 665/665 [01:36<00:00,  6.92it/s, accuracy=0.192, loss=3.54, val_accuracy=0.18, val_loss=3.62] \n",
      "Epoch 29: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.22, loss=3.39, val_accuracy=0.221, val_loss=3.42]\n",
      "Epoch 30: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.244, loss=3.26, val_accuracy=0.233, val_loss=3.31]\n",
      "Epoch 31: 100%|██████████| 665/665 [01:36<00:00,  6.92it/s, accuracy=0.264, loss=3.16, val_accuracy=0.262, val_loss=3.19]\n",
      "Epoch 32: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.28, loss=3.08, val_accuracy=0.266, val_loss=3.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.216, loss=3.38, val_accuracy=0.234, val_loss=3.33]\n",
      "Epoch 34: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.23, loss=3.3, val_accuracy=0.188, val_loss=3.55]\n",
      "Epoch 35: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.247, loss=3.2, val_accuracy=0.269, val_loss=3.12]\n",
      "Epoch 36: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.272, loss=3.07, val_accuracy=0.274, val_loss=3.1] \n",
      "Epoch 37: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.302, loss=2.93, val_accuracy=0.295, val_loss=2.98]\n",
      "Epoch 38: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.33, loss=2.8, val_accuracy=0.32, val_loss=2.88] \n",
      "Epoch 39: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.353, loss=2.7, val_accuracy=0.334, val_loss=2.83]\n",
      "Epoch 40: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.372, loss=2.62, val_accuracy=0.343, val_loss=2.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.286, loss=2.99, val_accuracy=0.243, val_loss=3.23]\n",
      "Epoch 42: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.3, loss=2.93, val_accuracy=0.244, val_loss=3.23]\n",
      "Epoch 43: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.317, loss=2.84, val_accuracy=0.261, val_loss=3.13]\n",
      "Epoch 44: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.34, loss=2.73, val_accuracy=0.339, val_loss=2.78]\n",
      "Epoch 45: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.372, loss=2.59, val_accuracy=0.323, val_loss=2.83]\n",
      "Epoch 46: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.402, loss=2.47, val_accuracy=0.386, val_loss=2.58]\n",
      "Epoch 47: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.428, loss=2.36, val_accuracy=0.391, val_loss=2.54]\n",
      "Epoch 48: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.446, loss=2.29, val_accuracy=0.4, val_loss=2.52]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.35, loss=2.68, val_accuracy=0.328, val_loss=2.79]\n",
      "Epoch 50: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.357, loss=2.65, val_accuracy=0.35, val_loss=2.74] \n",
      "Epoch 51: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.371, loss=2.59, val_accuracy=0.318, val_loss=2.87]\n",
      "Epoch 52: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.394, loss=2.48, val_accuracy=0.371, val_loss=2.62]\n",
      "Epoch 53: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.424, loss=2.35, val_accuracy=0.392, val_loss=2.55]\n",
      "Epoch 54: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.456, loss=2.22, val_accuracy=0.425, val_loss=2.4] \n",
      "Epoch 55: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.484, loss=2.11, val_accuracy=0.436, val_loss=2.35]\n",
      "Epoch 56: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.503, loss=2.04, val_accuracy=0.451, val_loss=2.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 665/665 [01:36<00:00,  6.92it/s, accuracy=0.394, loss=2.48, val_accuracy=0.374, val_loss=2.62]\n",
      "Epoch 58: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.396, loss=2.47, val_accuracy=0.357, val_loss=2.68]\n",
      "Epoch 59: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.418, loss=2.37, val_accuracy=0.405, val_loss=2.5] \n",
      "Epoch 60: 100%|██████████| 665/665 [01:36<00:00,  6.92it/s, accuracy=0.444, loss=2.26, val_accuracy=0.373, val_loss=2.58]\n",
      "Epoch 61: 100%|██████████| 665/665 [01:36<00:00,  6.92it/s, accuracy=0.474, loss=2.14, val_accuracy=0.426, val_loss=2.4] \n",
      "Epoch 62: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.508, loss=2.01, val_accuracy=0.474, val_loss=2.2] \n",
      "Epoch 63: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.537, loss=1.89, val_accuracy=0.486, val_loss=2.16]\n",
      "Epoch 64: 100%|██████████| 665/665 [01:36<00:00,  6.90it/s, accuracy=0.557, loss=1.82, val_accuracy=0.488, val_loss=2.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.438, loss=2.28, val_accuracy=0.377, val_loss=2.6] \n",
      "Epoch 66: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.442, loss=2.26, val_accuracy=0.419, val_loss=2.39]\n",
      "Epoch 67: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.461, loss=2.19, val_accuracy=0.382, val_loss=2.59]\n",
      "Epoch 68: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.485, loss=2.08, val_accuracy=0.456, val_loss=2.27]\n",
      "Epoch 69: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.518, loss=1.95, val_accuracy=0.466, val_loss=2.21]\n",
      "Epoch 70: 100%|██████████| 665/665 [01:36<00:00,  6.89it/s, accuracy=0.55, loss=1.82, val_accuracy=0.492, val_loss=2.1] \n",
      "Epoch 71: 100%|██████████| 665/665 [01:36<00:00,  6.91it/s, accuracy=0.583, loss=1.7, val_accuracy=0.504, val_loss=2.06]\n",
      "Epoch 72: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.605, loss=1.63, val_accuracy=0.517, val_loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.485, loss=2.08, val_accuracy=0.415, val_loss=2.42]\n",
      "Epoch 74: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.474, loss=2.12, val_accuracy=0.451, val_loss=2.29]\n",
      "Epoch 75: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.494, loss=2.03, val_accuracy=0.442, val_loss=2.34]\n",
      "Epoch 76: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.522, loss=1.92, val_accuracy=0.476, val_loss=2.17]\n",
      "Epoch 77: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.556, loss=1.79, val_accuracy=0.508, val_loss=2.05]\n",
      "Epoch 78: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.591, loss=1.66, val_accuracy=0.522, val_loss=2.01]\n",
      "Epoch 79: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.623, loss=1.54, val_accuracy=0.54, val_loss=1.94] \n",
      "Epoch 80: 100%|██████████| 665/665 [01:34<00:00,  7.00it/s, accuracy=0.643, loss=1.47, val_accuracy=0.54, val_loss=1.92] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.512, loss=1.96, val_accuracy=0.461, val_loss=2.24]\n",
      "Epoch 82: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.511, loss=1.96, val_accuracy=0.487, val_loss=2.15]\n",
      "Epoch 83: 100%|██████████| 665/665 [01:34<00:00,  7.00it/s, accuracy=0.525, loss=1.91, val_accuracy=0.491, val_loss=2.11]\n",
      "Epoch 84: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.552, loss=1.8, val_accuracy=0.495, val_loss=2.13]\n",
      "Epoch 85: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.587, loss=1.66, val_accuracy=0.525, val_loss=1.98]\n",
      "Epoch 86: 100%|██████████| 665/665 [01:34<00:00,  7.03it/s, accuracy=0.623, loss=1.53, val_accuracy=0.542, val_loss=1.93]\n",
      "Epoch 87: 100%|██████████| 665/665 [01:34<00:00,  7.02it/s, accuracy=0.655, loss=1.41, val_accuracy=0.541, val_loss=1.92]\n",
      "Epoch 88: 100%|██████████| 665/665 [01:34<00:00,  7.03it/s, accuracy=0.679, loss=1.33, val_accuracy=0.56, val_loss=1.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 665/665 [01:34<00:00,  7.02it/s, accuracy=0.544, loss=1.82, val_accuracy=0.446, val_loss=2.32]\n",
      "Epoch 90: 100%|██████████| 665/665 [01:34<00:00,  7.00it/s, accuracy=0.544, loss=1.82, val_accuracy=0.471, val_loss=2.2] \n",
      "Epoch 91: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.554, loss=1.78, val_accuracy=0.477, val_loss=2.2] \n",
      "Epoch 92: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.581, loss=1.68, val_accuracy=0.517, val_loss=2.05]\n",
      "Epoch 93: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.613, loss=1.56, val_accuracy=0.546, val_loss=1.92]\n",
      "Epoch 94: 100%|██████████| 665/665 [01:34<00:00,  7.01it/s, accuracy=0.654, loss=1.41, val_accuracy=0.552, val_loss=1.87]\n",
      "Epoch 95: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.686, loss=1.3, val_accuracy=0.563, val_loss=1.85]\n",
      "Epoch 96: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.709, loss=1.22, val_accuracy=0.572, val_loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.572, loss=1.71, val_accuracy=0.434, val_loss=2.37]\n",
      "Epoch 98: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.563, loss=1.74, val_accuracy=0.482, val_loss=2.17]\n",
      "Epoch 99: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.577, loss=1.69, val_accuracy=0.521, val_loss=2]   \n",
      "Epoch 100: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.602, loss=1.58, val_accuracy=0.505, val_loss=2.05]\n",
      "Epoch 101: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.64, loss=1.45, val_accuracy=0.536, val_loss=1.97]\n",
      "Epoch 102: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.678, loss=1.31, val_accuracy=0.563, val_loss=1.85]\n",
      "Epoch 103: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.712, loss=1.2, val_accuracy=0.574, val_loss=1.81]\n",
      "Epoch 104: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.736, loss=1.12, val_accuracy=0.579, val_loss=1.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.59, loss=1.62, val_accuracy=0.494, val_loss=2.13]\n",
      "Epoch 106: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.591, loss=1.63, val_accuracy=0.5, val_loss=2.12]  \n",
      "Epoch 107: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.6, loss=1.59, val_accuracy=0.523, val_loss=2.04]\n",
      "Epoch 108: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.624, loss=1.5, val_accuracy=0.545, val_loss=1.9] \n",
      "Epoch 109: 100%|██████████| 665/665 [01:34<00:00,  7.00it/s, accuracy=0.663, loss=1.36, val_accuracy=0.565, val_loss=1.85]\n",
      "Epoch 110: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.702, loss=1.22, val_accuracy=0.576, val_loss=1.81]\n",
      "Epoch 111: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.737, loss=1.1, val_accuracy=0.584, val_loss=1.79]\n",
      "Epoch 112: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.761, loss=1.03, val_accuracy=0.588, val_loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.611, loss=1.55, val_accuracy=0.488, val_loss=2.16]\n",
      "Epoch 114: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.598, loss=1.59, val_accuracy=0.488, val_loss=2.14]\n",
      "Epoch 115: 100%|██████████| 665/665 [01:34<00:00,  7.00it/s, accuracy=0.612, loss=1.54, val_accuracy=0.495, val_loss=2.14]\n",
      "Epoch 116: 100%|██████████| 665/665 [01:34<00:00,  7.01it/s, accuracy=0.644, loss=1.42, val_accuracy=0.539, val_loss=1.96]\n",
      "Epoch 117: 100%|██████████| 665/665 [01:34<00:00,  7.01it/s, accuracy=0.679, loss=1.29, val_accuracy=0.561, val_loss=1.89]\n",
      "Epoch 118: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.724, loss=1.14, val_accuracy=0.583, val_loss=1.79]\n",
      "Epoch 119: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.757, loss=1.03, val_accuracy=0.592, val_loss=1.77]\n",
      "Epoch 120: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.783, loss=0.949, val_accuracy=0.593, val_loss=1.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.631, loss=1.46, val_accuracy=0.503, val_loss=2.14]\n",
      "Epoch 122: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.617, loss=1.52, val_accuracy=0.531, val_loss=2.01]\n",
      "Epoch 123: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.631, loss=1.46, val_accuracy=0.526, val_loss=2.03]\n",
      "Epoch 124: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.655, loss=1.38, val_accuracy=0.522, val_loss=2.04]\n",
      "Epoch 125: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.695, loss=1.23, val_accuracy=0.569, val_loss=1.83]\n",
      "Epoch 126: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.736, loss=1.09, val_accuracy=0.586, val_loss=1.79]\n",
      "Epoch 127: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.775, loss=0.962, val_accuracy=0.596, val_loss=1.76]\n",
      "Epoch 128: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.799, loss=0.885, val_accuracy=0.603, val_loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.641, loss=1.42, val_accuracy=0.474, val_loss=2.29]\n",
      "Epoch 130: 100%|██████████| 665/665 [01:36<00:00,  6.90it/s, accuracy=0.626, loss=1.48, val_accuracy=0.498, val_loss=2.15]\n",
      "Epoch 131: 100%|██████████| 665/665 [01:36<00:00,  6.92it/s, accuracy=0.645, loss=1.41, val_accuracy=0.531, val_loss=1.99]\n",
      "Epoch 132: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.679, loss=1.29, val_accuracy=0.559, val_loss=1.9] \n",
      "Epoch 133: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.715, loss=1.16, val_accuracy=0.574, val_loss=1.83]\n",
      "Epoch 134: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.756, loss=1.02, val_accuracy=0.575, val_loss=1.86]\n",
      "Epoch 135: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.792, loss=0.9, val_accuracy=0.597, val_loss=1.76]\n",
      "Epoch 136: 100%|██████████| 665/665 [01:34<00:00,  7.00it/s, accuracy=0.815, loss=0.825, val_accuracy=0.601, val_loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.665, loss=1.33, val_accuracy=0.528, val_loss=2.05]\n",
      "Epoch 138: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.642, loss=1.41, val_accuracy=0.502, val_loss=2.14]\n",
      "Epoch 139: 100%|██████████| 665/665 [01:36<00:00,  6.93it/s, accuracy=0.659, loss=1.35, val_accuracy=0.539, val_loss=1.98]\n",
      "Epoch 140: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.689, loss=1.24, val_accuracy=0.531, val_loss=2.03]\n",
      "Epoch 141: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.726, loss=1.11, val_accuracy=0.578, val_loss=1.84]\n",
      "Epoch 142: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.77, loss=0.964, val_accuracy=0.592, val_loss=1.79]\n",
      "Epoch 143: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.805, loss=0.847, val_accuracy=0.603, val_loss=1.76]\n",
      "Epoch 144: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.83, loss=0.77, val_accuracy=0.601, val_loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.671, loss=1.3, val_accuracy=0.538, val_loss=2.02]\n",
      "Epoch 146: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.657, loss=1.35, val_accuracy=0.475, val_loss=2.27]\n",
      "Epoch 147: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.667, loss=1.31, val_accuracy=0.518, val_loss=2.09]\n",
      "Epoch 148: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.699, loss=1.2, val_accuracy=0.566, val_loss=1.87]\n",
      "Epoch 149: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.739, loss=1.06, val_accuracy=0.567, val_loss=1.88]\n",
      "Epoch 150: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.783, loss=0.916, val_accuracy=0.593, val_loss=1.8] \n",
      "Epoch 151: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.82, loss=0.799, val_accuracy=0.604, val_loss=1.76]\n",
      "Epoch 152: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.844, loss=0.723, val_accuracy=0.604, val_loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.68, loss=1.27, val_accuracy=0.528, val_loss=2.04]\n",
      "Epoch 154: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.667, loss=1.31, val_accuracy=0.532, val_loss=2.03]\n",
      "Epoch 155: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.682, loss=1.26, val_accuracy=0.543, val_loss=2]   \n",
      "Epoch 156: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.705, loss=1.17, val_accuracy=0.563, val_loss=1.92]\n",
      "Epoch 157: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.752, loss=1.01, val_accuracy=0.575, val_loss=1.86]\n",
      "Epoch 158: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.794, loss=0.875, val_accuracy=0.603, val_loss=1.79]\n",
      "Epoch 159: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.831, loss=0.756, val_accuracy=0.607, val_loss=1.77]\n",
      "Epoch 160: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.853, loss=0.685, val_accuracy=0.606, val_loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.689, loss=1.22, val_accuracy=0.523, val_loss=2.09]\n",
      "Epoch 162: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.673, loss=1.28, val_accuracy=0.54, val_loss=2.03] \n",
      "Epoch 163: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.692, loss=1.22, val_accuracy=0.546, val_loss=1.99]\n",
      "Epoch 164: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.722, loss=1.11, val_accuracy=0.534, val_loss=2.05]\n",
      "Epoch 165: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.761, loss=0.974, val_accuracy=0.578, val_loss=1.86]\n",
      "Epoch 166: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.804, loss=0.836, val_accuracy=0.59, val_loss=1.84] \n",
      "Epoch 167: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.841, loss=0.718, val_accuracy=0.603, val_loss=1.8] \n",
      "Epoch 168: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.864, loss=0.646, val_accuracy=0.61, val_loss=1.78] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.701, loss=1.18, val_accuracy=0.521, val_loss=2.16]\n",
      "Epoch 170: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.69, loss=1.22, val_accuracy=0.527, val_loss=2.06]\n",
      "Epoch 171: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.698, loss=1.19, val_accuracy=0.506, val_loss=2.19]\n",
      "Epoch 172: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.728, loss=1.08, val_accuracy=0.567, val_loss=1.92]\n",
      "Epoch 173: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.767, loss=0.952, val_accuracy=0.589, val_loss=1.85]\n",
      "Epoch 174: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.814, loss=0.797, val_accuracy=0.589, val_loss=1.86]\n",
      "Epoch 175: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.851, loss=0.684, val_accuracy=0.61, val_loss=1.78] \n",
      "Epoch 176: 100%|██████████| 665/665 [01:35<00:00,  6.94it/s, accuracy=0.873, loss=0.614, val_accuracy=0.606, val_loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.711, loss=1.14, val_accuracy=0.536, val_loss=2.05]\n",
      "Epoch 178: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.694, loss=1.21, val_accuracy=0.547, val_loss=2]   \n",
      "Epoch 179: 100%|██████████| 665/665 [01:36<00:00,  6.93it/s, accuracy=0.709, loss=1.15, val_accuracy=0.55, val_loss=1.99] \n",
      "Epoch 180: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.737, loss=1.04, val_accuracy=0.553, val_loss=2.01]\n",
      "Epoch 181: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.778, loss=0.907, val_accuracy=0.576, val_loss=1.92]\n",
      "Epoch 182: 100%|██████████| 665/665 [01:35<00:00,  6.93it/s, accuracy=0.823, loss=0.761, val_accuracy=0.601, val_loss=1.81]\n",
      "Epoch 183: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.86, loss=0.651, val_accuracy=0.606, val_loss=1.8] \n",
      "Epoch 184: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.88, loss=0.583, val_accuracy=0.607, val_loss=1.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.722, loss=1.1, val_accuracy=0.545, val_loss=2.05]\n",
      "Epoch 186: 100%|██████████| 665/665 [01:35<00:00,  6.95it/s, accuracy=0.699, loss=1.18, val_accuracy=0.532, val_loss=2.09]\n",
      "Epoch 187: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.712, loss=1.14, val_accuracy=0.559, val_loss=1.97]\n",
      "Epoch 188: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.748, loss=1.02, val_accuracy=0.57, val_loss=1.92] \n",
      "Epoch 189: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.787, loss=0.874, val_accuracy=0.579, val_loss=1.89]\n",
      "Epoch 190: 100%|██████████| 665/665 [01:34<00:00,  7.01it/s, accuracy=0.832, loss=0.734, val_accuracy=0.602, val_loss=1.84]\n",
      "Epoch 191: 100%|██████████| 665/665 [01:34<00:00,  7.01it/s, accuracy=0.867, loss=0.622, val_accuracy=0.609, val_loss=1.81]\n",
      "Epoch 192: 100%|██████████| 665/665 [01:34<00:00,  7.01it/s, accuracy=0.888, loss=0.555, val_accuracy=0.61, val_loss=1.82] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.729, loss=1.07, val_accuracy=0.541, val_loss=2.06]\n",
      "Epoch 194: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.711, loss=1.13, val_accuracy=0.554, val_loss=1.99]\n",
      "Epoch 195: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.724, loss=1.09, val_accuracy=0.558, val_loss=1.98]\n",
      "Epoch 196: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.751, loss=0.988, val_accuracy=0.579, val_loss=1.9] \n",
      "Epoch 197: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.793, loss=0.849, val_accuracy=0.586, val_loss=1.9] \n",
      "Epoch 198: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.838, loss=0.706, val_accuracy=0.601, val_loss=1.85]\n",
      "Epoch 199: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.873, loss=0.598, val_accuracy=0.604, val_loss=1.84]\n",
      "Epoch 200: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.895, loss=0.531, val_accuracy=0.61, val_loss=1.82] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201: 100%|██████████| 665/665 [01:35<00:00,  6.96it/s, accuracy=0.74, loss=1.03, val_accuracy=0.532, val_loss=2.1] \n",
      "Epoch 202: 100%|██████████| 665/665 [01:35<00:00,  6.97it/s, accuracy=0.711, loss=1.13, val_accuracy=0.548, val_loss=2.05]\n",
      "Epoch 203: 100%|██████████| 665/665 [01:35<00:00,  7.00it/s, accuracy=0.732, loss=1.06, val_accuracy=0.554, val_loss=2]   \n",
      "Epoch 204: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.757, loss=0.972, val_accuracy=0.576, val_loss=1.93]\n",
      "Epoch 205: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.802, loss=0.819, val_accuracy=0.587, val_loss=1.89]\n",
      "Epoch 206: 100%|██████████| 665/665 [01:35<00:00,  6.98it/s, accuracy=0.846, loss=0.681, val_accuracy=0.6, val_loss=1.86]  \n",
      "Epoch 207: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.881, loss=0.572, val_accuracy=0.611, val_loss=1.85]\n",
      "Epoch 208: 100%|██████████| 665/665 [01:35<00:00,  6.99it/s, accuracy=0.902, loss=0.507, val_accuracy=0.609, val_loss=1.86]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/1371441072.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm_model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24/1371441072.py\u001b[0m in \u001b[0;36mtrain_val_loop\u001b[0;34m(epoch, train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, n_offset)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# Compute metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "weight_decay = 1e-1\n",
    "cycle = 8\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cycle, eta_min=learning_rate / 10)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train_val_loop(epoch, train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, n_offset=1):\n",
    "    total_batches = len(train_dataloader)\n",
    "    train_size, train_batches = 0, 0\n",
    "    train_loss, train_correct = 0, 0\n",
    "    val_size, val_batches = 0, 0\n",
    "    val_loss, val_correct = 0, 0\n",
    "    \n",
    "    with tqdm(desc=f'Epoch {epoch+n_offset}', total=total_batches) as bar:\n",
    "        \n",
    "        # Training\n",
    "        for batch, (src, y) in enumerate(train_dataloader):\n",
    "            \n",
    "            # Compute prediction and loss\n",
    "            pred = model(src)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            # Compute metrics\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            train_size += len(y)\n",
    "            train_batches += 1\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "                \n",
    "            scheduler.step(epoch + batch / total_batches)\n",
    "            \n",
    "            # Update progress bar\n",
    "            bar.update()\n",
    "            bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches,\n",
    "                           lr=scheduler.get_last_lr())\n",
    "            \n",
    "        bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches)\n",
    "        \n",
    "        #scheduler.step()\n",
    "           \n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch, (src, y) in enumerate(val_dataloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                pred = model(src)\n",
    "                val_loss += loss_fn(pred, y).item()\n",
    "                \n",
    "                # Compute metrics\n",
    "                val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                val_size += len(y)\n",
    "                val_batches += 1\n",
    "\n",
    "                # Update progress bar\n",
    "                bar.set_postfix(\n",
    "                    accuracy = train_correct / train_size, loss = train_loss / train_batches,\n",
    "                    val_accuracy = val_correct / val_size, val_loss = val_loss / val_batches\n",
    "                )\n",
    "                \n",
    "    if scheduler.T_0 - scheduler.T_cur < 0.1:\n",
    "        print()\n",
    "        \n",
    "    train_losses.append(train_loss / train_batches)\n",
    "    val_losses.append(val_loss / val_batches)\n",
    "\n",
    "    return train_correct / train_size, train_loss / train_batches, val_correct / val_size, val_loss / val_batches\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "saved_state = model.state_dict()\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "#model.load_state_dict(torch.load(\"/kaggle/input/lstm-model/lstm_model_100Epochs_ss.pth\"))\n",
    "# Iterate through epochs for training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    acc, loss, v_acc, v_loss = train_val_loop(epoch, train_loader, val_loader, model, loss_fn, optimizer, scheduler)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        torch.save(model.state_dict(), 'lstm_model_' + str(epoch+1))\n",
    "    if v_loss<best_loss:\n",
    "        best_loss = v_loss\n",
    "        saved_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d42f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T08:34:09.975032Z",
     "iopub.status.busy": "2023-04-27T08:34:09.974352Z",
     "iopub.status.idle": "2023-04-27T08:34:10.020890Z",
     "shell.execute_reply": "2023-04-27T08:34:10.019808Z",
     "shell.execute_reply.started": "2023-04-27T08:34:09.974994Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"LSTMFinalModel.pth\")\n",
    "torch.save(saved_state,\"LSTMBestModelFinal.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f12f6666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T08:37:12.143567Z",
     "iopub.status.busy": "2023-04-27T08:37:12.142584Z",
     "iopub.status.idle": "2023-04-27T08:37:12.151288Z",
     "shell.execute_reply": "2023-04-27T08:37:12.150030Z",
     "shell.execute_reply.started": "2023-04-27T08:37:12.143530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caa79cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T08:37:33.757255Z",
     "iopub.status.busy": "2023-04-27T08:37:33.756891Z",
     "iopub.status.idle": "2023-04-27T08:37:33.764884Z",
     "shell.execute_reply": "2023-04-27T08:37:33.763664Z",
     "shell.execute_reply.started": "2023-04-27T08:37:33.757225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64de9222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T08:38:18.711516Z",
     "iopub.status.busy": "2023-04-27T08:38:18.710557Z",
     "iopub.status.idle": "2023-04-27T08:38:18.923614Z",
     "shell.execute_reply": "2023-04-27T08:38:18.922637Z",
     "shell.execute_reply.started": "2023-04-27T08:38:18.711469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23e6f2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:16:35.492170Z",
     "iopub.status.busy": "2023-04-28T01:16:35.491012Z",
     "iopub.status.idle": "2023-04-28T01:16:36.587332Z",
     "shell.execute_reply": "2023-04-28T01:16:36.586165Z",
     "shell.execute_reply.started": "2023-04-28T01:16:35.492116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb  state.db\n"
     ]
    }
   ],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f50274f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:20:37.100478Z",
     "iopub.status.busy": "2023-04-28T01:20:37.099165Z",
     "iopub.status.idle": "2023-04-28T01:20:42.341537Z",
     "shell.execute_reply": "2023-04-28T01:20:42.340276Z",
     "shell.execute_reply.started": "2023-04-28T01:20:37.100403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the Best Model on Validation Set: \n",
      "\tTest Loss: 0.0145, Test Accuracy: 0.6071\n"
     ]
    }
   ],
   "source": [
    "print(f\"Testing the Best Model on Validation Set: \")\n",
    "\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "\n",
    "num_features = 176\n",
    "hidden_size = 160\n",
    "num_layers = 5\n",
    "num_classes = 250\n",
    "model = LSTMModel(num_features = num_features, hidden_size = hidden_size, num_layers = num_layers, \n",
    "                  bidirectional = True, num_classes = num_classes, batch_first = True).to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/lstm-best-final/LSTMBestModelFinal.pth\"))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data, labels in val_loader:\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        test_loss +=loss.item()\n",
    "        _,gt = torch.max(outputs,1)\n",
    "        test_acc += torch.sum(labels==gt)\n",
    "\n",
    "    test_loss = test_loss/(len(val_loader)*128)\n",
    "    test_acc = test_acc/(len(val_loader)*128)\n",
    "\n",
    "\n",
    "    print(f'\\tTest Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ccc71f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:20:47.515190Z",
     "iopub.status.busy": "2023-04-28T01:20:47.514797Z",
     "iopub.status.idle": "2023-04-28T01:21:17.798901Z",
     "shell.execute_reply": "2023-04-28T01:21:17.797622Z",
     "shell.execute_reply.started": "2023-04-28T01:20:47.515156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Classification Accuracy on Train Set: 91.0049\n",
      "Mean Classification Accuracy on Validation Set: 60.8636\n"
     ]
    }
   ],
   "source": [
    "def get_mean_classification_accuracy(dataloader):\n",
    "    \n",
    "    acc=[]\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        batch = 0\n",
    "        mean_acc = 0.0\n",
    "        for data, labels in dataloader:\n",
    "            \n",
    "            correct_preds = 0\n",
    "            total_preds = 0\n",
    "            \n",
    "            batch = batch + 1\n",
    "            outputs = model(data)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            correct_preds = correct_preds + torch.sum(preds==labels.data)\n",
    "            total_preds = labels.size(0)\n",
    "            acc.append(correct_preds/total_preds)\n",
    "        mean_acc = torch.mean(torch.tensor(acc))\n",
    "        return mean_acc\n",
    "mean_acc_on_val_set = get_mean_classification_accuracy(val_loader)\n",
    "mean_acc_on_train_set = get_mean_classification_accuracy(train_loader)\n",
    "\n",
    "print(f'Mean Classification Accuracy on Train Set: {100*mean_acc_on_train_set:.4f}')\n",
    "print(f'Mean Classification Accuracy on Validation Set: {100*mean_acc_on_val_set:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdb97da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:21:57.199463Z",
     "iopub.status.busy": "2023-04-28T01:21:57.199068Z",
     "iopub.status.idle": "2023-04-28T01:22:33.716932Z",
     "shell.execute_reply": "2023-04-28T01:22:33.715731Z",
     "shell.execute_reply.started": "2023-04-28T01:21:57.199421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per class accuracies for the train set: \n",
      "TV: 94.1737\n",
      "after: 89.4439\n",
      "airplane: 90.3677\n",
      "all: 89.7665\n",
      "alligator: 91.7978\n",
      "animal: 83.0499\n",
      "another: 93.4681\n",
      "any: 92.5374\n",
      "apple: 92.4334\n",
      "arm: 91.9120\n",
      "aunt: 88.1760\n",
      "awake: 82.1475\n",
      "backyard: 88.1145\n",
      "bad: 91.2642\n",
      "balloon: 89.3557\n",
      "bath: 86.2491\n",
      "because: 94.9661\n",
      "bed: 90.5418\n",
      "bedroom: 88.2997\n",
      "bee: 92.6582\n",
      "before: 88.8988\n",
      "beside: 85.4884\n",
      "better: 93.2278\n",
      "bird: 94.8330\n",
      "black: 94.0474\n",
      "blow: 92.7690\n",
      "blue: 92.0544\n",
      "boat: 87.7916\n",
      "book: 89.7409\n",
      "boy: 90.4888\n",
      "brother: 94.0462\n",
      "brown: 92.3186\n",
      "bug: 96.0853\n",
      "bye: 93.4370\n",
      "callonphone: 93.0413\n",
      "can: 90.6289\n",
      "car: 93.0691\n",
      "carrot: 92.4366\n",
      "cat: 92.7914\n",
      "cereal: 88.5232\n",
      "chair: 85.1005\n",
      "cheek: 88.0806\n",
      "child: 89.4902\n",
      "chin: 84.1703\n",
      "chocolate: 91.6776\n",
      "clean: 91.7321\n",
      "close: 87.1644\n",
      "closet: 89.2115\n",
      "cloud: 94.5443\n",
      "clown: 94.7730\n",
      "cow: 93.5093\n",
      "cowboy: 91.4520\n",
      "cry: 88.4667\n",
      "cut: 89.9021\n",
      "cute: 91.9506\n",
      "dad: 91.0352\n",
      "dance: 87.4305\n",
      "dirty: 93.9280\n",
      "dog: 89.7634\n",
      "doll: 93.6287\n",
      "donkey: 91.7739\n",
      "down: 89.3438\n",
      "drawer: 92.9777\n",
      "drink: 94.8123\n",
      "drop: 84.4466\n",
      "dry: 87.2883\n",
      "dryer: 83.3272\n",
      "duck: 90.1157\n",
      "ear: 88.8993\n",
      "elephant: 92.6824\n",
      "empty: 92.8085\n",
      "every: 93.5403\n",
      "eye: 93.1247\n",
      "face: 91.5567\n",
      "fall: 91.3319\n",
      "farm: 93.0906\n",
      "fast: 91.1756\n",
      "feet: 90.9409\n",
      "find: 95.7299\n",
      "fine: 90.6380\n",
      "finger: 88.7126\n",
      "finish: 95.4293\n",
      "fireman: 94.4774\n",
      "first: 92.7190\n",
      "fish: 89.4777\n",
      "flag: 91.6605\n",
      "flower: 92.8773\n",
      "food: 92.3572\n",
      "for: 95.1905\n",
      "frenchfries: 92.4999\n",
      "frog: 88.5950\n",
      "garbage: 91.4378\n",
      "gift: 91.1729\n",
      "giraffe: 89.4638\n",
      "girl: 92.3882\n",
      "give: 85.7513\n",
      "glasswindow: 80.9728\n",
      "go: 88.4019\n",
      "goose: 85.7056\n",
      "grandma: 90.2164\n",
      "grandpa: 94.1929\n",
      "grass: 95.2682\n",
      "green: 89.7181\n",
      "gum: 87.9393\n",
      "hair: 93.4922\n",
      "happy: 94.0933\n",
      "hat: 91.9040\n",
      "hate: 93.6358\n",
      "have: 91.5488\n",
      "haveto: 89.3100\n",
      "head: 90.9062\n",
      "hear: 87.3109\n",
      "helicopter: 90.4919\n",
      "hello: 90.8840\n",
      "hen: 94.3870\n",
      "hesheit: 85.1377\n",
      "hide: 85.5451\n",
      "high: 93.3371\n",
      "home: 95.3718\n",
      "horse: 92.4900\n",
      "hot: 92.8735\n",
      "hungry: 91.2617\n",
      "icecream: 96.0205\n",
      "if: 90.7066\n",
      "into: 92.5726\n",
      "jacket: 93.9062\n",
      "jeans: 78.9855\n",
      "jump: 93.2559\n",
      "kiss: 93.1503\n",
      "kitty: 88.9302\n",
      "lamp: 88.3911\n",
      "later: 93.5070\n",
      "like: 90.4270\n",
      "lion: 92.1058\n",
      "lips: 88.1117\n",
      "listen: 94.6607\n",
      "look: 91.1435\n",
      "loud: 93.5965\n",
      "mad: 96.1956\n",
      "make: 88.4835\n",
      "man: 92.9447\n",
      "many: 87.0284\n",
      "milk: 90.7261\n",
      "minemy: 87.9799\n",
      "mitten: 96.6099\n",
      "mom: 93.6540\n",
      "moon: 93.0441\n",
      "morning: 90.2037\n",
      "mouse: 91.9410\n",
      "mouth: 79.2595\n",
      "nap: 86.4062\n",
      "napkin: 92.5821\n",
      "night: 90.7503\n",
      "no: 90.6039\n",
      "noisy: 90.8821\n",
      "nose: 91.0909\n",
      "not: 90.8018\n",
      "now: 92.1184\n",
      "nuts: 94.8503\n",
      "old: 88.9803\n",
      "on: 87.5682\n",
      "open: 88.2810\n",
      "orange: 94.0199\n",
      "outside: 93.9367\n",
      "owie: 91.0128\n",
      "owl: 94.4188\n",
      "pajamas: 93.0981\n",
      "pen: 88.0170\n",
      "pencil: 90.9067\n",
      "penny: 92.0283\n",
      "person: 93.1275\n",
      "pig: 87.4869\n",
      "pizza: 94.5935\n",
      "please: 89.3744\n",
      "police: 91.2567\n",
      "pool: 86.4437\n",
      "potty: 85.7588\n",
      "pretend: 86.2328\n",
      "pretty: 91.0255\n",
      "puppy: 83.7799\n",
      "puzzle: 86.9660\n",
      "quiet: 92.0262\n",
      "radio: 93.6264\n",
      "rain: 93.2176\n",
      "read: 87.6896\n",
      "red: 90.3856\n",
      "refrigerator: 92.0181\n",
      "ride: 89.2402\n",
      "room: 91.6705\n",
      "sad: 91.5937\n",
      "same: 88.2806\n",
      "say: 87.5482\n",
      "scissors: 94.8776\n",
      "see: 93.6978\n",
      "shhh: 94.6665\n",
      "shirt: 89.8326\n",
      "shoe: 85.6150\n",
      "shower: 92.2435\n",
      "sick: 92.8401\n",
      "sleep: 92.7510\n",
      "sleepy: 90.7578\n",
      "smile: 95.2649\n",
      "snack: 90.1289\n",
      "snow: 93.3289\n",
      "stairs: 86.3012\n",
      "stay: 90.1357\n",
      "sticky: 89.2903\n",
      "store: 89.6013\n",
      "story: 91.4787\n",
      "stuck: 94.2785\n",
      "sun: 94.5294\n",
      "table: 90.9171\n",
      "talk: 93.2982\n",
      "taste: 95.0961\n",
      "thankyou: 94.2677\n",
      "that: 91.0111\n",
      "there: 88.5353\n",
      "think: 90.9684\n",
      "thirsty: 90.1884\n",
      "tiger: 93.7245\n",
      "time: 89.9370\n",
      "tomorrow: 93.4883\n",
      "tongue: 86.9368\n",
      "tooth: 84.4033\n",
      "toothbrush: 85.9440\n",
      "touch: 89.5085\n",
      "toy: 89.5335\n",
      "tree: 90.2326\n",
      "uncle: 92.8309\n",
      "underwear: 87.7925\n",
      "up: 92.9487\n",
      "vacuum: 82.7865\n",
      "wait: 88.7516\n",
      "wake: 83.4568\n",
      "water: 91.9809\n",
      "wet: 88.8180\n",
      "weus: 90.7274\n",
      "where: 93.0704\n",
      "white: 87.3298\n",
      "who: 88.4744\n",
      "why: 92.2069\n",
      "will: 91.4840\n",
      "wolf: 92.5572\n",
      "yellow: 92.2211\n",
      "yes: 85.1483\n",
      "yesterday: 94.7926\n",
      "yourself: 87.2082\n",
      "yucky: 90.8380\n",
      "zebra: 92.5657\n",
      "zipper: 80.5957\n",
      "Mean per class accuracies for the validation set: \n",
      "TV: 60.6795\n",
      "after: 26.9055\n",
      "airplane: 59.7037\n",
      "all: 45.4319\n",
      "alligator: 51.4591\n",
      "animal: 41.4805\n",
      "another: 65.3000\n",
      "any: 60.8473\n",
      "apple: 70.1270\n",
      "arm: 75.5288\n",
      "aunt: 67.5949\n",
      "awake: 23.6420\n",
      "backyard: 33.1001\n",
      "bad: 51.9980\n",
      "balloon: 66.8950\n",
      "bath: 49.5564\n",
      "because: 86.0581\n",
      "bed: 67.0649\n",
      "bedroom: 52.6177\n",
      "bee: 50.3332\n",
      "before: 57.2275\n",
      "beside: 41.6377\n",
      "better: 90.8188\n",
      "bird: 89.3178\n",
      "black: 75.0438\n",
      "blow: 77.7010\n",
      "blue: 64.1604\n",
      "boat: 46.1739\n",
      "book: 64.4707\n",
      "boy: 52.5216\n",
      "brother: 61.1310\n",
      "brown: 73.4643\n",
      "bug: 65.9685\n",
      "bye: 77.1708\n",
      "callonphone: 82.2192\n",
      "can: 63.9530\n",
      "car: 50.2325\n",
      "carrot: 71.1836\n",
      "cat: 27.5744\n",
      "cereal: 44.0222\n",
      "chair: 31.4090\n",
      "cheek: 83.1164\n",
      "child: 66.5191\n",
      "chin: 51.4486\n",
      "chocolate: 82.0961\n",
      "clean: 49.3659\n",
      "close: 42.5426\n",
      "closet: 71.2384\n",
      "cloud: 32.7099\n",
      "clown: 84.8715\n",
      "cow: 76.9109\n",
      "cowboy: 81.9942\n",
      "cry: 60.3862\n",
      "cut: 45.2519\n",
      "cute: 77.2999\n",
      "dad: 62.7096\n",
      "dance: 46.5968\n",
      "dirty: 58.2207\n",
      "dog: 54.8051\n",
      "doll: 63.5602\n",
      "donkey: 61.9857\n",
      "down: 38.0775\n",
      "drawer: 39.6842\n",
      "drink: 69.4907\n",
      "drop: 51.0089\n",
      "dry: 87.0476\n",
      "dryer: 48.1234\n",
      "duck: 58.7885\n",
      "ear: 75.1920\n",
      "elephant: 79.8770\n",
      "empty: 51.0859\n",
      "every: 50.9892\n",
      "eye: 70.1834\n",
      "face: 75.7055\n",
      "fall: 55.2736\n",
      "farm: 69.0300\n",
      "fast: 39.6037\n",
      "feet: 64.6929\n",
      "find: 73.0712\n",
      "fine: 54.6541\n",
      "finger: 44.4854\n",
      "finish: 56.3701\n",
      "fireman: 81.7037\n",
      "first: 59.6823\n",
      "fish: 46.5316\n",
      "flag: 49.2991\n",
      "flower: 87.7899\n",
      "food: 82.1301\n",
      "for: 68.1189\n",
      "frenchfries: 67.0992\n",
      "frog: 74.0343\n",
      "garbage: 44.2373\n",
      "gift: 50.8423\n",
      "giraffe: 79.1828\n",
      "girl: 67.3495\n",
      "give: 20.9160\n",
      "glasswindow: 51.2809\n",
      "go: 43.1259\n",
      "goose: 36.9473\n",
      "grandma: 59.3082\n",
      "grandpa: 84.3951\n",
      "grass: 73.8197\n",
      "green: 64.7923\n",
      "gum: 75.2882\n",
      "hair: 81.3860\n",
      "happy: 64.5732\n",
      "hat: 52.0133\n",
      "hate: 60.5556\n",
      "have: 64.8195\n",
      "haveto: 40.8193\n",
      "head: 48.5851\n",
      "hear: 41.3536\n",
      "helicopter: 39.7942\n",
      "hello: 47.4125\n",
      "hen: 75.9468\n",
      "hesheit: 48.0669\n",
      "hide: 49.0663\n",
      "high: 79.1025\n",
      "home: 75.6506\n",
      "horse: 57.7950\n",
      "hot: 64.8739\n",
      "hungry: 77.9136\n",
      "icecream: 85.1555\n",
      "if: 61.0313\n",
      "into: 37.7722\n",
      "jacket: 71.0702\n",
      "jeans: 50.8299\n",
      "jump: 50.7617\n",
      "kiss: 51.6788\n",
      "kitty: 52.1092\n",
      "lamp: 55.7661\n",
      "later: 81.8954\n",
      "like: 65.4714\n",
      "lion: 56.6256\n",
      "lips: 40.5847\n",
      "listen: 64.7861\n",
      "look: 64.6286\n",
      "loud: 64.6404\n",
      "mad: 56.9108\n",
      "make: 39.2013\n",
      "man: 81.6889\n",
      "many: 51.2817\n",
      "milk: 56.5213\n",
      "minemy: 71.7723\n",
      "mitten: 54.9871\n",
      "mom: 59.5453\n",
      "moon: 62.9860\n",
      "morning: 56.6571\n",
      "mouse: 76.4409\n",
      "mouth: 40.5979\n",
      "nap: 37.6225\n",
      "napkin: 72.3665\n",
      "night: 54.6247\n",
      "no: 58.0504\n",
      "noisy: 31.6778\n",
      "nose: 58.6299\n",
      "not: 59.0755\n",
      "now: 76.4000\n",
      "nuts: 61.6433\n",
      "old: 61.9970\n",
      "on: 31.7538\n",
      "open: 71.3196\n",
      "orange: 73.8357\n",
      "outside: 68.1578\n",
      "owie: 39.8320\n",
      "owl: 92.2934\n",
      "pajamas: 41.7833\n",
      "pen: 20.3221\n",
      "pencil: 44.7018\n",
      "penny: 64.6372\n",
      "person: 38.8677\n",
      "pig: 61.4744\n",
      "pizza: 70.6436\n",
      "please: 79.5888\n",
      "police: 81.0770\n",
      "pool: 36.7673\n",
      "potty: 30.8473\n",
      "pretend: 51.8526\n",
      "pretty: 69.5770\n",
      "puppy: 31.5091\n",
      "puzzle: 46.4854\n",
      "quiet: 78.7566\n",
      "radio: 78.2551\n",
      "rain: 36.7067\n",
      "read: 28.6379\n",
      "red: 41.1285\n",
      "refrigerator: 50.8026\n",
      "ride: 46.0645\n",
      "room: 47.9667\n",
      "sad: 69.1677\n",
      "same: 52.1828\n",
      "say: 74.8333\n",
      "scissors: 48.4378\n",
      "see: 74.3049\n",
      "shhh: 85.5954\n",
      "shirt: 70.7880\n",
      "shoe: 75.2196\n",
      "shower: 59.2353\n",
      "sick: 72.9607\n",
      "sleep: 40.7073\n",
      "sleepy: 50.9089\n",
      "smile: 65.6924\n",
      "snack: 43.0015\n",
      "snow: 75.0338\n",
      "stairs: 69.8531\n",
      "stay: 45.7862\n",
      "sticky: 33.8459\n",
      "store: 79.2749\n",
      "story: 57.8725\n",
      "stuck: 69.7882\n",
      "sun: 67.6184\n",
      "table: 56.0228\n",
      "talk: 77.7317\n",
      "taste: 76.8369\n",
      "thankyou: 70.7740\n",
      "that: 62.4460\n",
      "there: 28.2827\n",
      "think: 63.5804\n",
      "thirsty: 90.1266\n",
      "tiger: 74.7253\n",
      "time: 63.1751\n",
      "tomorrow: 75.7211\n",
      "tongue: 46.1994\n",
      "tooth: 46.9530\n",
      "toothbrush: 79.2340\n",
      "touch: 65.5425\n",
      "toy: 50.7094\n",
      "tree: 69.1264\n",
      "uncle: 77.8242\n",
      "underwear: 76.9001\n",
      "up: 67.9488\n",
      "vacuum: 42.7533\n",
      "wait: 62.7552\n",
      "wake: 57.3776\n",
      "water: 84.4559\n",
      "wet: 54.0386\n",
      "weus: 66.4894\n",
      "where: 61.5220\n",
      "white: 38.0867\n",
      "who: 75.1903\n",
      "why: 52.0150\n",
      "will: 48.7828\n",
      "wolf: 81.9250\n",
      "yellow: 72.5474\n",
      "yes: 58.2005\n",
      "yesterday: 83.4272\n",
      "yourself: 55.7538\n",
      "yucky: 71.5831\n",
      "zebra: 55.5522\n",
      "zipper: 39.5634\n"
     ]
    }
   ],
   "source": [
    "def get_mean_per_class_accuracy(dataloader):\n",
    "    with torch.no_grad():\n",
    "        class_acc = [[] for i in range(250)]\n",
    "        \n",
    "        num_classes = 250\n",
    "        class_correct = [0] * num_classes\n",
    "        class_total = [0] * num_classes\n",
    "        for data, labels in dataloader:\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            for i in range(num_classes):\n",
    "                if class_total[i]==0:\n",
    "                    class_acc[i].append(0)\n",
    "                else:\n",
    "                    class_acc[i].append(class_correct[i]/class_total[i])\n",
    "        mean_per_class_acc_list = [torch.mean(torch.tensor(class_acc[i])) for i in range(len(class_acc))]\n",
    "        return mean_per_class_acc_list\n",
    "    \n",
    "import json\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "\n",
    "s2p_map = read_json(os.path.join(\"/kaggle/input/sign-to-pred/sign_to_prediction_index_map.json\"))\n",
    "p2s_map = {v: k for k, v in s2p_map.items()}\n",
    "\n",
    "encoder = lambda x: s2p_map.get(x)\n",
    "decoder = lambda x: p2s_map.get(x)\n",
    "\n",
    "\n",
    "print('Mean per class accuracies for the train set: ')\n",
    "train_mean_per_class_acc = get_mean_per_class_accuracy(train_loader)\n",
    "for i in range(len(train_mean_per_class_acc)):\n",
    "    print(f'{p2s_map[i]}: {100*train_mean_per_class_acc[i]:.4f}')\n",
    "    \n",
    "print('Mean per class accuracies for the validation set: ')\n",
    "val_mean_per_class_acc = get_mean_per_class_accuracy(val_loader)\n",
    "for i in range(len(val_mean_per_class_acc)):\n",
    "    print(f'{p2s_map[i]}: {100*val_mean_per_class_acc[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f739f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in val_loader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [v for k,v in p2s_map.items()],\n",
    "                     columns = [v for k,v in p2s_map.items()])\n",
    "plt.figure(figsize = (250,250))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "# plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45cc17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d30d0b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T05:44:52.277855Z",
     "iopub.status.busy": "2023-04-25T05:44:52.277326Z",
     "iopub.status.idle": "2023-04-25T05:44:53.521436Z",
     "shell.execute_reply": "2023-04-25T05:44:53.520406Z",
     "shell.execute_reply.started": "2023-04-25T05:44:52.277812Z"
    }
   },
   "outputs": [],
   "source": [
    "num_features = 176\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "num_classes = 250\n",
    "model = LSTMModel(num_features = num_features, hidden_size = hidden_size, num_layers = num_layers, \n",
    "                  bidirectional = True, num_classes = num_classes, batch_first = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd76ce76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T05:44:53.523574Z",
     "iopub.status.busy": "2023-04-25T05:44:53.523206Z",
     "iopub.status.idle": "2023-04-25T13:00:20.726145Z",
     "shell.execute_reply": "2023-04-25T13:00:20.724855Z",
     "shell.execute_reply.started": "2023-04-25T05:44:53.523536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 333/333 [01:28<00:00,  3.77it/s, accuracy=0.428, loss=2.47, val_accuracy=0.396, val_loss=2.59]\n",
      "Epoch 2: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.566, loss=1.7, val_accuracy=0.461, val_loss=2.3] \n",
      "Epoch 3: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.584, loss=1.62, val_accuracy=0.439, val_loss=2.42]\n",
      "Epoch 4: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.622, loss=1.49, val_accuracy=0.435, val_loss=2.43]\n",
      "Epoch 5: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.66, loss=1.36, val_accuracy=0.485, val_loss=2.22]\n",
      "Epoch 6: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.701, loss=1.23, val_accuracy=0.494, val_loss=2.18]\n",
      "Epoch 7: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.735, loss=1.12, val_accuracy=0.507, val_loss=2.15]\n",
      "Epoch 8: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.76, loss=1.04, val_accuracy=0.511, val_loss=2.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.606, loss=1.55, val_accuracy=0.439, val_loss=2.43]\n",
      "Epoch 10: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.611, loss=1.52, val_accuracy=0.451, val_loss=2.38]\n",
      "Epoch 11: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.629, loss=1.46, val_accuracy=0.459, val_loss=2.35]\n",
      "Epoch 12: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.657, loss=1.36, val_accuracy=0.471, val_loss=2.3] \n",
      "Epoch 13: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.695, loss=1.23, val_accuracy=0.469, val_loss=2.31]\n",
      "Epoch 14: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.734, loss=1.11, val_accuracy=0.497, val_loss=2.2] \n",
      "Epoch 15: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.769, loss=0.997, val_accuracy=0.511, val_loss=2.16]\n",
      "Epoch 16: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.792, loss=0.925, val_accuracy=0.51, val_loss=2.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.628, loss=1.44, val_accuracy=0.454, val_loss=2.36]\n",
      "Epoch 18: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.639, loss=1.4, val_accuracy=0.44, val_loss=2.45] \n",
      "Epoch 19: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.655, loss=1.35, val_accuracy=0.438, val_loss=2.48]\n",
      "Epoch 20: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.683, loss=1.25, val_accuracy=0.484, val_loss=2.25]\n",
      "Epoch 21: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.718, loss=1.13, val_accuracy=0.496, val_loss=2.23]\n",
      "Epoch 22: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.761, loss=1, val_accuracy=0.511, val_loss=2.19]\n",
      "Epoch 23: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.797, loss=0.895, val_accuracy=0.514, val_loss=2.17]\n",
      "Epoch 24: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.822, loss=0.824, val_accuracy=0.516, val_loss=2.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.666, loss=1.3, val_accuracy=0.464, val_loss=2.37]\n",
      "Epoch 26: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.662, loss=1.32, val_accuracy=0.445, val_loss=2.5] \n",
      "Epoch 27: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.669, loss=1.28, val_accuracy=0.464, val_loss=2.38]\n",
      "Epoch 28: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.704, loss=1.17, val_accuracy=0.467, val_loss=2.35]\n",
      "Epoch 29: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.743, loss=1.05, val_accuracy=0.5, val_loss=2.25]  \n",
      "Epoch 30: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.784, loss=0.92, val_accuracy=0.508, val_loss=2.23]\n",
      "Epoch 31: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.821, loss=0.811, val_accuracy=0.519, val_loss=2.2] \n",
      "Epoch 32: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.845, loss=0.742, val_accuracy=0.519, val_loss=2.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.668, loss=1.29, val_accuracy=0.438, val_loss=2.5] \n",
      "Epoch 34: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.674, loss=1.26, val_accuracy=0.446, val_loss=2.47]\n",
      "Epoch 35: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.682, loss=1.23, val_accuracy=0.492, val_loss=2.3] \n",
      "Epoch 36: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.718, loss=1.11, val_accuracy=0.485, val_loss=2.31]\n",
      "Epoch 37: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.76, loss=0.978, val_accuracy=0.484, val_loss=2.35]\n",
      "Epoch 38: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.805, loss=0.845, val_accuracy=0.513, val_loss=2.24]\n",
      "Epoch 39: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.842, loss=0.74, val_accuracy=0.521, val_loss=2.21]\n",
      "Epoch 40: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.868, loss=0.665, val_accuracy=0.523, val_loss=2.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.689, loss=1.2, val_accuracy=0.446, val_loss=2.51]\n",
      "Epoch 42: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.687, loss=1.2, val_accuracy=0.474, val_loss=2.4] \n",
      "Epoch 43: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.701, loss=1.16, val_accuracy=0.469, val_loss=2.4] \n",
      "Epoch 44: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.741, loss=1.03, val_accuracy=0.493, val_loss=2.33]\n",
      "Epoch 45: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.779, loss=0.91, val_accuracy=0.514, val_loss=2.24]\n",
      "Epoch 46: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.825, loss=0.776, val_accuracy=0.513, val_loss=2.28]\n",
      "Epoch 47: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.86, loss=0.673, val_accuracy=0.521, val_loss=2.24]\n",
      "Epoch 48: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.885, loss=0.605, val_accuracy=0.524, val_loss=2.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.709, loss=1.12, val_accuracy=0.484, val_loss=2.44]\n",
      "Epoch 50: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.7, loss=1.16, val_accuracy=0.468, val_loss=2.4] \n",
      "Epoch 51: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.718, loss=1.09, val_accuracy=0.456, val_loss=2.51]\n",
      "Epoch 52: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.752, loss=0.985, val_accuracy=0.499, val_loss=2.3] \n",
      "Epoch 53: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.794, loss=0.858, val_accuracy=0.5, val_loss=2.33]  \n",
      "Epoch 54: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.841, loss=0.719, val_accuracy=0.517, val_loss=2.28]\n",
      "Epoch 55: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.877, loss=0.615, val_accuracy=0.525, val_loss=2.24]\n",
      "Epoch 56: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.899, loss=0.553, val_accuracy=0.523, val_loss=2.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.72, loss=1.09, val_accuracy=0.491, val_loss=2.39]\n",
      "Epoch 58: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.715, loss=1.09, val_accuracy=0.436, val_loss=2.62]\n",
      "Epoch 59: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.735, loss=1.03, val_accuracy=0.463, val_loss=2.5] \n",
      "Epoch 60: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.768, loss=0.927, val_accuracy=0.475, val_loss=2.43]\n",
      "Epoch 61: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.809, loss=0.802, val_accuracy=0.509, val_loss=2.32]\n",
      "Epoch 62: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.858, loss=0.663, val_accuracy=0.514, val_loss=2.31]\n",
      "Epoch 63: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.891, loss=0.569, val_accuracy=0.522, val_loss=2.3] \n",
      "Epoch 64: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.912, loss=0.508, val_accuracy=0.524, val_loss=2.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.735, loss=1.03, val_accuracy=0.449, val_loss=2.65]\n",
      "Epoch 66: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.714, loss=1.1, val_accuracy=0.463, val_loss=2.53]\n",
      "Epoch 67: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.75, loss=0.978, val_accuracy=0.47, val_loss=2.53] \n",
      "Epoch 68: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.78, loss=0.881, val_accuracy=0.496, val_loss=2.35]\n",
      "Epoch 69: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.829, loss=0.74, val_accuracy=0.509, val_loss=2.35]\n",
      "Epoch 70: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.871, loss=0.621, val_accuracy=0.523, val_loss=2.31]\n",
      "Epoch 71: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.902, loss=0.527, val_accuracy=0.519, val_loss=2.31]\n",
      "Epoch 72: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.921, loss=0.468, val_accuracy=0.522, val_loss=2.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.757, loss=0.949, val_accuracy=0.441, val_loss=2.72]\n",
      "Epoch 74: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.738, loss=1, val_accuracy=0.483, val_loss=2.46]\n",
      "Epoch 75: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.761, loss=0.937, val_accuracy=0.487, val_loss=2.41]\n",
      "Epoch 76: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.792, loss=0.841, val_accuracy=0.491, val_loss=2.42]\n",
      "Epoch 77: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.837, loss=0.704, val_accuracy=0.506, val_loss=2.36]\n",
      "Epoch 78: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.879, loss=0.588, val_accuracy=0.508, val_loss=2.39]\n",
      "Epoch 79: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.913, loss=0.49, val_accuracy=0.527, val_loss=2.32]\n",
      "Epoch 80: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.928, loss=0.437, val_accuracy=0.527, val_loss=2.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.745, loss=0.986, val_accuracy=0.464, val_loss=2.58]\n",
      "Epoch 82: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.75, loss=0.965, val_accuracy=0.48, val_loss=2.48] \n",
      "Epoch 83: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.765, loss=0.915, val_accuracy=0.467, val_loss=2.58]\n",
      "Epoch 84: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.803, loss=0.803, val_accuracy=0.492, val_loss=2.43]\n",
      "Epoch 85: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.852, loss=0.658, val_accuracy=0.52, val_loss=2.33] \n",
      "Epoch 86: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.89, loss=0.551, val_accuracy=0.513, val_loss=2.38]\n",
      "Epoch 87: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.92, loss=0.463, val_accuracy=0.521, val_loss=2.37]\n",
      "Epoch 88: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.934, loss=0.411, val_accuracy=0.53, val_loss=2.36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.763, loss=0.926, val_accuracy=0.474, val_loss=2.57]\n",
      "Epoch 90: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.76, loss=0.932, val_accuracy=0.47, val_loss=2.57] \n",
      "Epoch 91: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.77, loss=0.895, val_accuracy=0.448, val_loss=2.68]\n",
      "Epoch 92: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.814, loss=0.764, val_accuracy=0.503, val_loss=2.42]\n",
      "Epoch 93: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.856, loss=0.644, val_accuracy=0.512, val_loss=2.4] \n",
      "Epoch 94: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.899, loss=0.52, val_accuracy=0.521, val_loss=2.41]\n",
      "Epoch 95: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.926, loss=0.435, val_accuracy=0.527, val_loss=2.39]\n",
      "Epoch 96: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.939, loss=0.388, val_accuracy=0.527, val_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.777, loss=0.878, val_accuracy=0.448, val_loss=2.73]\n",
      "Epoch 98: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.768, loss=0.898, val_accuracy=0.476, val_loss=2.57]\n",
      "Epoch 99: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.798, loss=0.808, val_accuracy=0.462, val_loss=2.66]\n",
      "Epoch 100: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.821, loss=0.742, val_accuracy=0.473, val_loss=2.55]\n",
      "Epoch 101: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.868, loss=0.605, val_accuracy=0.505, val_loss=2.44]\n",
      "Epoch 102: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.906, loss=0.493, val_accuracy=0.512, val_loss=2.42]\n",
      "Epoch 103: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.93, loss=0.416, val_accuracy=0.527, val_loss=2.41]\n",
      "Epoch 104: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.942, loss=0.371, val_accuracy=0.53, val_loss=2.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.773, loss=0.892, val_accuracy=0.465, val_loss=2.66]\n",
      "Epoch 106: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.779, loss=0.866, val_accuracy=0.444, val_loss=2.76]\n",
      "Epoch 107: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.79, loss=0.828, val_accuracy=0.474, val_loss=2.56]\n",
      "Epoch 108: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.828, loss=0.719, val_accuracy=0.5, val_loss=2.46]  \n",
      "Epoch 109: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.877, loss=0.578, val_accuracy=0.494, val_loss=2.52]\n",
      "Epoch 110: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.912, loss=0.472, val_accuracy=0.523, val_loss=2.41]\n",
      "Epoch 111: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.934, loss=0.399, val_accuracy=0.528, val_loss=2.41]\n",
      "Epoch 112: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.944, loss=0.358, val_accuracy=0.529, val_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.778, loss=0.865, val_accuracy=0.472, val_loss=2.62]\n",
      "Epoch 114: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.776, loss=0.874, val_accuracy=0.462, val_loss=2.65]\n",
      "Epoch 115: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.8, loss=0.8, val_accuracy=0.486, val_loss=2.54]\n",
      "Epoch 116: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.836, loss=0.687, val_accuracy=0.498, val_loss=2.48]\n",
      "Epoch 117: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.88, loss=0.561, val_accuracy=0.516, val_loss=2.44]\n",
      "Epoch 118: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.917, loss=0.457, val_accuracy=0.518, val_loss=2.44]\n",
      "Epoch 119: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.937, loss=0.384, val_accuracy=0.527, val_loss=2.43]\n",
      "Epoch 120: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.946, loss=0.345, val_accuracy=0.53, val_loss=2.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.794, loss=0.815, val_accuracy=0.478, val_loss=2.63]\n",
      "Epoch 122: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.79, loss=0.826, val_accuracy=0.48, val_loss=2.6]  \n",
      "Epoch 123: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.806, loss=0.779, val_accuracy=0.478, val_loss=2.6] \n",
      "Epoch 124: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.838, loss=0.678, val_accuracy=0.469, val_loss=2.67]\n",
      "Epoch 125: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.887, loss=0.539, val_accuracy=0.512, val_loss=2.47]\n",
      "Epoch 126: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.92, loss=0.442, val_accuracy=0.52, val_loss=2.44] \n",
      "Epoch 127: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.939, loss=0.373, val_accuracy=0.527, val_loss=2.46]\n",
      "Epoch 128: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.947, loss=0.337, val_accuracy=0.533, val_loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.8, loss=0.796, val_accuracy=0.476, val_loss=2.68]\n",
      "Epoch 130: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.797, loss=0.806, val_accuracy=0.482, val_loss=2.63]\n",
      "Epoch 131: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.818, loss=0.739, val_accuracy=0.465, val_loss=2.72]\n",
      "Epoch 132: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.852, loss=0.636, val_accuracy=0.515, val_loss=2.45]\n",
      "Epoch 133: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.89, loss=0.525, val_accuracy=0.514, val_loss=2.47]\n",
      "Epoch 134: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.923, loss=0.429, val_accuracy=0.517, val_loss=2.51]\n",
      "Epoch 135: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.941, loss=0.362, val_accuracy=0.533, val_loss=2.47]\n",
      "Epoch 136: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.948, loss=0.329, val_accuracy=0.535, val_loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.81, loss=0.767, val_accuracy=0.454, val_loss=2.81]\n",
      "Epoch 138: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.804, loss=0.785, val_accuracy=0.47, val_loss=2.69] \n",
      "Epoch 139: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.826, loss=0.716, val_accuracy=0.441, val_loss=2.82]\n",
      "Epoch 140: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.855, loss=0.627, val_accuracy=0.496, val_loss=2.56]\n",
      "Epoch 141: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.891, loss=0.522, val_accuracy=0.511, val_loss=2.52]\n",
      "Epoch 142: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.925, loss=0.422, val_accuracy=0.525, val_loss=2.49]\n",
      "Epoch 143: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.943, loss=0.353, val_accuracy=0.532, val_loss=2.47]\n",
      "Epoch 144: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.948, loss=0.323, val_accuracy=0.534, val_loss=2.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.813, loss=0.755, val_accuracy=0.479, val_loss=2.65]\n",
      "Epoch 146: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.806, loss=0.774, val_accuracy=0.484, val_loss=2.63]\n",
      "Epoch 147: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.824, loss=0.716, val_accuracy=0.488, val_loss=2.6] \n",
      "Epoch 148: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.856, loss=0.622, val_accuracy=0.497, val_loss=2.59]\n",
      "Epoch 149: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.898, loss=0.499, val_accuracy=0.512, val_loss=2.52]\n",
      "Epoch 150: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.928, loss=0.406, val_accuracy=0.523, val_loss=2.51]\n",
      "Epoch 151: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.943, loss=0.349, val_accuracy=0.529, val_loss=2.52]\n",
      "Epoch 152: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.948, loss=0.317, val_accuracy=0.531, val_loss=2.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.824, loss=0.712, val_accuracy=0.47, val_loss=2.77] \n",
      "Epoch 154: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.814, loss=0.751, val_accuracy=0.47, val_loss=2.7]  \n",
      "Epoch 155: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.829, loss=0.701, val_accuracy=0.476, val_loss=2.71]\n",
      "Epoch 156: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.864, loss=0.602, val_accuracy=0.484, val_loss=2.65]\n",
      "Epoch 157: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.902, loss=0.488, val_accuracy=0.513, val_loss=2.53]\n",
      "Epoch 158: 100%|██████████| 333/333 [01:27<00:00,  3.79it/s, accuracy=0.929, loss=0.399, val_accuracy=0.525, val_loss=2.5] \n",
      "Epoch 159: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.945, loss=0.341, val_accuracy=0.531, val_loss=2.5] \n",
      "Epoch 160: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.949, loss=0.312, val_accuracy=0.535, val_loss=2.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 161: 100%|██████████| 333/333 [01:27<00:00,  3.79it/s, accuracy=0.822, loss=0.723, val_accuracy=0.499, val_loss=2.66]\n",
      "Epoch 162: 100%|██████████| 333/333 [01:28<00:00,  3.78it/s, accuracy=0.811, loss=0.755, val_accuracy=0.474, val_loss=2.72]\n",
      "Epoch 163: 100%|██████████| 333/333 [01:27<00:00,  3.78it/s, accuracy=0.833, loss=0.689, val_accuracy=0.459, val_loss=2.83]\n",
      "Epoch 164: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.86, loss=0.607, val_accuracy=0.48, val_loss=2.65] \n",
      "Epoch 165: 100%|██████████| 333/333 [01:27<00:00,  3.79it/s, accuracy=0.901, loss=0.486, val_accuracy=0.514, val_loss=2.55]\n",
      "Epoch 166: 100%|██████████| 333/333 [01:27<00:00,  3.79it/s, accuracy=0.928, loss=0.401, val_accuracy=0.515, val_loss=2.53]\n",
      "Epoch 167: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.944, loss=0.338, val_accuracy=0.532, val_loss=2.51]\n",
      "Epoch 168: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.949, loss=0.31, val_accuracy=0.541, val_loss=2.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.825, loss=0.715, val_accuracy=0.451, val_loss=2.9] \n",
      "Epoch 170: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.815, loss=0.742, val_accuracy=0.469, val_loss=2.75]\n",
      "Epoch 171: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.831, loss=0.694, val_accuracy=0.493, val_loss=2.57]\n",
      "Epoch 172: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.87, loss=0.577, val_accuracy=0.497, val_loss=2.62]\n",
      "Epoch 173: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.904, loss=0.475, val_accuracy=0.51, val_loss=2.54] \n",
      "Epoch 174: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.932, loss=0.388, val_accuracy=0.521, val_loss=2.56]\n",
      "Epoch 175: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.945, loss=0.333, val_accuracy=0.528, val_loss=2.52]\n",
      "Epoch 176: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.949, loss=0.307, val_accuracy=0.534, val_loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 177: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.83, loss=0.699, val_accuracy=0.497, val_loss=2.62]\n",
      "Epoch 178: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.826, loss=0.707, val_accuracy=0.477, val_loss=2.72]\n",
      "Epoch 179: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.842, loss=0.665, val_accuracy=0.492, val_loss=2.61]\n",
      "Epoch 180: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.875, loss=0.561, val_accuracy=0.503, val_loss=2.6] \n",
      "Epoch 181: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.907, loss=0.465, val_accuracy=0.516, val_loss=2.56]\n",
      "Epoch 182: 100%|██████████| 333/333 [01:27<00:00,  3.79it/s, accuracy=0.932, loss=0.386, val_accuracy=0.528, val_loss=2.52]\n",
      "Epoch 183: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.946, loss=0.328, val_accuracy=0.536, val_loss=2.53]\n",
      "Epoch 184: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.949, loss=0.303, val_accuracy=0.539, val_loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 185: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.84, loss=0.666, val_accuracy=0.466, val_loss=2.85]\n",
      "Epoch 186: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.824, loss=0.715, val_accuracy=0.485, val_loss=2.7] \n",
      "Epoch 187: 100%|██████████| 333/333 [01:27<00:00,  3.79it/s, accuracy=0.834, loss=0.68, val_accuracy=0.496, val_loss=2.6] \n",
      "Epoch 188: 100%|██████████| 333/333 [01:27<00:00,  3.80it/s, accuracy=0.87, loss=0.572, val_accuracy=0.49, val_loss=2.67] \n",
      "Epoch 189: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.906, loss=0.468, val_accuracy=0.514, val_loss=2.57]\n",
      "Epoch 190: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.935, loss=0.376, val_accuracy=0.521, val_loss=2.56]\n",
      "Epoch 191: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.946, loss=0.326, val_accuracy=0.53, val_loss=2.56] \n",
      "Epoch 192: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.949, loss=0.304, val_accuracy=0.541, val_loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 193: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.839, loss=0.664, val_accuracy=0.476, val_loss=2.76]\n",
      "Epoch 194: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.826, loss=0.712, val_accuracy=0.477, val_loss=2.75]\n",
      "Epoch 195: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.848, loss=0.64, val_accuracy=0.492, val_loss=2.66]\n",
      "Epoch 196: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.872, loss=0.566, val_accuracy=0.513, val_loss=2.56]\n",
      "Epoch 197: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.908, loss=0.456, val_accuracy=0.516, val_loss=2.59]\n",
      "Epoch 198: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.934, loss=0.372, val_accuracy=0.52, val_loss=2.57] \n",
      "Epoch 199: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.947, loss=0.322, val_accuracy=0.537, val_loss=2.54]\n",
      "Epoch 200: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.95, loss=0.298, val_accuracy=0.535, val_loss=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 201: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.85, loss=0.629, val_accuracy=0.468, val_loss=2.83]\n",
      "Epoch 202: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.84, loss=0.662, val_accuracy=0.449, val_loss=2.89]\n",
      "Epoch 203: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.853, loss=0.62, val_accuracy=0.482, val_loss=2.71]\n",
      "Epoch 204: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.883, loss=0.53, val_accuracy=0.489, val_loss=2.73]\n",
      "Epoch 205: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.909, loss=0.449, val_accuracy=0.514, val_loss=2.59]\n",
      "Epoch 206: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.936, loss=0.366, val_accuracy=0.526, val_loss=2.58]\n",
      "Epoch 207: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.947, loss=0.319, val_accuracy=0.535, val_loss=2.54]\n",
      "Epoch 208: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.95, loss=0.297, val_accuracy=0.539, val_loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.841, loss=0.664, val_accuracy=0.452, val_loss=2.93]\n",
      "Epoch 210: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.839, loss=0.665, val_accuracy=0.472, val_loss=2.78]\n",
      "Epoch 211: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.848, loss=0.639, val_accuracy=0.498, val_loss=2.58]\n",
      "Epoch 212: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.881, loss=0.537, val_accuracy=0.511, val_loss=2.57]\n",
      "Epoch 213: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.914, loss=0.439, val_accuracy=0.516, val_loss=2.6] \n",
      "Epoch 214: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.934, loss=0.37, val_accuracy=0.526, val_loss=2.56]\n",
      "Epoch 215: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.947, loss=0.317, val_accuracy=0.539, val_loss=2.55]\n",
      "Epoch 216: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.95, loss=0.297, val_accuracy=0.537, val_loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 217: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.84, loss=0.66, val_accuracy=0.425, val_loss=3.11]\n",
      "Epoch 218: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.837, loss=0.673, val_accuracy=0.473, val_loss=2.73]\n",
      "Epoch 219: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.855, loss=0.615, val_accuracy=0.506, val_loss=2.6] \n",
      "Epoch 220: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.88, loss=0.537, val_accuracy=0.512, val_loss=2.56]\n",
      "Epoch 221: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.914, loss=0.435, val_accuracy=0.514, val_loss=2.62]\n",
      "Epoch 222: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.935, loss=0.367, val_accuracy=0.527, val_loss=2.56]\n",
      "Epoch 223: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.947, loss=0.316, val_accuracy=0.528, val_loss=2.61]\n",
      "Epoch 224: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.949, loss=0.296, val_accuracy=0.54, val_loss=2.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 225: 100%|██████████| 333/333 [01:26<00:00,  3.83it/s, accuracy=0.854, loss=0.615, val_accuracy=0.456, val_loss=2.93]\n",
      "Epoch 226: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.836, loss=0.678, val_accuracy=0.438, val_loss=3.02]\n",
      "Epoch 227: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.853, loss=0.624, val_accuracy=0.498, val_loss=2.65]\n",
      "Epoch 228: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.885, loss=0.522, val_accuracy=0.489, val_loss=2.74]\n",
      "Epoch 229: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.911, loss=0.444, val_accuracy=0.522, val_loss=2.61]\n",
      "Epoch 230: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.937, loss=0.359, val_accuracy=0.528, val_loss=2.59]\n",
      "Epoch 231: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.947, loss=0.314, val_accuracy=0.54, val_loss=2.56] \n",
      "Epoch 232: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.95, loss=0.294, val_accuracy=0.539, val_loss=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 233: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.855, loss=0.614, val_accuracy=0.481, val_loss=2.81]\n",
      "Epoch 234: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.841, loss=0.658, val_accuracy=0.469, val_loss=2.86]\n",
      "Epoch 235: 100%|██████████| 333/333 [01:26<00:00,  3.85it/s, accuracy=0.86, loss=0.603, val_accuracy=0.466, val_loss=2.87]\n",
      "Epoch 236: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.876, loss=0.549, val_accuracy=0.503, val_loss=2.66]\n",
      "Epoch 237: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.915, loss=0.432, val_accuracy=0.505, val_loss=2.66]\n",
      "Epoch 238: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.936, loss=0.359, val_accuracy=0.53, val_loss=2.56] \n",
      "Epoch 239: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.947, loss=0.313, val_accuracy=0.535, val_loss=2.58]\n",
      "Epoch 240: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.95, loss=0.292, val_accuracy=0.543, val_loss=2.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 241: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.841, loss=0.667, val_accuracy=0.494, val_loss=2.66]\n",
      "Epoch 242: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.854, loss=0.615, val_accuracy=0.483, val_loss=2.75]\n",
      "Epoch 243: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.864, loss=0.585, val_accuracy=0.499, val_loss=2.65]\n",
      "Epoch 244: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.884, loss=0.524, val_accuracy=0.517, val_loss=2.59]\n",
      "Epoch 245: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.916, loss=0.426, val_accuracy=0.516, val_loss=2.64]\n",
      "Epoch 246: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.936, loss=0.358, val_accuracy=0.535, val_loss=2.55]\n",
      "Epoch 247: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.947, loss=0.313, val_accuracy=0.539, val_loss=2.57]\n",
      "Epoch 248: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.95, loss=0.291, val_accuracy=0.542, val_loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.858, loss=0.602, val_accuracy=0.449, val_loss=2.98]\n",
      "Epoch 250: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.851, loss=0.624, val_accuracy=0.491, val_loss=2.7] \n",
      "Epoch 251: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.866, loss=0.577, val_accuracy=0.499, val_loss=2.68]\n",
      "Epoch 252: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.891, loss=0.503, val_accuracy=0.473, val_loss=2.84]\n",
      "Epoch 253: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.917, loss=0.424, val_accuracy=0.515, val_loss=2.63]\n",
      "Epoch 254: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.937, loss=0.356, val_accuracy=0.53, val_loss=2.6]  \n",
      "Epoch 255: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.947, loss=0.31, val_accuracy=0.543, val_loss=2.58]\n",
      "Epoch 256: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.95, loss=0.291, val_accuracy=0.544, val_loss=2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 257: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.859, loss=0.599, val_accuracy=0.485, val_loss=2.78]\n",
      "Epoch 258: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.856, loss=0.611, val_accuracy=0.48, val_loss=2.8]  \n",
      "Epoch 259: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.865, loss=0.582, val_accuracy=0.501, val_loss=2.69]\n",
      "Epoch 260: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.89, loss=0.504, val_accuracy=0.5, val_loss=2.72]  \n",
      "Epoch 261: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.918, loss=0.42, val_accuracy=0.521, val_loss=2.62]\n",
      "Epoch 262: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.939, loss=0.348, val_accuracy=0.535, val_loss=2.58]\n",
      "Epoch 263: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.947, loss=0.31, val_accuracy=0.543, val_loss=2.57]\n",
      "Epoch 264: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.95, loss=0.29, val_accuracy=0.544, val_loss=2.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.869, loss=0.57, val_accuracy=0.466, val_loss=2.93]\n",
      "Epoch 266: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.861, loss=0.592, val_accuracy=0.481, val_loss=2.77]\n",
      "Epoch 267: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.867, loss=0.572, val_accuracy=0.497, val_loss=2.69]\n",
      "Epoch 268: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.893, loss=0.497, val_accuracy=0.518, val_loss=2.64]\n",
      "Epoch 269: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.916, loss=0.424, val_accuracy=0.523, val_loss=2.6] \n",
      "Epoch 270: 100%|██████████| 333/333 [01:26<00:00,  3.84it/s, accuracy=0.938, loss=0.351, val_accuracy=0.537, val_loss=2.58]\n",
      "Epoch 271: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.948, loss=0.307, val_accuracy=0.541, val_loss=2.59]\n",
      "Epoch 272: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.95, loss=0.289, val_accuracy=0.544, val_loss=2.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 273: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.865, loss=0.58, val_accuracy=0.452, val_loss=2.97]\n",
      "Epoch 274: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.855, loss=0.615, val_accuracy=0.494, val_loss=2.7] \n",
      "Epoch 275: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.864, loss=0.585, val_accuracy=0.49, val_loss=2.76] \n",
      "Epoch 276: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.89, loss=0.508, val_accuracy=0.506, val_loss=2.69]\n",
      "Epoch 277: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.916, loss=0.422, val_accuracy=0.528, val_loss=2.59]\n",
      "Epoch 278: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.937, loss=0.353, val_accuracy=0.527, val_loss=2.58]\n",
      "Epoch 279: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.948, loss=0.307, val_accuracy=0.542, val_loss=2.57]\n",
      "Epoch 280: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.95, loss=0.288, val_accuracy=0.545, val_loss=2.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 281: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.864, loss=0.584, val_accuracy=0.474, val_loss=2.93]\n",
      "Epoch 282: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.855, loss=0.619, val_accuracy=0.463, val_loss=2.92]\n",
      "Epoch 283: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.87, loss=0.566, val_accuracy=0.511, val_loss=2.64]\n",
      "Epoch 284: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.893, loss=0.498, val_accuracy=0.501, val_loss=2.73]\n",
      "Epoch 285: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.916, loss=0.423, val_accuracy=0.517, val_loss=2.66]\n",
      "Epoch 286: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.938, loss=0.347, val_accuracy=0.529, val_loss=2.59]\n",
      "Epoch 287: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.948, loss=0.306, val_accuracy=0.541, val_loss=2.59]\n",
      "Epoch 288: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.95, loss=0.288, val_accuracy=0.543, val_loss=2.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.842, loss=0.667, val_accuracy=0.474, val_loss=2.85]\n",
      "Epoch 290: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.857, loss=0.605, val_accuracy=0.476, val_loss=2.86]\n",
      "Epoch 291: 100%|██████████| 333/333 [01:26<00:00,  3.87it/s, accuracy=0.87, loss=0.565, val_accuracy=0.466, val_loss=2.87]\n",
      "Epoch 292: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.894, loss=0.489, val_accuracy=0.5, val_loss=2.7]   \n",
      "Epoch 293: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.918, loss=0.414, val_accuracy=0.522, val_loss=2.62]\n",
      "Epoch 294: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.94, loss=0.345, val_accuracy=0.537, val_loss=2.58]\n",
      "Epoch 295: 100%|██████████| 333/333 [01:27<00:00,  3.81it/s, accuracy=0.948, loss=0.304, val_accuracy=0.543, val_loss=2.58]\n",
      "Epoch 296: 100%|██████████| 333/333 [01:26<00:00,  3.86it/s, accuracy=0.95, loss=0.287, val_accuracy=0.542, val_loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 297: 100%|██████████| 333/333 [01:27<00:00,  3.83it/s, accuracy=0.874, loss=0.553, val_accuracy=0.481, val_loss=2.93]\n",
      "Epoch 298: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.858, loss=0.602, val_accuracy=0.496, val_loss=2.74]\n",
      "Epoch 299: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.872, loss=0.558, val_accuracy=0.506, val_loss=2.67]\n",
      "Epoch 300: 100%|██████████| 333/333 [01:27<00:00,  3.82it/s, accuracy=0.896, loss=0.483, val_accuracy=0.509, val_loss=2.63]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "weight_decay = 1e-1\n",
    "cycle = 8\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/lstm-model/lstm_model_100Epochs_ss.pth\"))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cycle, eta_min=learning_rate / 10)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train_val_loop(epoch, train_dataloader, val_dataloader, model, loss_fn, optimizer, scheduler, n_offset=1):\n",
    "    total_batches = len(train_dataloader)\n",
    "    train_size, train_batches = 0, 0\n",
    "    train_loss, train_correct = 0, 0\n",
    "    val_size, val_batches = 0, 0\n",
    "    val_loss, val_correct = 0, 0\n",
    "    \n",
    "    with tqdm(desc=f'Epoch {epoch+n_offset}', total=total_batches) as bar:\n",
    "        \n",
    "        # Training\n",
    "        for batch, (src, y) in enumerate(train_dataloader):\n",
    "            \n",
    "            # Compute prediction and loss\n",
    "            pred = model(src)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            # Compute metrics\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            train_size += len(y)\n",
    "            train_batches += 1\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "                \n",
    "            scheduler.step(epoch + batch / total_batches)\n",
    "            \n",
    "            # Update progress bar\n",
    "            bar.update()\n",
    "            bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches,\n",
    "                           lr=scheduler.get_last_lr())\n",
    "            \n",
    "        bar.set_postfix(accuracy = train_correct / train_size, loss = train_loss / train_batches)\n",
    "        \n",
    "        #scheduler.step()\n",
    "           \n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch, (src, y) in enumerate(val_dataloader):\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                pred = model(src)\n",
    "                val_loss += loss_fn(pred, y).item()\n",
    "                \n",
    "                # Compute metrics\n",
    "                val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "                val_size += len(y)\n",
    "                val_batches += 1\n",
    "\n",
    "                # Update progress bar\n",
    "                bar.set_postfix(\n",
    "                    accuracy = train_correct / train_size, loss = train_loss / train_batches,\n",
    "                    val_accuracy = val_correct / val_size, val_loss = val_loss / val_batches\n",
    "                )\n",
    "                \n",
    "    if scheduler.T_0 - scheduler.T_cur < 0.1:\n",
    "        print()\n",
    "        \n",
    "    train_losses.append(train_loss / train_batches)\n",
    "    val_losses.append(val_loss / val_batches)\n",
    "\n",
    "    return train_correct / train_size, train_loss / train_batches, val_correct / val_size, val_loss / val_batches\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "saved_state = model.state_dict()\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "#model.load_state_dict(torch.load(\"/kaggle/input/lstm-model/lstm_model_100Epochs_ss.pth\"))\n",
    "# Iterate through epochs for training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    acc, loss, v_acc, v_loss = train_val_loop(epoch, train_loader, val_loader, model, loss_fn, optimizer, scheduler)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        torch.save(model.state_dict(), 'lstm_model_' + str(epoch+1))\n",
    "    if v_loss<best_loss:\n",
    "        best_loss = v_loss\n",
    "        saved_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3918b7cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T13:00:20.790910Z",
     "iopub.status.busy": "2023-04-25T13:00:20.790149Z",
     "iopub.status.idle": "2023-04-25T13:00:20.855561Z",
     "shell.execute_reply": "2023-04-25T13:00:20.854410Z",
     "shell.execute_reply.started": "2023-04-25T13:00:20.790870Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_model_' + str(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c82b7e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T05:28:05.282671Z",
     "iopub.status.busy": "2023-04-19T05:28:05.281909Z",
     "iopub.status.idle": "2023-04-19T05:28:05.338185Z",
     "shell.execute_reply": "2023-04-19T05:28:05.337163Z",
     "shell.execute_reply.started": "2023-04-19T05:28:05.282627Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_model_100Epochs.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d906094d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T05:30:44.549412Z",
     "iopub.status.busy": "2023-04-19T05:30:44.548913Z",
     "iopub.status.idle": "2023-04-19T05:30:44.591543Z",
     "shell.execute_reply": "2023-04-19T05:30:44.590530Z",
     "shell.execute_reply.started": "2023-04-19T05:30:44.549375Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(saved_state, 'lstm_model_100Epochs_ss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6346bf8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T05:27:59.084882Z",
     "iopub.status.busy": "2023-04-19T05:27:59.084435Z",
     "iopub.status.idle": "2023-04-19T05:27:59.182791Z",
     "shell.execute_reply": "2023-04-19T05:27:59.181543Z",
     "shell.execute_reply.started": "2023-04-19T05:27:59.084836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0864,  0.0119,  0.1229,  ..., -0.0498, -0.0056,  0.1881],\n",
       "                      [ 0.0817,  0.0473, -0.0083,  ..., -0.1880,  0.0184,  0.0378],\n",
       "                      [ 0.0567, -0.0426,  0.0238,  ...,  0.0863,  0.0587,  0.0775],\n",
       "                      ...,\n",
       "                      [ 0.0803,  0.0377,  0.0656,  ..., -0.0336, -0.0406,  0.0663],\n",
       "                      [ 0.0114,  0.0700,  0.0495,  ...,  0.0162,  0.0813,  0.0083],\n",
       "                      [ 0.0686, -0.0754,  0.0048,  ...,  0.0699, -0.0017,  0.1190]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[ 0.0644,  0.0750,  0.0120,  ..., -0.0929,  0.0026,  0.0265],\n",
       "                      [-0.0318,  0.0135, -0.0001,  ...,  0.0982,  0.0389, -0.0307],\n",
       "                      [ 0.0509, -0.0128,  0.0318,  ...,  0.0746, -0.0209,  0.0345],\n",
       "                      ...,\n",
       "                      [-0.0552,  0.0216,  0.0282,  ...,  0.0825,  0.0427, -0.0618],\n",
       "                      [-0.0566, -0.0590, -0.0370,  ...,  0.1114, -0.0019,  0.1011],\n",
       "                      [-0.0953, -0.0311,  0.0567,  ...,  0.0470,  0.0521, -0.0038]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([0.0623, 0.0242, 0.0055,  ..., 0.0359, 0.0516, 0.0295], device='cuda:0')),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([0.0756, 0.0278, 0.0334,  ..., 0.0443, 0.0258, 0.0290], device='cuda:0')),\n",
       "             ('lstm.weight_ih_l0_reverse',\n",
       "              tensor([[-0.0129,  0.0486, -0.0619,  ...,  0.0245, -0.0040,  0.0444],\n",
       "                      [ 0.0457, -0.0556,  0.0186,  ..., -0.0282,  0.0823,  0.0468],\n",
       "                      [-0.0123,  0.0178, -0.0223,  ..., -0.0150,  0.0148, -0.0148],\n",
       "                      ...,\n",
       "                      [ 0.0303,  0.0450,  0.0705,  ...,  0.0291, -0.0435,  0.0146],\n",
       "                      [ 0.0174,  0.0827,  0.1303,  ..., -0.0134,  0.0198,  0.0602],\n",
       "                      [-0.0076,  0.0371,  0.0114,  ...,  0.0043, -0.0358, -0.0112]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0846,  0.0083,  0.0646,  ..., -0.0656, -0.0583, -0.0832],\n",
       "                      [ 0.0003, -0.0949,  0.0283,  ..., -0.0325, -0.0149, -0.0113],\n",
       "                      [-0.0330, -0.0323, -0.0068,  ...,  0.0144,  0.0041,  0.0548],\n",
       "                      ...,\n",
       "                      [-0.0141,  0.0214,  0.0835,  ..., -0.0331, -0.0232, -0.0781],\n",
       "                      [-0.0083, -0.0008,  0.1164,  ..., -0.0853, -0.0300, -0.1251],\n",
       "                      [ 0.0030,  0.0147,  0.0104,  ...,  0.0074, -0.0173,  0.0050]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l0_reverse',\n",
       "              tensor([-0.0009,  0.0014, -0.0253,  ...,  0.0109,  0.0542, -0.0078],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l0_reverse',\n",
       "              tensor([-1.8535e-03, -1.2405e-02, -1.8960e-02,  ..., -5.7867e-05,\n",
       "                       2.5893e-02, -1.2673e-02], device='cuda:0')),\n",
       "             ('lstm.weight_ih_l1',\n",
       "              tensor([[ 0.0868,  0.0448,  0.0590,  ...,  0.0524,  0.0257,  0.0022],\n",
       "                      [-0.0323, -0.0475, -0.0241,  ..., -0.0426, -0.0603, -0.0756],\n",
       "                      [-0.0317,  0.0807, -0.0306,  ...,  0.0199,  0.0434, -0.0087],\n",
       "                      ...,\n",
       "                      [-0.0145, -0.1522,  0.0150,  ..., -0.0285, -0.0211, -0.0754],\n",
       "                      [-0.0411, -0.0526,  0.0336,  ...,  0.0196,  0.0454, -0.0254],\n",
       "                      [-0.0076, -0.0356, -0.0388,  ..., -0.0477, -0.0216, -0.0299]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l1',\n",
       "              tensor([[ 0.0076, -0.0116,  0.0037,  ..., -0.0365, -0.0083, -0.0109],\n",
       "                      [ 0.0018,  0.0401,  0.0363,  ...,  0.0785, -0.0097, -0.0392],\n",
       "                      [ 0.0097, -0.0309, -0.0105,  ...,  0.0516,  0.0147, -0.0265],\n",
       "                      ...,\n",
       "                      [-0.0225,  0.0113,  0.0102,  ..., -0.0346,  0.0051, -0.0210],\n",
       "                      [-0.0248, -0.0376,  0.0162,  ...,  0.0134, -0.0086,  0.0142],\n",
       "                      [-0.0491,  0.0735, -0.0231,  ..., -0.0584,  0.0366, -0.0142]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l1',\n",
       "              tensor([-0.0168,  0.0287, -0.0304,  ...,  0.0203,  0.0094, -0.0081],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l1',\n",
       "              tensor([ 0.0018,  0.0020, -0.0036,  ...,  0.0267,  0.0217,  0.0024],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_ih_l1_reverse',\n",
       "              tensor([[-0.0875, -0.0047, -0.0073,  ...,  0.0284, -0.0054,  0.0168],\n",
       "                      [ 0.0069,  0.0216, -0.0704,  ..., -0.0072,  0.0072, -0.0230],\n",
       "                      [-0.0064, -0.0725,  0.0139,  ...,  0.0581,  0.0489,  0.0567],\n",
       "                      ...,\n",
       "                      [ 0.0880,  0.0293,  0.0020,  ...,  0.0097,  0.0771,  0.0105],\n",
       "                      [ 0.0129, -0.0338,  0.0192,  ...,  0.0215,  0.0336, -0.0129],\n",
       "                      [ 0.0030,  0.0512,  0.0142,  ...,  0.0258,  0.0962,  0.0084]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l1_reverse',\n",
       "              tensor([[ 0.0175,  0.0273, -0.0353,  ..., -0.0312,  0.0253, -0.0043],\n",
       "                      [ 0.0478, -0.0379, -0.0102,  ..., -0.0458,  0.0252,  0.0036],\n",
       "                      [ 0.0340, -0.0062,  0.0313,  ..., -0.1129,  0.0075, -0.0985],\n",
       "                      ...,\n",
       "                      [-0.0277,  0.0032,  0.0465,  ..., -0.0146, -0.0135, -0.0638],\n",
       "                      [ 0.0322, -0.0236,  0.0116,  ..., -0.0413,  0.0246, -0.0245],\n",
       "                      [-0.0953, -0.0386,  0.0701,  ..., -0.0501,  0.0011, -0.0475]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l1_reverse',\n",
       "              tensor([ 0.0026,  0.0154,  0.0517,  ...,  0.0664, -0.0174, -0.0043],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l1_reverse',\n",
       "              tensor([-0.0169,  0.0116,  0.0468,  ...,  0.0455,  0.0055,  0.0305],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_ih_l2',\n",
       "              tensor([[-0.0614, -0.1067, -0.0425,  ..., -0.0233, -0.0322, -0.0271],\n",
       "                      [ 0.0235,  0.0647,  0.0182,  ...,  0.0027, -0.0242,  0.0121],\n",
       "                      [-0.0447,  0.0176,  0.0008,  ...,  0.0292,  0.0140,  0.0211],\n",
       "                      ...,\n",
       "                      [-0.0314, -0.0193, -0.0290,  ..., -0.0761,  0.0401, -0.0833],\n",
       "                      [ 0.0123,  0.0504,  0.0514,  ..., -0.0757,  0.0260, -0.0130],\n",
       "                      [-0.0048, -0.0985,  0.0170,  ..., -0.0469, -0.0079, -0.0179]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l2',\n",
       "              tensor([[ 0.0282, -0.0230,  0.0377,  ...,  0.0043, -0.0079, -0.0172],\n",
       "                      [ 0.0093, -0.0352,  0.0824,  ..., -0.0238, -0.0567, -0.0451],\n",
       "                      [-0.0053, -0.0402,  0.0464,  ..., -0.0283, -0.0762, -0.0002],\n",
       "                      ...,\n",
       "                      [ 0.0719, -0.0961,  0.1088,  ...,  0.0048, -0.1420, -0.1031],\n",
       "                      [-0.0021,  0.0456,  0.0452,  ..., -0.0454, -0.0932, -0.0033],\n",
       "                      [-0.0310, -0.1029, -0.0202,  ..., -0.0101,  0.0372, -0.0220]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l2',\n",
       "              tensor([ 0.0473, -0.0108, -0.0056,  ...,  0.0071,  0.0330,  0.0075],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l2',\n",
       "              tensor([ 0.0620,  0.0112,  0.0034,  ..., -0.0194,  0.0261, -0.0057],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_ih_l2_reverse',\n",
       "              tensor([[-0.0450, -0.0132, -0.0567,  ..., -0.0032, -0.1522, -0.0728],\n",
       "                      [-0.0238, -0.0089, -0.0064,  ...,  0.0073, -0.1221, -0.0364],\n",
       "                      [-0.0531,  0.0005, -0.0415,  ..., -0.0130, -0.0713,  0.0243],\n",
       "                      ...,\n",
       "                      [-0.0088,  0.0108,  0.0208,  ..., -0.0601, -0.0030, -0.0231],\n",
       "                      [-0.0794, -0.0083, -0.1636,  ..., -0.0911, -0.0845, -0.1114],\n",
       "                      [-0.0576, -0.0234, -0.0218,  ...,  0.0046,  0.0452, -0.0357]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l2_reverse',\n",
       "              tensor([[ 0.0243,  0.0415, -0.0119,  ..., -0.1220, -0.0230,  0.0288],\n",
       "                      [-0.0314, -0.0422,  0.0370,  ..., -0.0908, -0.0279,  0.0287],\n",
       "                      [-0.0054, -0.0439,  0.0370,  ..., -0.0324,  0.0829,  0.0678],\n",
       "                      ...,\n",
       "                      [ 0.0367, -0.0203,  0.0236,  ..., -0.0548, -0.0719, -0.0175],\n",
       "                      [-0.0417,  0.0362,  0.0209,  ..., -0.0288, -0.0292, -0.0136],\n",
       "                      [ 0.0173,  0.0574, -0.0215,  ..., -0.0185,  0.0298, -0.0576]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l2_reverse',\n",
       "              tensor([ 0.0113, -0.0346, -0.0166,  ...,  0.1307,  0.0040,  0.0179],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l2_reverse',\n",
       "              tensor([ 0.0227, -0.0505, -0.0161,  ...,  0.1006,  0.0058,  0.0511],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_ih_l3',\n",
       "              tensor([[ 0.0450,  0.0618,  0.0049,  ...,  0.0787,  0.0142,  0.0199],\n",
       "                      [-0.1001,  0.0019, -0.0221,  ..., -0.0771, -0.0377,  0.0262],\n",
       "                      [-0.0237,  0.0188,  0.0942,  ..., -0.0265, -0.0160,  0.0134],\n",
       "                      ...,\n",
       "                      [-0.0248, -0.0615, -0.0543,  ..., -0.0241, -0.0102, -0.0286],\n",
       "                      [-0.0185, -0.0468, -0.0746,  ...,  0.0129,  0.0438, -0.0057],\n",
       "                      [-0.0356, -0.0253, -0.1042,  ..., -0.0525, -0.0396, -0.0435]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l3',\n",
       "              tensor([[ 0.0902, -0.0084,  0.0974,  ...,  0.0261, -0.1061, -0.1277],\n",
       "                      [-0.0941,  0.0556, -0.0660,  ..., -0.0153,  0.0010, -0.0534],\n",
       "                      [ 0.0075,  0.0326, -0.0614,  ...,  0.0501, -0.0069,  0.0789],\n",
       "                      ...,\n",
       "                      [-0.0574, -0.0055,  0.0404,  ..., -0.1839, -0.1257,  0.0661],\n",
       "                      [-0.0752, -0.0720,  0.0317,  ..., -0.0921,  0.1405, -0.0191],\n",
       "                      [-0.0113, -0.0414,  0.0097,  ...,  0.1296,  0.0940,  0.0902]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l3',\n",
       "              tensor([-0.0021,  0.0262, -0.0167,  ...,  0.0151,  0.0346,  0.0430],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l3',\n",
       "              tensor([0.0035, 0.0329, 0.0016,  ..., 0.0437, 0.0553, 0.0222], device='cuda:0')),\n",
       "             ('lstm.weight_ih_l3_reverse',\n",
       "              tensor([[-0.0291,  0.0042, -0.1002,  ..., -0.0367, -0.0291, -0.0167],\n",
       "                      [-0.0973, -0.0197, -0.0220,  ..., -0.1221, -0.0323, -0.0204],\n",
       "                      [ 0.0411, -0.1119,  0.1020,  ..., -0.0014, -0.0674,  0.0043],\n",
       "                      ...,\n",
       "                      [-0.0368, -0.1001,  0.1499,  ...,  0.0199,  0.0116, -0.0265],\n",
       "                      [-0.0328, -0.1295,  0.0310,  ...,  0.0296,  0.0312, -0.0397],\n",
       "                      [ 0.1080, -0.0206, -0.0077,  ..., -0.0038, -0.0804,  0.0419]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.weight_hh_l3_reverse',\n",
       "              tensor([[-0.0108, -0.0026, -0.0108,  ..., -0.0022, -0.0205, -0.0116],\n",
       "                      [ 0.0169,  0.0180, -0.0150,  ..., -0.0180, -0.0032, -0.0048],\n",
       "                      [-0.0057, -0.0107, -0.0103,  ..., -0.0034, -0.0034, -0.0097],\n",
       "                      ...,\n",
       "                      [ 0.0123,  0.0049, -0.0147,  ..., -0.0022, -0.0198,  0.0182],\n",
       "                      [-0.0202, -0.0035,  0.0188,  ...,  0.0094, -0.0030, -0.0054],\n",
       "                      [ 0.0055,  0.0083,  0.0187,  ...,  0.0143, -0.0087, -0.0110]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_ih_l3_reverse',\n",
       "              tensor([-0.0114,  0.0233,  0.0995,  ...,  0.0283,  0.0333,  0.0594],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm.bias_hh_l3_reverse',\n",
       "              tensor([-0.0162,  0.0187,  0.0756,  ...,  0.0460,  0.0289,  0.0625],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[-0.0259,  0.0470,  0.1824,  ..., -0.1295,  0.1936,  0.0361],\n",
       "                      [ 0.0771, -0.0573, -0.1607,  ..., -0.0907, -0.0652, -0.0709],\n",
       "                      [ 0.0863, -0.0465, -0.0012,  ...,  0.1342, -0.0627, -0.1323],\n",
       "                      ...,\n",
       "                      [ 0.0067,  0.0154,  0.0441,  ...,  0.0209, -0.0211, -0.0013],\n",
       "                      [-0.0297, -0.0413,  0.1777,  ..., -0.0903,  0.1044, -0.0890],\n",
       "                      [ 0.0123,  0.1571, -0.1737,  ...,  0.1467, -0.1689, -0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([-7.4206e-04,  5.0035e-02,  1.7274e-02,  1.1145e-02,  3.0850e-03,\n",
       "                       5.6021e-03, -3.8226e-02, -1.6503e-02, -2.6361e-02,  3.4458e-02,\n",
       "                      -2.3218e-02, -3.8907e-02,  2.8941e-02,  1.7155e-02,  2.2140e-02,\n",
       "                      -9.6047e-05,  4.4011e-02,  1.3751e-02,  1.5393e-02, -3.9819e-03,\n",
       "                      -2.5514e-04,  6.8464e-03, -3.9268e-03, -2.3191e-02, -2.8742e-02,\n",
       "                       1.8419e-03, -4.5462e-02,  1.3418e-02,  7.3579e-03, -2.2935e-02,\n",
       "                      -7.1934e-03, -4.9280e-02, -4.3461e-02, -9.5870e-03, -4.4663e-02,\n",
       "                       2.2603e-02, -3.8496e-02, -3.2656e-02,  6.6030e-03,  4.0995e-02,\n",
       "                       6.6446e-03, -5.2644e-03,  4.1311e-02, -1.2618e-02,  5.8954e-03,\n",
       "                      -9.2572e-03,  7.5274e-02,  3.4348e-02,  5.1851e-02, -6.4615e-02,\n",
       "                      -1.9558e-02,  1.9186e-03,  9.5409e-03, -6.7135e-03, -6.2938e-03,\n",
       "                      -4.4542e-03, -2.4308e-02,  5.6251e-03,  1.6521e-02,  1.9641e-02,\n",
       "                      -4.9782e-03, -5.3558e-02,  1.8480e-02,  1.7316e-02, -7.2677e-03,\n",
       "                       1.6005e-02, -3.2612e-02, -1.8722e-02,  8.8134e-03,  5.8459e-03,\n",
       "                       2.8373e-02,  2.2868e-02, -5.5297e-03, -2.3341e-02, -1.0671e-02,\n",
       "                       1.1444e-02,  2.5499e-03, -1.8852e-02, -1.8374e-03, -2.1301e-02,\n",
       "                       1.8458e-02, -6.7309e-03,  4.4921e-03, -2.5033e-02,  3.4065e-02,\n",
       "                       1.8319e-02, -2.6957e-02, -1.4169e-03, -1.6221e-02, -4.4786e-02,\n",
       "                       5.3744e-03, -3.9456e-03, -2.4702e-02, -2.0620e-03, -2.8390e-02,\n",
       "                       3.5676e-02,  6.8618e-02,  4.2130e-02,  3.6794e-02,  2.6583e-02,\n",
       "                       3.6357e-02, -9.6613e-03,  5.3460e-02, -2.7994e-02,  1.0401e-02,\n",
       "                      -1.7990e-02,  2.5471e-02, -6.9503e-03, -1.4531e-02, -2.0976e-02,\n",
       "                      -1.4403e-02, -1.2708e-02,  2.5516e-02,  6.9356e-03,  4.7973e-02,\n",
       "                       1.2602e-02, -1.0370e-02, -2.2124e-02, -1.7327e-02, -2.2511e-02,\n",
       "                       1.8140e-02, -2.5600e-02, -5.2165e-02,  4.3673e-02,  2.2373e-02,\n",
       "                      -3.6841e-02,  4.7441e-02,  1.6376e-02,  4.3561e-02,  5.3701e-03,\n",
       "                       3.0768e-02, -8.4813e-03,  9.4638e-03, -2.3279e-02, -4.1205e-02,\n",
       "                      -4.2217e-02,  3.3831e-02,  2.2935e-02,  1.0092e-02, -6.3538e-03,\n",
       "                       1.4933e-02, -3.2807e-02, -4.1802e-02, -3.2265e-03, -5.5477e-03,\n",
       "                       3.4640e-03, -2.2776e-02,  1.6689e-02, -1.1251e-02,  6.2886e-03,\n",
       "                       6.9824e-02,  2.7946e-02,  3.0830e-02, -7.2623e-03,  1.5188e-02,\n",
       "                       2.3163e-03, -7.1398e-03, -2.3950e-02, -2.0785e-02,  2.3543e-02,\n",
       "                       5.0753e-02,  8.4882e-03, -6.4648e-02, -3.0896e-02,  6.5150e-03,\n",
       "                      -2.8607e-02,  5.4588e-02, -4.1059e-02, -2.3858e-02, -2.6325e-02,\n",
       "                      -4.0605e-03, -3.3847e-02,  6.3199e-03,  8.8219e-03, -5.0140e-02,\n",
       "                       4.9470e-04, -1.8845e-02, -1.1036e-02, -1.1163e-03,  3.9167e-02,\n",
       "                       1.9985e-02,  5.6661e-02, -3.5046e-02, -5.4322e-02, -3.5453e-03,\n",
       "                      -4.4137e-03, -1.4502e-02, -1.7417e-02, -2.1080e-03, -1.9395e-02,\n",
       "                       2.3332e-02,  2.6391e-02, -2.8286e-02, -4.0306e-02, -4.2100e-02,\n",
       "                      -2.1413e-02, -1.0897e-02, -2.0350e-02,  6.7864e-03, -5.6557e-04,\n",
       "                       2.6449e-02,  2.6449e-02,  3.4044e-02,  2.3252e-02, -2.7595e-02,\n",
       "                       3.0219e-02,  3.4729e-02,  3.5797e-02, -1.9120e-02, -3.3977e-02,\n",
       "                       2.7304e-02,  5.5376e-04, -5.3100e-03, -3.8835e-02, -4.3279e-02,\n",
       "                      -6.8735e-02,  5.9555e-02,  2.0562e-02,  1.1249e-03, -2.3231e-04,\n",
       "                       3.1287e-02, -1.2766e-02, -2.1379e-02, -1.5305e-02, -1.4326e-02,\n",
       "                       2.4705e-02, -2.1315e-02,  2.8220e-02, -4.1996e-02,  2.2144e-02,\n",
       "                       1.1873e-02,  1.6781e-02, -1.4677e-02, -1.0293e-02, -4.0635e-02,\n",
       "                      -5.6990e-03, -2.3575e-02, -4.0122e-02,  8.1054e-03, -1.3271e-03,\n",
       "                      -9.0636e-04, -5.1714e-03, -1.5857e-02,  1.4008e-02,  3.6806e-02,\n",
       "                      -3.9860e-02, -1.5182e-02,  5.3442e-02,  1.9438e-02, -1.9759e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('embed.0.weight',\n",
       "              tensor([[ 0.0593,  0.0880,  0.0712,  ..., -0.0099, -0.0056,  0.0366],\n",
       "                      [ 0.0115,  0.0051,  0.0168,  ...,  0.0172, -0.0221,  0.0082],\n",
       "                      [-0.0042,  0.0394,  0.0168,  ...,  0.0265, -0.0274, -0.0350],\n",
       "                      ...,\n",
       "                      [-0.0250, -0.0335, -0.0063,  ...,  0.0195, -0.0115, -0.0131],\n",
       "                      [-0.0359, -0.0056,  0.0083,  ...,  0.0068,  0.0177,  0.0286],\n",
       "                      [ 0.0064, -0.0039,  0.0251,  ...,  0.0423,  0.0136, -0.0031]],\n",
       "                     device='cuda:0')),\n",
       "             ('embed.0.bias',\n",
       "              tensor([-1.0595e-02, -1.7056e-02, -2.1325e-02,  6.8763e-03,  3.3603e-02,\n",
       "                       4.9397e-02,  2.5844e-02,  6.5687e-03,  2.1201e-02, -3.5690e-02,\n",
       "                      -4.3432e-03,  2.1214e-02, -3.2466e-02, -1.0855e-03,  1.8802e-02,\n",
       "                       4.7069e-03, -1.2330e-02,  3.5031e-02,  4.6243e-04, -7.6540e-03,\n",
       "                      -1.4618e-02,  8.0311e-02,  3.5354e-02,  7.2246e-02,  2.3623e-02,\n",
       "                       1.4676e-02,  5.7426e-02,  2.2656e-02,  9.7671e-03, -3.7180e-02,\n",
       "                       1.1337e-02, -1.2107e-02, -3.7623e-02,  9.8128e-02, -1.4708e-03,\n",
       "                       4.5957e-02,  3.3917e-02,  2.9490e-02,  1.2940e-01,  2.5445e-03,\n",
       "                      -1.4995e-02,  2.2869e-02, -4.3572e-03,  3.4766e-02,  5.3924e-03,\n",
       "                       2.2942e-02, -2.3720e-03, -3.1567e-02, -7.7343e-03,  9.8881e-03,\n",
       "                      -4.2721e-02, -1.0569e-03,  6.7519e-02, -2.5566e-02,  1.3341e-02,\n",
       "                       1.1329e-02,  3.6280e-03,  1.6219e-03,  4.0488e-02,  1.1700e-02,\n",
       "                       3.9348e-02,  2.3810e-02, -1.8225e-02, -2.7726e-02,  1.4697e-01,\n",
       "                       1.0793e-02, -8.5772e-03, -4.9596e-02,  9.0860e-03,  3.6842e-02,\n",
       "                       3.1600e-02,  1.4183e-02, -3.9522e-02, -3.0793e-02,  3.4133e-02,\n",
       "                      -2.5883e-02, -1.6025e-02,  1.2022e-02, -2.1330e-03,  9.1008e-04,\n",
       "                      -3.2174e-02,  5.4788e-02,  1.1215e-01,  4.5549e-04, -5.1152e-02,\n",
       "                      -1.8240e-02, -2.1260e-03,  1.5356e-02,  7.1275e-02, -4.9783e-03,\n",
       "                       1.3664e-02,  4.8241e-04, -4.3141e-02,  6.2503e-03,  4.3340e-03,\n",
       "                      -1.6668e-02,  9.4406e-04,  5.4192e-02,  4.8574e-04, -4.8708e-02,\n",
       "                       3.4588e-02,  1.3375e-02, -2.9539e-02,  1.5898e-03,  4.4938e-02,\n",
       "                       5.8079e-04, -1.5025e-02,  8.5616e-03,  2.2744e-02, -6.3978e-02,\n",
       "                       3.3995e-02,  2.5623e-02,  2.3692e-02,  3.7442e-02,  5.9586e-02,\n",
       "                       2.1809e-02, -1.0881e-02,  3.6756e-02, -4.2785e-02,  1.5879e-02,\n",
       "                      -7.3333e-03,  2.0301e-02, -1.9333e-02,  5.8171e-02,  8.0757e-03,\n",
       "                      -3.9303e-02, -1.6954e-02,  2.6826e-03, -4.8437e-02,  2.3044e-02,\n",
       "                       3.3602e-02, -3.0041e-03,  4.9999e-02, -4.5579e-02,  4.8802e-02,\n",
       "                      -1.1531e-02,  3.7679e-02,  5.1378e-02,  5.6879e-03,  3.2795e-02,\n",
       "                       4.0359e-03, -1.2989e-02,  2.4566e-02,  1.7822e-03, -1.8149e-02,\n",
       "                      -3.2749e-02, -5.0956e-02, -1.5720e-02,  5.5383e-05,  1.1524e-02,\n",
       "                       5.7892e-02, -3.9528e-02,  2.7997e-02, -1.6815e-02, -4.0689e-02,\n",
       "                      -6.3188e-03, -7.8538e-03, -2.0229e-02,  8.0940e-03,  3.1475e-02,\n",
       "                       2.9353e-02,  5.1617e-02,  4.2883e-02, -1.3724e-02,  6.0675e-03,\n",
       "                       5.7349e-02, -1.6211e-02,  4.3945e-02, -1.0870e-03,  6.3496e-03,\n",
       "                      -2.5424e-02,  2.8310e-02,  1.7255e-02,  4.6190e-02, -3.6254e-03,\n",
       "                       8.2894e-03,  1.7972e-02, -4.1926e-02,  3.3474e-02,  3.5413e-03,\n",
       "                       2.9013e-03,  1.7721e-02,  2.8556e-02, -3.2898e-02, -1.7828e-02,\n",
       "                       5.5008e-02,  5.3861e-03,  6.0759e-02,  7.6229e-03, -2.1898e-02,\n",
       "                      -3.9875e-02,  3.5713e-04, -1.0171e-02, -4.8735e-02,  3.9635e-03,\n",
       "                      -2.4406e-02,  4.0379e-02, -1.2228e-02,  4.3605e-03, -2.0605e-02,\n",
       "                       1.3839e-02,  8.3301e-03,  2.2358e-02, -4.0684e-02,  2.0134e-02,\n",
       "                       2.1538e-02, -3.6779e-04,  4.9297e-03, -4.7174e-04, -3.4113e-03,\n",
       "                       4.7938e-02, -2.8633e-02,  2.9529e-03,  2.8421e-02,  1.9625e-02,\n",
       "                       1.4764e-02,  2.5249e-02,  1.4747e-02,  2.1947e-03,  9.6728e-03,\n",
       "                       2.9642e-02,  3.0588e-02, -7.1405e-02,  1.0276e-02,  3.6010e-02,\n",
       "                       3.8807e-02, -4.6250e-02,  5.9845e-03,  2.1584e-02,  5.5548e-02,\n",
       "                      -5.2551e-02, -3.9809e-02,  1.1735e-02, -1.0519e-02,  4.1042e-03,\n",
       "                       5.8170e-03,  1.2627e-01,  2.9632e-02, -8.7029e-03,  4.9693e-02,\n",
       "                      -1.3603e-02,  7.0678e-02, -1.0744e-02, -3.6705e-03, -4.1402e-02,\n",
       "                      -2.0178e-02,  6.9175e-04,  1.6362e-02, -6.5939e-03,  1.7240e-02,\n",
       "                      -1.1393e-02,  1.8852e-02, -2.7911e-02,  9.3177e-03,  8.4205e-03,\n",
       "                      -3.8896e-02,  1.5878e-03, -4.6124e-03, -2.7164e-02,  2.3011e-02,\n",
       "                       9.3543e-03, -3.4887e-02, -3.8590e-02, -3.4809e-02,  3.9629e-02,\n",
       "                       2.7955e-03, -2.6447e-02, -2.4275e-02, -2.9726e-02,  7.4652e-03,\n",
       "                      -9.8752e-03,  1.1430e-02, -2.5740e-02,  1.3104e-02,  1.3279e-02,\n",
       "                      -5.4384e-03,  3.7664e-02,  2.7714e-02,  7.2928e-02, -1.8416e-02,\n",
       "                      -1.4383e-02,  5.7256e-03, -9.5421e-04,  1.0747e-02, -8.4714e-03,\n",
       "                      -4.8426e-03, -4.5064e-02,  9.8986e-03, -4.9393e-02,  1.8451e-02,\n",
       "                       5.0345e-03,  7.2878e-02,  2.4776e-02, -2.4092e-02,  1.6801e-03,\n",
       "                       2.2450e-02, -1.3217e-02,  4.3135e-03,  2.8535e-03, -1.0977e-02,\n",
       "                       1.8118e-02, -5.6254e-03,  2.0087e-04,  4.5185e-02,  6.0614e-02,\n",
       "                       3.7595e-02,  1.8075e-02,  1.1510e-02, -3.2336e-02,  1.0467e-02,\n",
       "                      -8.9256e-03, -9.7743e-03, -3.1375e-02, -2.9046e-03,  2.6469e-02,\n",
       "                       2.0094e-02, -3.3290e-02, -3.0325e-02,  1.7096e-02,  2.5479e-02,\n",
       "                       9.7635e-02,  2.7397e-02,  1.5385e-02, -2.0317e-02, -1.5600e-02,\n",
       "                      -3.1780e-02,  3.5864e-02,  9.2599e-02, -5.9524e-02,  3.2529e-02,\n",
       "                      -5.0897e-02, -3.1587e-02,  1.9638e-02, -6.4374e-02, -3.2343e-02,\n",
       "                      -2.5287e-02,  1.7815e-02,  1.9950e-02,  3.0544e-03, -2.6507e-02,\n",
       "                       2.3855e-02,  1.0579e-03, -4.3001e-02,  4.4219e-02,  5.1582e-03,\n",
       "                      -1.2030e-02, -2.5638e-02,  4.6878e-02,  2.9526e-02,  1.6947e-02,\n",
       "                       2.2059e-02, -1.1248e-02], device='cuda:0')),\n",
       "             ('embed.1.weight',\n",
       "              tensor([0.3544, 0.3087, 0.2967, 0.0999, 0.1071, 0.1462, 0.2035, 0.3022, 0.0959,\n",
       "                      0.1547, 0.3266, 0.3554, 0.3138, 0.3101, 0.0413, 0.3805, 0.3029, 0.2772,\n",
       "                      0.3507, 0.0496, 0.2957, 0.3462, 0.2267, 0.3750, 0.1038, 0.2624, 0.2578,\n",
       "                      0.2377, 0.3482, 0.3516, 0.1300, 0.1808, 0.3491, 0.3443, 0.3569, 0.3766,\n",
       "                      0.3503, 0.2619, 0.4883, 0.3111, 0.2967, 0.3165, 0.3203, 0.2680, 0.3219,\n",
       "                      0.3828, 0.2086, 0.2947, 0.3242, 0.3327, 0.3209, 0.3100, 0.1560, 0.2323,\n",
       "                      0.0990, 0.0766, 0.3720, 0.1043, 0.2124, 0.1763, 0.1547, 0.3394, 0.1862,\n",
       "                      0.1963, 0.6150, 0.3049, 0.3573, 0.2944, 0.0564, 0.3381, 0.1172, 0.1187,\n",
       "                      0.2335, 0.3223, 0.2403, 0.3621, 0.3143, 0.0817, 0.3727, 0.0510, 0.2421,\n",
       "                      0.3950, 0.4446, 0.3710, 0.2233, 0.1820, 0.4279, 0.2640, 0.3098, 0.3275,\n",
       "                      0.3257, 0.3828, 0.2494, 0.3715, 0.2839, 0.2858, 0.3235, 0.3068, 0.3848,\n",
       "                      0.2214, 0.0820, 0.2387, 0.3450, 0.0308, 0.0732, 0.3468, 0.2138, 0.2973,\n",
       "                      0.2826, 0.1920, 0.2558, 0.1969, 0.3340, 0.2845, 0.3773, 0.2188, 0.3505,\n",
       "                      0.3799, 0.2720, 0.3778, 0.1478, 0.3079, 0.2939, 0.1246, 0.1373, 0.3394,\n",
       "                      0.4303, 0.0770, 0.3378, 0.0701, 0.3296, 0.3204, 0.0715, 0.2495, 0.1582,\n",
       "                      0.3887, 0.3499, 0.1581, 0.1094, 0.3458, 0.0725, 0.3843, 0.3072, 0.3342,\n",
       "                      0.2024, 0.3478, 0.1734, 0.4041, 0.2582, 0.3405, 0.1559, 0.3676, 0.3231,\n",
       "                      0.2531, 0.4228, 0.3559, 0.3203, 0.0947, 0.3628, 0.3028, 0.4295, 0.0709,\n",
       "                      0.3926, 0.3196, 0.4169, 0.1148, 0.2912, 0.3715, 0.3175, 0.3096, 0.3488,\n",
       "                      0.3915, 0.2077, 0.2011, 0.1771, 0.3917, 0.3081, 0.3181, 0.3822, 0.3425,\n",
       "                      0.3632, 0.3702, 0.3715, 0.3157, 0.3280, 0.4508, 0.1749, 0.3033, 0.3246,\n",
       "                      0.3470, 0.1997, 0.2931, 0.3613, 0.1968, 0.1846, 0.1747, 0.3420, 0.4484,\n",
       "                      0.0673, 0.1940, 0.3038, 0.0778, 0.3229, 0.3098, 0.3482, 0.3638, 0.3593,\n",
       "                      0.4240, 0.3630, 0.3985, 0.1415, 0.2442, 0.0783, 0.2874, 0.1440, 0.2993,\n",
       "                      0.0451, 0.1583, 0.2887, 0.3133, 0.2242, 0.2495, 0.3444, 0.2848, 0.3515,\n",
       "                      0.3123, 0.3699, 0.2233, 0.3170, 0.0686, 0.3266, 0.3152, 0.3630, 0.3679,\n",
       "                      0.2105, 0.3690, 0.4458, 0.1754, 0.3250, 0.3834, 0.2620, 0.2054, 0.1643,\n",
       "                      0.3500, 0.3412, 0.3645, 0.3445, 0.4374, 0.2050, 0.3865, 0.3699, 0.3086,\n",
       "                      0.3215, 0.2841, 0.3203, 0.1464, 0.0659, 0.3516, 0.3401, 0.3716, 0.2555,\n",
       "                      0.2953, 0.2966, 0.2669, 0.3302, 0.1082, 0.2876, 0.3168, 0.3776, 0.0960,\n",
       "                      0.0703, 0.2859, 0.3939, 0.3185, 0.3704, 0.4087, 0.2284, 0.3532, 0.4368,\n",
       "                      0.3160, 0.4082, 0.3065, 0.3498, 0.2754, 0.2450, 0.1451, 0.3133, 0.3446,\n",
       "                      0.3057, 0.1906, 0.3152, 0.2966, 0.3552, 0.3233, 0.3602, 0.1972, 0.2633,\n",
       "                      0.3372, 0.2891, 0.3355, 0.3481, 0.3282, 0.3060, 0.2000, 0.1337, 0.1679,\n",
       "                      0.4174, 0.3432, 0.2342, 0.3546, 0.3858, 0.1571, 0.3835, 0.3712, 0.2726,\n",
       "                      0.0894, 0.2860, 0.3876, 0.2789, 0.3844, 0.4142, 0.3708, 0.3628, 0.2945,\n",
       "                      0.3370, 0.1910, 0.1781, 0.3518, 0.2903, 0.3520, 0.2210, 0.2047, 0.4115,\n",
       "                      0.2979, 0.3280, 0.1409, 0.2755, 0.1496, 0.3791, 0.3473, 0.0684, 0.3540,\n",
       "                      0.3288, 0.2497, 0.3704, 0.3826, 0.4170, 0.3075, 0.3083, 0.2761, 0.3416,\n",
       "                      0.1070], device='cuda:0')),\n",
       "             ('embed.1.bias',\n",
       "              tensor([-0.0130, -0.0077, -0.0214, -0.1807, -0.2020, -0.2115, -0.1298, -0.0102,\n",
       "                      -0.1911, -0.1477, -0.0044, -0.0351, -0.0559, -0.0418, -0.2516, -0.0078,\n",
       "                      -0.0203, -0.0130, -0.0167, -0.2345, -0.0217, -0.0367, -0.0476, -0.0585,\n",
       "                      -0.2338, -0.0586, -0.1167, -0.0614, -0.0074, -0.0170, -0.1672, -0.1439,\n",
       "                      -0.0059, -0.0417, -0.0154,  0.0053, -0.0092, -0.0373,  0.0348, -0.0222,\n",
       "                      -0.0091, -0.0084, -0.0152, -0.0189, -0.0096, -0.0192, -0.0966, -0.0243,\n",
       "                      -0.0218, -0.0464, -0.0249, -0.0298, -0.1723, -0.0851, -0.1979, -0.2322,\n",
       "                      -0.0148, -0.2393, -0.0643, -0.1520, -0.1856, -0.0400, -0.1392, -0.0733,\n",
       "                       0.1094, -0.0169, -0.0145, -0.0304, -0.2329, -0.0220, -0.2045, -0.2143,\n",
       "                      -0.0500,  0.0020, -0.0737, -0.0175, -0.0279, -0.2140, -0.0361, -0.2171,\n",
       "                      -0.0584, -0.0150, -0.0033, -0.0178, -0.0850, -0.1061, -0.0036, -0.0181,\n",
       "                      -0.0735, -0.0167, -0.0137, -0.0083, -0.0308, -0.0455, -0.0644, -0.0211,\n",
       "                      -0.0319, -0.0223, -0.0268, -0.0749, -0.2108, -0.0552, -0.0124, -0.2231,\n",
       "                      -0.2010, -0.0120, -0.1381, -0.0252, -0.0424, -0.1275, -0.0475, -0.1063,\n",
       "                      -0.0153, -0.0643, -0.0348, -0.0755, -0.0429, -0.0221, -0.0324, -0.0189,\n",
       "                      -0.1456, -0.0186, -0.0345, -0.2015, -0.2127, -0.0292, -0.0192, -0.2019,\n",
       "                      -0.0235, -0.2272, -0.0419, -0.0257, -0.2281, -0.0164, -0.1758, -0.0162,\n",
       "                      -0.0050, -0.1758, -0.1778, -0.0171, -0.2391, -0.0095, -0.0430, -0.0277,\n",
       "                      -0.0655, -0.0161, -0.1216, -0.0218, -0.0230, -0.0213, -0.2192, -0.0215,\n",
       "                      -0.0167, -0.0590, -0.0013, -0.0151, -0.0125, -0.2035, -0.0211, -0.0194,\n",
       "                      -0.0134, -0.1978, -0.0055, -0.0232, -0.0115, -0.2392, -0.0378, -0.0132,\n",
       "                      -0.0241, -0.0456, -0.0110, -0.0063, -0.1107, -0.1590, -0.0581, -0.0132,\n",
       "                      -0.0328, -0.0060, -0.0157, -0.0270, -0.0192, -0.0289, -0.0234, -0.0385,\n",
       "                      -0.0160,  0.0284, -0.1701, -0.1150, -0.0201, -0.0327, -0.0747, -0.0324,\n",
       "                      -0.0658, -0.1484, -0.0992, -0.1485, -0.0169, -0.0157, -0.2299, -0.1545,\n",
       "                      -0.0703, -0.2452, -0.0025, -0.0286, -0.0097,  0.0051, -0.0357, -0.0309,\n",
       "                      -0.0188,  0.0048, -0.2028, -0.0384, -0.2478, -0.0332, -0.1569, -0.0326,\n",
       "                      -0.2665, -0.1803, -0.0518, -0.0306, -0.1589, -0.0643,  0.0093,  0.0230,\n",
       "                      -0.0082, -0.0112, -0.0163, -0.0421, -0.0168, -0.2129, -0.0175, -0.0156,\n",
       "                      -0.0388, -0.0106, -0.1269, -0.0115, -0.0207, -0.1683, -0.0212, -0.0407,\n",
       "                      -0.0202, -0.1845, -0.1227, -0.0125, -0.0191, -0.0110, -0.0229, -0.0040,\n",
       "                      -0.0664, -0.0202, -0.0148, -0.0295, -0.0177, -0.0266, -0.0298, -0.1736,\n",
       "                      -0.2123, -0.0271, -0.0110, -0.0230, -0.0267, -0.0317, -0.0207, -0.0127,\n",
       "                      -0.0315, -0.1977, -0.0369, -0.0020, -0.0169, -0.2105, -0.2353, -0.0128,\n",
       "                      -0.0058, -0.0264, -0.0126, -0.0247, -0.0717, -0.0250, -0.0056, -0.0170,\n",
       "                      -0.0057, -0.0290, -0.0370, -0.0235, -0.0383, -0.1492, -0.0174, -0.0462,\n",
       "                      -0.0266, -0.0985, -0.0260, -0.0897, -0.0140, -0.0289, -0.0006, -0.0824,\n",
       "                      -0.0391, -0.0004, -0.0208, -0.0165, -0.0259, -0.0198, -0.0737, -0.1796,\n",
       "                      -0.2290, -0.1652, -0.0242, -0.0227, -0.0411, -0.0269,  0.0018, -0.1502,\n",
       "                      -0.0021, -0.0105, -0.0165, -0.1852, -0.0170, -0.0265, -0.0214, -0.0212,\n",
       "                      -0.0425, -0.0042, -0.0243, -0.0170, -0.0243, -0.0827, -0.1135, -0.0719,\n",
       "                      -0.0122, -0.0212, -0.0439, -0.0648, -0.0071, -0.0402, -0.0071, -0.1454,\n",
       "                      -0.0514, -0.1310, -0.0121, -0.0178, -0.2135, -0.0123, -0.0099, -0.1111,\n",
       "                      -0.0162, -0.0250, -0.0227, -0.0182, -0.0148, -0.0235, -0.0250, -0.1763],\n",
       "                     device='cuda:0')),\n",
       "             ('embed.3.weight',\n",
       "              tensor([[ 0.0250, -0.0201, -0.0033,  ..., -0.0076, -0.0106,  0.0060],\n",
       "                      [ 0.0539, -0.0237, -0.0056,  ..., -0.0053,  0.0084,  0.0195],\n",
       "                      [ 0.0118, -0.0146, -0.0642,  ..., -0.0172, -0.0086,  0.0421],\n",
       "                      ...,\n",
       "                      [ 0.0316, -0.0400, -0.0027,  ...,  0.0110,  0.0280,  0.0289],\n",
       "                      [-0.0071, -0.0524, -0.0097,  ...,  0.0713, -0.0106,  0.0318],\n",
       "                      [-0.0170,  0.0167,  0.0779,  ...,  0.0156, -0.0096,  0.0196]],\n",
       "                     device='cuda:0')),\n",
       "             ('embed.3.bias',\n",
       "              tensor([ 7.1345e-03, -6.6182e-03,  2.1287e-02, -3.2421e-03, -3.0586e-02,\n",
       "                       5.9230e-03, -1.1963e-02,  3.9981e-02, -6.6744e-03, -4.4515e-03,\n",
       "                      -1.2210e-02, -1.2007e-02, -1.8971e-02,  1.6335e-02,  1.8361e-03,\n",
       "                      -8.9709e-03,  1.8044e-02,  1.0987e-03, -1.1596e-02, -1.0196e-02,\n",
       "                      -1.1687e-02, -5.4123e-03, -5.1745e-03, -3.7994e-03,  9.5479e-03,\n",
       "                       6.8651e-04,  8.9589e-04, -2.9418e-03, -7.5542e-04,  5.6612e-03,\n",
       "                       1.3337e-02,  1.0177e-03, -1.7874e-02, -8.2704e-03, -2.4662e-02,\n",
       "                       1.7379e-02,  1.4524e-02,  5.9298e-03,  1.4976e-02,  1.3209e-02,\n",
       "                       3.6186e-03, -2.4851e-02, -1.0014e-02,  3.5896e-04,  1.3127e-02,\n",
       "                       9.9673e-03, -5.9211e-04, -6.8378e-03, -4.7466e-03,  1.6620e-02,\n",
       "                       7.0850e-03,  2.9314e-02,  2.1177e-03, -1.2343e-02, -1.2534e-02,\n",
       "                       7.6139e-04,  9.6826e-03, -3.2501e-03,  2.3982e-04, -1.0048e-02,\n",
       "                      -7.2423e-03, -7.0834e-03,  2.6381e-02,  8.1115e-03,  3.0314e-02,\n",
       "                       3.8883e-03, -2.9241e-03, -2.6020e-02, -1.2233e-02,  1.0281e-03,\n",
       "                       5.5327e-03, -1.0373e-02, -7.7820e-03,  1.6001e-02,  4.7717e-03,\n",
       "                      -6.0926e-03,  1.5970e-02, -6.6093e-03, -2.1304e-02,  2.0582e-02,\n",
       "                      -9.4534e-03,  8.6879e-03, -1.9732e-02,  2.1791e-03, -1.0259e-02,\n",
       "                       1.1192e-02, -6.8154e-03,  2.7245e-02,  1.3194e-02,  1.0399e-02,\n",
       "                      -7.9564e-03, -8.8054e-03, -3.7746e-03, -1.5782e-02, -1.0641e-02,\n",
       "                       3.6629e-03,  1.9394e-02,  4.0884e-03,  1.9483e-02, -2.6865e-02,\n",
       "                       5.4089e-03, -4.2982e-03, -2.1471e-02, -1.8047e-02, -1.6354e-02,\n",
       "                       9.2934e-04,  4.5937e-03, -4.5187e-03, -1.1439e-02, -8.8020e-03,\n",
       "                      -2.7303e-03,  4.5085e-05,  1.6611e-02, -1.7495e-02, -4.5255e-03,\n",
       "                      -2.4251e-02, -6.0445e-04,  1.0924e-02, -9.2180e-04, -2.2285e-02,\n",
       "                       1.7519e-03,  6.0320e-03,  2.0845e-02,  7.5224e-03,  1.0368e-02,\n",
       "                      -1.7472e-02,  8.1201e-03, -1.1917e-02,  2.6547e-02,  1.1680e-02,\n",
       "                      -1.8734e-02,  4.8863e-03, -1.4802e-02, -1.9776e-02,  1.1756e-02,\n",
       "                      -2.3514e-02,  1.4344e-02,  1.0818e-02,  9.8448e-03,  1.7523e-02,\n",
       "                      -9.8757e-03,  1.2227e-02,  5.7908e-03, -5.8084e-03, -3.5924e-03,\n",
       "                       1.1841e-04, -8.3242e-03,  3.0799e-03,  9.0904e-03,  4.0024e-03,\n",
       "                       1.8085e-03,  1.1326e-02,  6.6365e-03, -1.1286e-02,  2.6491e-03,\n",
       "                      -2.4270e-02, -1.0525e-02, -2.0186e-02,  9.8730e-03,  1.2064e-02,\n",
       "                       2.0109e-02,  1.0969e-02, -1.3737e-02, -1.3808e-02,  7.4609e-04,\n",
       "                       2.0763e-03,  1.0955e-02,  2.1670e-03,  9.2517e-03, -8.4597e-03,\n",
       "                       7.9624e-04, -1.8676e-02,  5.3454e-03, -3.8334e-03, -2.6617e-02,\n",
       "                       1.0162e-02], device='cuda:0')),\n",
       "             ('embed.4.weight',\n",
       "              tensor([0.3703, 0.5160, 0.5074, 0.5807, 0.5007, 0.4557, 0.4156, 0.5590, 0.3801,\n",
       "                      0.6246, 0.6411, 0.4835, 0.4844, 0.3880, 0.5288, 0.6630, 0.3863, 0.4792,\n",
       "                      0.5129, 0.5301, 0.5469, 0.6596, 0.6331, 0.3986, 0.4894, 0.4462, 0.5745,\n",
       "                      0.4914, 0.6039, 0.4561, 0.6692, 0.4445, 0.4874, 0.6340, 0.4565, 0.3611,\n",
       "                      0.4010, 0.6406, 0.4461, 0.4206, 0.4056, 0.5482, 0.6024, 0.5493, 0.6061,\n",
       "                      0.4527, 0.4158, 0.6228, 0.5891, 0.4640, 0.6729, 0.4093, 0.4318, 0.5982,\n",
       "                      0.4875, 0.6107, 0.4639, 0.4323, 0.5948, 0.6168, 0.6208, 0.5837, 0.4616,\n",
       "                      0.4892, 0.4194, 0.5498, 0.6434, 0.4524, 0.5435, 0.4276, 0.4731, 0.6788,\n",
       "                      0.5902, 0.4183, 0.5622, 0.6581, 0.6067, 0.4123, 0.6511, 0.4547, 0.4311,\n",
       "                      0.5133, 0.4319, 0.5670, 0.6258, 0.4695, 0.6269, 0.4301, 0.3631, 0.3940,\n",
       "                      0.5436, 0.6716, 0.4246, 0.5903, 0.6049, 0.4670, 0.5533, 0.4461, 0.5297,\n",
       "                      0.5265, 0.4455, 0.5136, 0.5939, 0.5313, 0.4646, 0.6038, 0.5476, 0.6098,\n",
       "                      0.4547, 0.6656, 0.5424, 0.4357, 0.5531, 0.7021, 0.4068, 0.5421, 0.3182,\n",
       "                      0.3941, 0.6354, 0.6421, 0.6364, 0.6831, 0.4477, 0.5253, 0.4980, 0.4254,\n",
       "                      0.4225, 0.4778, 0.4125, 0.4177, 0.6143, 0.5013, 0.5385, 0.5598, 0.4397,\n",
       "                      0.6331, 0.4632, 0.4750, 0.5968, 0.5735, 0.4955, 0.6177, 0.6372, 0.4854,\n",
       "                      0.6612, 0.3906, 0.4601, 0.3799, 0.5077, 0.6218, 0.4863, 0.4885, 0.5003,\n",
       "                      0.4104, 0.4827, 0.5460, 0.3901, 0.5623, 0.4163, 0.4532, 0.3742, 0.3995,\n",
       "                      0.6253, 0.5899, 0.4516, 0.6017, 0.5883, 0.4850, 0.5141, 0.5432, 0.2374,\n",
       "                      0.7473, 0.3946, 0.5278, 0.6019, 0.3867], device='cuda:0')),\n",
       "             ('embed.4.bias',\n",
       "              tensor([ 0.0367,  0.0090, -0.0462,  0.0594,  0.0152, -0.0268, -0.0111,  0.1294,\n",
       "                      -0.1160,  0.0275,  0.2145, -0.0216,  0.0738,  0.0396,  0.0584,  0.2067,\n",
       "                       0.0144,  0.0846,  0.0381,  0.0368,  0.0053,  0.1745,  0.0325,  0.0342,\n",
       "                       0.0036, -0.0398,  0.0509,  0.0125,  0.0171, -0.0489,  0.1739,  0.0223,\n",
       "                       0.0381,  0.0275,  0.0388,  0.0322,  0.0321,  0.2043, -0.0053,  0.0272,\n",
       "                       0.0042, -0.0453,  0.0103,  0.0183,  0.1485,  0.0342,  0.0456,  0.1252,\n",
       "                      -0.0219, -0.0230,  0.0349,  0.0487, -0.0080,  0.0996,  0.0454,  0.0287,\n",
       "                       0.0224,  0.0433,  0.1398,  0.2171,  0.1980,  0.0051,  0.0437, -0.0584,\n",
       "                       0.0397,  0.0483,  0.2208,  0.0233,  0.0473,  0.0455,  0.0155,  0.0508,\n",
       "                       0.1936,  0.0248,  0.0563,  0.0076, -0.0025,  0.0191,  0.1651, -0.0794,\n",
       "                       0.0439, -0.0006,  0.0431,  0.1890,  0.2064,  0.0441,  0.1596,  0.0488,\n",
       "                       0.0258,  0.0333,  0.0648,  0.1798,  0.0563,  0.0311,  0.1504, -0.0457,\n",
       "                       0.1435,  0.0749,  0.1255, -0.0202, -0.0187, -0.0348,  0.0237,  0.1088,\n",
       "                      -0.0635,  0.1917,  0.0289,  0.1614,  0.0448,  0.2322,  0.0301, -0.0048,\n",
       "                       0.0769,  0.1833, -0.0091, -0.0296, -0.0650,  0.0151,  0.1863, -0.0216,\n",
       "                       0.2214, -0.0028,  0.0268, -0.0224, -0.0109,  0.0087,  0.0533, -0.0016,\n",
       "                       0.0381,  0.0033,  0.1945,  0.0328,  0.0172,  0.0265, -0.0316,  0.2311,\n",
       "                       0.0465, -0.0345,  0.1139,  0.1834, -0.0031,  0.2009,  0.2344, -0.0018,\n",
       "                       0.1781,  0.0218, -0.0205,  0.0393, -0.0188,  0.2208, -0.0129,  0.0285,\n",
       "                      -0.0023,  0.0322,  0.0236,  0.0078, -0.0713,  0.0063, -0.1147,  0.0237,\n",
       "                       0.0408,  0.0561,  0.2317,  0.0023,  0.0697,  0.0190,  0.1857,  0.0169,\n",
       "                      -0.0107,  0.0323, -0.0985,  0.0497,  0.0217, -0.0313,  0.0374,  0.0131],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da099c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/kaggle/input/lstm-model/lstm_model_100Epochs_ss.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcac23bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:42:19.690242Z",
     "iopub.status.busy": "2023-04-20T18:42:19.689764Z",
     "iopub.status.idle": "2023-04-20T18:42:20.802441Z",
     "shell.execute_reply": "2023-04-20T18:42:20.801191Z",
     "shell.execute_reply.started": "2023-04-20T18:42:19.690204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403035e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:41:56.256055Z",
     "iopub.status.busy": "2023-04-20T18:41:56.255060Z",
     "iopub.status.idle": "2023-04-20T18:41:57.245222Z",
     "shell.execute_reply": "2023-04-20T18:41:57.243839Z",
     "shell.execute_reply.started": "2023-04-20T18:41:56.255979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9673908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-20T18:42:11.455506Z",
     "iopub.status.busy": "2023-04-20T18:42:11.454785Z",
     "iopub.status.idle": "2023-04-20T18:42:12.573577Z",
     "shell.execute_reply": "2023-04-20T18:42:12.571417Z",
     "shell.execute_reply.started": "2023-04-20T18:42:11.455460Z"
    }
   },
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1733044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
